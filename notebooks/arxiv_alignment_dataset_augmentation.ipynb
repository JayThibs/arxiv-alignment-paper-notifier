{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arxiv_alignment_dataset_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wzIalYJ8l9I3",
        "d2bs1wn-l3YI",
        "_4DMsFqP4Y4s",
        "OTeKGRXEz4ki"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPun4NyLySUsMEkXDxtCqJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c62618e41bc42aba761b58896ed19fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5978b5aceb4e4d59bbdc30649b3f562c",
              "IPY_MODEL_2317af9b56b941cc9ea5ff9ff3eea713",
              "IPY_MODEL_fca80cf567814eb2b6a12b120c777d5d"
            ],
            "layout": "IPY_MODEL_d15b349a4def4d32854373a7a1edb63d"
          }
        },
        "5978b5aceb4e4d59bbdc30649b3f562c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d344c65b3fb845549e2fd5f7510ef4fa",
            "placeholder": "​",
            "style": "IPY_MODEL_51d75420be0e417d86541e0dee784a86",
            "value": "Downloading: 100%"
          }
        },
        "2317af9b56b941cc9ea5ff9ff3eea713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43d8171b30a44a6abdb9a7ed19bedcc",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caabe2ef1bbd4ab1aada130d53bac5cd",
            "value": 898823
          }
        },
        "fca80cf567814eb2b6a12b120c777d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09148b698a6c4ed9935adfb5a0778c46",
            "placeholder": "​",
            "style": "IPY_MODEL_6be5244099a848a1b08cb24aaee04c30",
            "value": " 878k/878k [00:01&lt;00:00, 1.13MB/s]"
          }
        },
        "d15b349a4def4d32854373a7a1edb63d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d344c65b3fb845549e2fd5f7510ef4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d75420be0e417d86541e0dee784a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e43d8171b30a44a6abdb9a7ed19bedcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caabe2ef1bbd4ab1aada130d53bac5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09148b698a6c4ed9935adfb5a0778c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be5244099a848a1b08cb24aaee04c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b7cc6c27a94fb7bd3d454520bafe4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9dcd6c69384485f82813f28e5312a55",
              "IPY_MODEL_2f757abafc5b4007b03896756fa48514",
              "IPY_MODEL_1567b8ff089243b0ba5882b5c394e36b"
            ],
            "layout": "IPY_MODEL_698826e8d03b426181672c76926119b5"
          }
        },
        "b9dcd6c69384485f82813f28e5312a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b26e7d6c304abe9c236f348ccaa411",
            "placeholder": "​",
            "style": "IPY_MODEL_10f87684db4d43f9a2a06eaf43f9d887",
            "value": "Downloading: 100%"
          }
        },
        "2f757abafc5b4007b03896756fa48514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f553aabb1e4c918207a6c0697b9a1f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94d33b2c5f1246ba86a66a181026cd7f",
            "value": 456318
          }
        },
        "1567b8ff089243b0ba5882b5c394e36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95224d4e4c84468abb17a7d6aa62a2f",
            "placeholder": "​",
            "style": "IPY_MODEL_582885c9a2534a69bc2c101eb8b21f1f",
            "value": " 446k/446k [00:00&lt;00:00, 680kB/s]"
          }
        },
        "698826e8d03b426181672c76926119b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b26e7d6c304abe9c236f348ccaa411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f87684db4d43f9a2a06eaf43f9d887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f553aabb1e4c918207a6c0697b9a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d33b2c5f1246ba86a66a181026cd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b95224d4e4c84468abb17a7d6aa62a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582885c9a2534a69bc2c101eb8b21f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b05e49705a4f6c8f2e3cd3babde227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5263a323046d4b5eb3422b4d7c0aa4b0",
              "IPY_MODEL_6cd595156eeb4fe883651cb3fbf63a2d",
              "IPY_MODEL_4b259a2cfa144ad6aa012e3f6ac0db1a"
            ],
            "layout": "IPY_MODEL_0a4df9e1d5de43b3a6bc4f5f2d06cbec"
          }
        },
        "5263a323046d4b5eb3422b4d7c0aa4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7195055329f144f2999c2b0fa9f36386",
            "placeholder": "​",
            "style": "IPY_MODEL_69f525cad91843b8becb3beaf0091233",
            "value": "Downloading: 100%"
          }
        },
        "6cd595156eeb4fe883651cb3fbf63a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ceff7d79494dfa8c4ca678f988aa5f",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2e40ac64cd94a1fa25b81ee71d2a596",
            "value": 1355863
          }
        },
        "4b259a2cfa144ad6aa012e3f6ac0db1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10910e67e344ac9adb08d36e84d2120",
            "placeholder": "​",
            "style": "IPY_MODEL_926f541a620040d9a72e8d6dd688e2c0",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.19MB/s]"
          }
        },
        "0a4df9e1d5de43b3a6bc4f5f2d06cbec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7195055329f144f2999c2b0fa9f36386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f525cad91843b8becb3beaf0091233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ceff7d79494dfa8c4ca678f988aa5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e40ac64cd94a1fa25b81ee71d2a596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f10910e67e344ac9adb08d36e84d2120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926f541a620040d9a72e8d6dd688e2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1e5a54f060d4a49b19959f755721d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5137de83145940fbaf53604933e637bd",
              "IPY_MODEL_e18ceeb6a05a4bbab9eaaf0c74242443",
              "IPY_MODEL_931c7ab1c5cb4987bbaadf501f388bf3"
            ],
            "layout": "IPY_MODEL_77998a592da847049bb85b53c9a47782"
          }
        },
        "5137de83145940fbaf53604933e637bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a3c35260b34e43a8e68fb1a5e2c57f",
            "placeholder": "​",
            "style": "IPY_MODEL_a6fdbbaeb5224fbba7ae447c9bd643d2",
            "value": "Downloading: 100%"
          }
        },
        "e18ceeb6a05a4bbab9eaaf0c74242443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da08b6286ce045098ae176f3ed700a1c",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e280657777dc4b51adc72a693fbb8050",
            "value": 481
          }
        },
        "931c7ab1c5cb4987bbaadf501f388bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_716f4b70e28745b98c184f555060bb0b",
            "placeholder": "​",
            "style": "IPY_MODEL_6eced96b889240f98b5699d5a100165f",
            "value": " 481/481 [00:00&lt;00:00, 18.1kB/s]"
          }
        },
        "77998a592da847049bb85b53c9a47782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a3c35260b34e43a8e68fb1a5e2c57f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fdbbaeb5224fbba7ae447c9bd643d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da08b6286ce045098ae176f3ed700a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e280657777dc4b51adc72a693fbb8050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "716f4b70e28745b98c184f555060bb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eced96b889240f98b5699d5a100165f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34da5cead73e434394701e120a4e3b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adebee4e6a1b44059e7530437fdba9b3",
              "IPY_MODEL_8284b17a48684abaac99a5c64b577a72",
              "IPY_MODEL_2ba9f45834704bb5b66882d65a54b245"
            ],
            "layout": "IPY_MODEL_5022cb3ebc924525b2b3e321eddb5a28"
          }
        },
        "adebee4e6a1b44059e7530437fdba9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a145c253d942ffaac58ca6b52c9881",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8166a003fd401bb6eedd0c8c71aa22",
            "value": "Downloading: 100%"
          }
        },
        "8284b17a48684abaac99a5c64b577a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f87e4ab8098847ee9d931c109e4de6bb",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35df10161c924025b9528c43b5a59f19",
            "value": 501200538
          }
        },
        "2ba9f45834704bb5b66882d65a54b245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c842e7ed8d4fcd94230c4829700e34",
            "placeholder": "​",
            "style": "IPY_MODEL_b18b3cdf6e2d498cb062d9a134f11dee",
            "value": " 478M/478M [00:07&lt;00:00, 70.9MB/s]"
          }
        },
        "5022cb3ebc924525b2b3e321eddb5a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a145c253d942ffaac58ca6b52c9881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8166a003fd401bb6eedd0c8c71aa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f87e4ab8098847ee9d931c109e4de6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35df10161c924025b9528c43b5a59f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13c842e7ed8d4fcd94230c4829700e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18b3cdf6e2d498cb062d9a134f11dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/arxiv-alignment-paper-notifier/blob/main/notebooks/arxiv_alignment_dataset_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmenting Number of Alignment Papers in the Dataset\n",
        "\n",
        "This notebook fine-tunes a language model to classify arxiv paper summaries as alignment paper vs not alignment paper.\n",
        "\n",
        "## Installations"
      ],
      "metadata": {
        "id": "CyOjyF6FeL0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aH8ifayeAfK",
        "outputId": "ed4ef22f-1595-44ec-97e8-bc47eebbbad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 20 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81 kB 3.6 MB/s \n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers wandb jsonlines arxiv -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "HCjqbq62foj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import wandb\n",
        "import wandb\n",
        "\n",
        "# Login with your authentication key\n",
        "wandb.login()\n",
        "\n",
        "# setup wandb environment variables\n",
        "%env WANDB_ENTITY=jacquesthibs\n",
        "%env WANDB_PROJECT=accelerating-alignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "tgDlqcvTfntN",
        "outputId": "f2123686-5855-4342-d8de-e7becd5ed3f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_ENTITY=jacquesthibs\n",
            "env: WANDB_PROJECT=accelerating-alignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDSdQf_egJHP",
        "outputId": "f20883ed-df9d-48fa-a90c-c64f6a17b86d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf2H8Vfqle45",
        "outputId": "4e7dd725-c4d4-4137-eba3-4f3d0469f749"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import os\n",
        "import arxiv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rYT9XDXTlpQW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2c62618e41bc42aba761b58896ed19fa",
            "5978b5aceb4e4d59bbdc30649b3f562c",
            "2317af9b56b941cc9ea5ff9ff3eea713",
            "fca80cf567814eb2b6a12b120c777d5d",
            "d15b349a4def4d32854373a7a1edb63d",
            "d344c65b3fb845549e2fd5f7510ef4fa",
            "51d75420be0e417d86541e0dee784a86",
            "e43d8171b30a44a6abdb9a7ed19bedcc",
            "caabe2ef1bbd4ab1aada130d53bac5cd",
            "09148b698a6c4ed9935adfb5a0778c46",
            "6be5244099a848a1b08cb24aaee04c30",
            "64b7cc6c27a94fb7bd3d454520bafe4d",
            "b9dcd6c69384485f82813f28e5312a55",
            "2f757abafc5b4007b03896756fa48514",
            "1567b8ff089243b0ba5882b5c394e36b",
            "698826e8d03b426181672c76926119b5",
            "75b26e7d6c304abe9c236f348ccaa411",
            "10f87684db4d43f9a2a06eaf43f9d887",
            "64f553aabb1e4c918207a6c0697b9a1f",
            "94d33b2c5f1246ba86a66a181026cd7f",
            "b95224d4e4c84468abb17a7d6aa62a2f",
            "582885c9a2534a69bc2c101eb8b21f1f",
            "c4b05e49705a4f6c8f2e3cd3babde227",
            "5263a323046d4b5eb3422b4d7c0aa4b0",
            "6cd595156eeb4fe883651cb3fbf63a2d",
            "4b259a2cfa144ad6aa012e3f6ac0db1a",
            "0a4df9e1d5de43b3a6bc4f5f2d06cbec",
            "7195055329f144f2999c2b0fa9f36386",
            "69f525cad91843b8becb3beaf0091233",
            "30ceff7d79494dfa8c4ca678f988aa5f",
            "a2e40ac64cd94a1fa25b81ee71d2a596",
            "f10910e67e344ac9adb08d36e84d2120",
            "926f541a620040d9a72e8d6dd688e2c0",
            "f1e5a54f060d4a49b19959f755721d42",
            "5137de83145940fbaf53604933e637bd",
            "e18ceeb6a05a4bbab9eaaf0c74242443",
            "931c7ab1c5cb4987bbaadf501f388bf3",
            "77998a592da847049bb85b53c9a47782",
            "d9a3c35260b34e43a8e68fb1a5e2c57f",
            "a6fdbbaeb5224fbba7ae447c9bd643d2",
            "da08b6286ce045098ae176f3ed700a1c",
            "e280657777dc4b51adc72a693fbb8050",
            "716f4b70e28745b98c184f555060bb0b",
            "6eced96b889240f98b5699d5a100165f"
          ]
        },
        "id": "ReGJds3DEDuH",
        "outputId": "64602ffd-c1ca-4315-ef67-b3d75306aabd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c62618e41bc42aba761b58896ed19fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64b7cc6c27a94fb7bd3d454520bafe4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b05e49705a4f6c8f2e3cd3babde227"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1e5a54f060d4a49b19959f755721d42"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataset"
      ],
      "metadata": {
        "id": "D9iTOIfDlxbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alignment Forum"
      ],
      "metadata": {
        "id": "wzIalYJ8l9I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "af = {}\n",
        "i = 0\n",
        "with jsonlines.open('data/ai-alignment-dataset/uber-file.jsonl') as reader:\n",
        "    for obj in reader:\n",
        "        try:\n",
        "            if obj['source'] == 'alignment forum':\n",
        "                af[i] = obj\n",
        "                i += 1\n",
        "        except KeyError:\n",
        "            pass"
      ],
      "metadata": {
        "id": "3oxgur6klwNp"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "top_af = {}\n",
        "for k in af.keys():\n",
        "    if int(af[k]['score']) > 20:\n",
        "        top_af[i] = {}\n",
        "        top_af[i]['text'] = af[k]['text']\n",
        "        top_af[i]['alignment_text'] = 'pos'\n",
        "        i += 1\n",
        "        \n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9FFPNWHxdY_",
        "outputId": "6bbdcd92-c5ff-4d83-bed2-3926c7f2b3a0"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(top_af)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfRMQnmhhdtI",
        "outputId": "2fa93f22-3a60-4d6e-d20a-7715ac3a4673"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1123"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af_intro_texts = {}\n",
        "\n",
        "for i in top_af.keys():\n",
        "    af_intro_texts[i] = {}\n",
        "    text = top_af[i]['text'].replace('\\n', ' ')\n",
        "    text = tokenizer.decode(tokenizer(text, truncation=True)['input_ids'])\n",
        "    af_intro_texts[i]['text'] = text"
      ],
      "metadata": {
        "id": "S3wIWlly4YlV"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(af_intro_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpzbIcvR4YrS",
        "outputId": "32ea961a-7048-4313-f180-5928b3c0e537"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1123"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elicit"
      ],
      "metadata": {
        "id": "d2bs1wn-l3YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data/ai-alignment-dataset/\n",
        "!mkdir alignment_text_classifier\n",
        "%cd alignment_text_classifier\n",
        "!mkdir pos neg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilrzdwKZ4YxD",
        "outputId": "faa49276-16eb-499f-b103-3a1e8b464eed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/ai-alignment-dataset\n",
            "mkdir: cannot create directory ‘alignment_text_classifier’: File exists\n",
            "/content/drive/MyDrive/data/ai-alignment-dataset/alignment_text_classifier\n",
            "mkdir: cannot create directory ‘pos’: File exists\n",
            "mkdir: cannot create directory ‘neg’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('elicit-results.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "REy8tlw94Yt4",
        "outputId": "97554dec-f4a5-42cc-d0f8-41f651b173d3"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Index  Starred                                              Title  \\\n",
              "0      1     True              Incorrigibility in the CIRL Framework   \n",
              "1      2     True  Artificial Intelligence Safety and Cybersecuri...   \n",
              "2      3     True  AI Paradigms and AI Safety: Mapping Artefacts ...   \n",
              "3      4     True  Suffering-focused AI safety: Why \"fail-safe'\" ...   \n",
              "4      5     True  AI Research Considerations for Human Existenti...   \n",
              "\n",
              "   Publication Year                                             Author  \\\n",
              "0            2018.0                                        Carey, Ryan   \n",
              "1            2016.0          Yampolskiy, Roman V.; Spellchecker, M. S.   \n",
              "2            2020.0  Hernandez-Orallo, Jose; Martınez-Plumed, Ferna...   \n",
              "3            2016.0                                       Gloor, Lukas   \n",
              "4            2020.0                     Critch, Andrew; Krueger, David   \n",
              "\n",
              "                               Url  \\\n",
              "0  http://arxiv.org/abs/1709.06275   \n",
              "1  http://arxiv.org/abs/1610.07997   \n",
              "2                              NaN   \n",
              "3                              NaN   \n",
              "4                              NaN   \n",
              "\n",
              "                                       Abstract Note            Manual Tags  \\\n",
              "0  A value learning system has incentives to foll...  MIRI; FHI; TechSafety   \n",
              "1  In this work, we present and analyze reported ...  Other-org; MetaSafety   \n",
              "2  AI safety often analyses a risk or safety issu...  CSER; TechSafety; CFI   \n",
              "3  AI-safety eﬀorts focused on suﬀering reduction...        MetaSafety; CLR   \n",
              "4  Framed in positive terms, this report examines...       TechSafety; CHAI   \n",
              "\n",
              "                                      Automatic Tags  \n",
              "0  Computer Science - Artificial Intelligence; ai...  \n",
              "1  Computer Science - Artificial Intelligence; Co...  \n",
              "2                                                NaN  \n",
              "3                                                NaN  \n",
              "4                                                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb3f91bc-d2d8-46d7-84bf-3ac146ae4371\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Starred</th>\n",
              "      <th>Title</th>\n",
              "      <th>Publication Year</th>\n",
              "      <th>Author</th>\n",
              "      <th>Url</th>\n",
              "      <th>Abstract Note</th>\n",
              "      <th>Manual Tags</th>\n",
              "      <th>Automatic Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>Incorrigibility in the CIRL Framework</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>Carey, Ryan</td>\n",
              "      <td>http://arxiv.org/abs/1709.06275</td>\n",
              "      <td>A value learning system has incentives to foll...</td>\n",
              "      <td>MIRI; FHI; TechSafety</td>\n",
              "      <td>Computer Science - Artificial Intelligence; ai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>Artificial Intelligence Safety and Cybersecuri...</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Yampolskiy, Roman V.; Spellchecker, M. S.</td>\n",
              "      <td>http://arxiv.org/abs/1610.07997</td>\n",
              "      <td>In this work, we present and analyze reported ...</td>\n",
              "      <td>Other-org; MetaSafety</td>\n",
              "      <td>Computer Science - Artificial Intelligence; Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>AI Paradigms and AI Safety: Mapping Artefacts ...</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>Hernandez-Orallo, Jose; Martınez-Plumed, Ferna...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AI safety often analyses a risk or safety issu...</td>\n",
              "      <td>CSER; TechSafety; CFI</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>Suffering-focused AI safety: Why \"fail-safe'\" ...</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Gloor, Lukas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AI-safety eﬀorts focused on suﬀering reduction...</td>\n",
              "      <td>MetaSafety; CLR</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>AI Research Considerations for Human Existenti...</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>Critch, Andrew; Krueger, David</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Framed in positive terms, this report examines...</td>\n",
              "      <td>TechSafety; CHAI</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb3f91bc-d2d8-46d7-84bf-3ac146ae4371')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb3f91bc-d2d8-46d7-84bf-3ac146ae4371 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb3f91bc-d2d8-46d7-84bf-3ac146ae4371');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('abstract_ds.json'):\n",
        "    with open('abstract_ds.json') as f:\n",
        "        abstract_ds = json.load(f)\n",
        "else:\n",
        "    abstract_ds = {}"
      ],
      "metadata": {
        "id": "K0iNlbMcV-mr"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "kbj-Kw-Cp4ZG"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not pd.isnull(df.loc[4]['Url']):\n",
        "    print('yes')"
      ],
      "metadata": {
        "id": "xySCeDEdnHxj"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "j = 0\n",
        "non_arxiv = {}\n",
        "for i in range(len(df)):\n",
        "    if not pd.isnull(df.loc[i]['Url']):\n",
        "        if 'arxiv' in df.iloc[i]['Url']:\n",
        "            pass\n",
        "            # id = str(df.iloc[i]['Url'].split('/')[-1].split('v')[0])\n",
        "            # print(id)\n",
        "            # abstract_ds[id] = {}\n",
        "            # abstract_ds[id]['alignment_text'] = 'pos'\n",
        "            # abstract_ds[id]['text'] = \"Title: \" + df.iloc[i]['Title'] + \"\\n\" + \"Abstract: \" + df.iloc[i]['Abstract Note'].replace(\"\\n\", \" \")\n",
        "        else:\n",
        "            non_arxiv[str(j)] = {}\n",
        "            non_arxiv[str(j)]['alignment_text'] = 'pos'\n",
        "            non_arxiv[str(j)]['text'] = \"Title: \" + df.iloc[i]['Title'] + \"\\n\" + \"Abstract: \" + df.iloc[i]['Abstract Note'].replace(\"\\n\", \" \")\n",
        "            j += 1\n"
      ],
      "metadata": {
        "id": "C1VZ4aWVman8"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(abstract_ds))\n",
        "print(len(non_arxiv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQ4bEPWpTst",
        "outputId": "250045e6-5e1a-4c57-be0b-ec2c13981293"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1059\n",
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for k in abstract_ds.keys():\n",
        "    if abstract_ds[k]['alignment_text'] == 'neg':\n",
        "        counter += 1\n",
        "\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5jwMDNkrb-v",
        "outputId": "57c5ba3f-5435-40d1-c79d-184e2bb12a82"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arxiv"
      ],
      "metadata": {
        "id": "_4DMsFqP4Y4s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "sTQ2TZuFEcGO"
      },
      "outputs": [],
      "source": [
        "search = arxiv.Search(\n",
        "    query=\"ai capabilities\",\n",
        "    max_results=300, #float('inf'),\n",
        "    sort_by = arxiv.SortCriterion.Relevance\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usnOl1JHGpZH",
        "outputId": "0b7dee8b-d02f-4d6f-bcef-c39046c51f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "URL: http://arxiv.org/pdf/1905.01023v1 \n",
            "\n",
            "\n",
            "74\n",
            "cs\n",
            "Title: The Windfall Clause: Distributing the Benefits of AI for the Common Good \n",
            "Authors: Cullen O'Keefe, Peter Cihon, Ben Garfinkel, Carrick Flynn, Jade Leung, Allan Dafoe \n",
            "Date: 2019-12-25 05:30:40+00:00 \n",
            "Id: 1912.11595 \n",
            "Summary: As the transformative potential of AI has become increasingly salient as a\n",
            "matter of public and political interest, there has been growing discussion\n",
            "about the need to ensure that AI broadly benefits humanity. This in turn has\n",
            "spurred debate on the social responsibilities of large technology companies to\n",
            "serve the interests of society at large. In response, ethical principles and\n",
            "codes of conduct have been proposed to meet the escalating demand for this\n",
            "responsibility to be taken seriously. As yet, however, few institutional\n",
            "innovations have been suggested to translate this responsibility into legal\n",
            "commitments which apply to companies positioned to reap large financial gains\n",
            "from the development and use of AI. This paper offers one potentially\n",
            "attractive tool for addressing such issues: the Windfall Clause, which is an ex\n",
            "ante commitment by AI firms to donate a significant amount of any eventual\n",
            "extremely large profits. By this we mean an early commitment that profits that\n",
            "a firm could not earn without achieving fundamental, economically\n",
            "transformative breakthroughs in AI capabilities will be donated to benefit\n",
            "humanity broadly, with particular attention towards mitigating any downsides\n",
            "from deployment of windfall-generating AI. \n",
            "URL: http://arxiv.org/pdf/1912.11595v2 \n",
            "\n",
            "\n",
            "75\n",
            "cs\n",
            "Title: Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals \n",
            "Authors: Kathrin Blagec, Jakob Kraiger, Wolfgang Frühwirt, Matthias Samwald \n",
            "Date: 2022-01-18 15:05:28+00:00 \n",
            "Id: 2201.07040 \n",
            "Summary: Publicly accessible benchmarks that allow for assessing and comparing model\n",
            "performances are important drivers of progress in artificial intelligence (AI).\n",
            "While recent advances in AI capabilities hold the potential to transform\n",
            "medical practice by assisting and augmenting the cognitive processes of\n",
            "healthcare professionals, the coverage of clinically relevant tasks by AI\n",
            "benchmarks is largely unclear. Furthermore, there is a lack of systematized\n",
            "meta-information that allows clinical AI researchers to quickly determine\n",
            "accessibility, scope, content and other characteristics of datasets and\n",
            "benchmark datasets relevant to the clinical domain.\n",
            "  To address these issues, we curated and released a comprehensive catalogue of\n",
            "datasets and benchmarks pertaining to the broad domain of clinical and\n",
            "biomedical natural language processing (NLP), based on a systematic review of\n",
            "literature and online resources. A total of 450 NLP datasets were manually\n",
            "systematized and annotated with rich metadata, such as targeted tasks, clinical\n",
            "applicability, data types, performance metrics, accessibility and licensing\n",
            "information, and availability of data splits. We then compared tasks covered by\n",
            "AI benchmark datasets with relevant tasks that medical practitioners reported\n",
            "as highly desirable targets for automation in a previous empirical study.\n",
            "  Our analysis indicates that AI benchmarks of direct clinical relevance are\n",
            "scarce and fail to cover most work activities that clinicians want to see\n",
            "addressed. In particular, tasks associated with routine documentation and\n",
            "patient data administration workflows are not represented despite significant\n",
            "associated workloads. Thus, currently available AI benchmarks are improperly\n",
            "aligned with desired targets for AI automation in clinical settings, and novel\n",
            "benchmarks should be created to fill these gaps. \n",
            "URL: http://arxiv.org/pdf/2201.07040v2 \n",
            "\n",
            "\n",
            "76\n",
            "cs\n",
            "Title: Data-Centric Green AI: An Exploratory Empirical Study \n",
            "Authors: Roberto Verdecchia, Luís Cruz, June Sallou, Michelle Lin, James Wickenden, Estelle Hotellier \n",
            "Date: 2022-04-06 12:22:43+00:00 \n",
            "Id: 2204.02766 \n",
            "Summary: With the growing availability of large-scale datasets, and the popularization\n",
            "of affordable storage and computational capabilities, the energy consumed by AI\n",
            "is becoming a growing concern. To address this issue, in recent years, studies\n",
            "have focused on demonstrating how AI energy efficiency can be improved by\n",
            "tuning the model training strategy. Nevertheless, how modifications applied to\n",
            "datasets can impact the energy consumption of AI is still an open question. To\n",
            "fill this gap, in this exploratory study, we evaluate if data-centric\n",
            "approaches can be utilized to improve AI energy efficiency. To achieve our\n",
            "goal, we conduct an empirical experiment, executed by considering 6 different\n",
            "AI algorithms, a dataset comprising 5,574 data points, and two dataset\n",
            "modifications (number of data points and number of features). Our results show\n",
            "evidence that, by exclusively conducting modifications on datasets, energy\n",
            "consumption can be drastically reduced (up to 92.16%), often at the cost of a\n",
            "negligible or even absent accuracy decline. As additional introductory results,\n",
            "we demonstrate how, by exclusively changing the algorithm used, energy savings\n",
            "up to two orders of magnitude can be achieved. In conclusion, this exploratory\n",
            "investigation empirically demonstrates the importance of applying data-centric\n",
            "techniques to improve AI energy efficiency. Our results call for a research\n",
            "agenda that focuses on data-centric techniques, to further enable and\n",
            "democratize Green AI. \n",
            "URL: http://arxiv.org/pdf/2204.02766v2 \n",
            "\n",
            "\n",
            "78\n",
            "cs\n",
            "Title: Guidelines for Artificial Intelligence Containment \n",
            "Authors: James Babcock, Janos Kramar, Roman V. Yampolskiy \n",
            "Date: 2017-07-24 18:33:18+00:00 \n",
            "Id: 1707.08476 \n",
            "Summary: With almost daily improvements in capabilities of artificial intelligence it\n",
            "is more important than ever to develop safety software for use by the AI\n",
            "research community. Building on our previous work on AI Containment Problem we\n",
            "propose a number of guidelines which should help AI safety researchers to\n",
            "develop reliable sandboxing software for intelligent programs of all levels.\n",
            "Such safety container software will make it possible to study and analyze\n",
            "intelligent artificial agent while maintaining certain level of safety against\n",
            "information leakage, social engineering attacks and cyberattacks from within\n",
            "the container. \n",
            "URL: http://arxiv.org/pdf/1707.08476v1 \n",
            "\n",
            "\n",
            "79\n",
            "cs\n",
            "Title: FutureMapping: The Computational Structure of Spatial AI Systems \n",
            "Authors: Andrew J. Davison \n",
            "Date: 2018-03-29 23:46:34+00:00 \n",
            "Id: 1803.11288 \n",
            "Summary: We discuss and predict the evolution of Simultaneous Localisation and Mapping\n",
            "(SLAM) into a general geometric and semantic `Spatial AI' perception capability\n",
            "for intelligent embodied devices. A big gap remains between the visual\n",
            "perception performance that devices such as augmented reality eyewear or\n",
            "comsumer robots will require and what is possible within the constraints\n",
            "imposed by real products. Co-design of algorithms, processors and sensors will\n",
            "be needed. We explore the computational structure of current and future Spatial\n",
            "AI algorithms and consider this within the landscape of ongoing hardware\n",
            "developments. \n",
            "URL: http://arxiv.org/pdf/1803.11288v1 \n",
            "\n",
            "\n",
            "81\n",
            "cs\n",
            "Title: Follow Pedro! An Infrared-based Person-Follower using Nonlinear Optimization \n",
            "Authors: Pedro Pena, Toffee Albina \n",
            "Date: 2019-12-14 12:56:02+00:00 \n",
            "Id: 1912.06837 \n",
            "Summary: We used ROS2 as a platform to conduct AI research for developing a Follow-Me\n",
            "capability as a proof-of-concept on a wheeled robot, demonstrating that AI\n",
            "research is possible in the ROS2 framework. We developed a complete system that\n",
            "uses perception and navigation components based on a sensor suite of fisheye\n",
            "cameras, lidar, and IMU running on an ARM64 Embedded Linux platform that runs\n",
            "ROS2 natively. The perception package detects AR markers and/or IR beacons to\n",
            "track a person. The tracker uses AI algorithms such as particle filters and\n",
            "nonlinear optimization to extract the SE(3) information of the 2D feature. \n",
            "URL: http://arxiv.org/pdf/1912.06837v1 \n",
            "\n",
            "\n",
            "83\n",
            "cs\n",
            "Title: Explanation Ontology: A Model of Explanations for User-Centered AI \n",
            "Authors: Shruthi Chari, Oshani Seneviratne, Daniel M. Gruen, Morgan A. Foreman, Amar K. Das, Deborah L. McGuinness \n",
            "Date: 2020-10-04 03:53:35+00:00 \n",
            "Id: 2010.01479 \n",
            "Summary: Explainability has been a goal for Artificial Intelligence (AI) systems since\n",
            "their conception, with the need for explainability growing as more complex AI\n",
            "models are increasingly used in critical, high-stakes settings such as\n",
            "healthcare. Explanations have often added to an AI system in a non-principled,\n",
            "post-hoc manner. With greater adoption of these systems and emphasis on\n",
            "user-centric explainability, there is a need for a structured representation\n",
            "that treats explainability as a primary consideration, mapping end user needs\n",
            "to specific explanation types and the system's AI capabilities. We design an\n",
            "explanation ontology to model both the role of explanations, accounting for the\n",
            "system and user attributes in the process, and the range of different\n",
            "literature-derived explanation types. We indicate how the ontology can support\n",
            "user requirements for explanations in the domain of healthcare. We evaluate our\n",
            "ontology with a set of competency questions geared towards a system designer\n",
            "who might use our ontology to decide which explanation types to include, given\n",
            "a combination of users' needs and a system's capabilities, both in system\n",
            "design settings and in real-time operations. Through the use of this ontology,\n",
            "system designers will be able to make informed choices on which explanations AI\n",
            "systems can and should provide. \n",
            "URL: http://arxiv.org/pdf/2010.01479v1 \n",
            "\n",
            "\n",
            "85\n",
            "cs\n",
            "Title: Thinking Fast and Slow in AI: the Role of Metacognition \n",
            "Authors: Marianna Bergamaschi Ganapini, Murray Campbell, Francesco Fabiano, Lior Horesh, Jon Lenchner, Andrea Loreggia, Nicholas Mattei, Francesca Rossi, Biplav Srivastava, Kristen Brent Venable \n",
            "Date: 2021-10-05 06:05:38+00:00 \n",
            "Id: 2110.01834 \n",
            "Summary: AI systems have seen dramatic advancement in recent years, bringing many\n",
            "applications that pervade our everyday life. However, we are still mostly\n",
            "seeing instances of narrow AI: many of these recent developments are typically\n",
            "focused on a very limited set of competencies and goals, e.g., image\n",
            "interpretation, natural language processing, classification, prediction, and\n",
            "many others. Moreover, while these successes can be accredited to improved\n",
            "algorithms and techniques, they are also tightly linked to the availability of\n",
            "huge datasets and computational power. State-of-the-art AI still lacks many\n",
            "capabilities that would naturally be included in a notion of (human)\n",
            "intelligence.\n",
            "  We argue that a better study of the mechanisms that allow humans to have\n",
            "these capabilities can help us understand how to imbue AI systems with these\n",
            "competencies. We focus especially on D. Kahneman's theory of thinking fast and\n",
            "slow, and we propose a multi-agent AI architecture where incoming problems are\n",
            "solved by either system 1 (or \"fast\") agents, that react by exploiting only\n",
            "past experience, or by system 2 (or \"slow\") agents, that are deliberately\n",
            "activated when there is the need to reason and search for optimal solutions\n",
            "beyond what is expected from the system 1 agent. Both kinds of agents are\n",
            "supported by a model of the world, containing domain knowledge about the\n",
            "environment, and a model of \"self\", containing information about past actions\n",
            "of the system and solvers' skills. \n",
            "URL: http://arxiv.org/pdf/2110.01834v1 \n",
            "\n",
            "\n",
            "86\n",
            "cs\n",
            "Title: A Cognitive Framework for Delegation Between Error-Prone AI and Human Agents \n",
            "Authors: Andrew Fuchs, Andrea Passarella, Marco Conti \n",
            "Date: 2022-04-06 15:15:21+00:00 \n",
            "Id: 2204.02889 \n",
            "Summary: With humans interacting with AI-based systems at an increasing rate, it is\n",
            "necessary to ensure the artificial systems are acting in a manner which\n",
            "reflects understanding of the human. In the case of humans and artificial AI\n",
            "agents operating in the same environment, we note the significance of\n",
            "comprehension and response to the actions or capabilities of a human from an\n",
            "agent's perspective, as well as the possibility to delegate decisions either to\n",
            "humans or to agents, depending on who is deemed more suitable at a certain\n",
            "point in time. Such capabilities will ensure an improved responsiveness and\n",
            "utility of the entire human-AI system. To that end, we investigate the use of\n",
            "cognitively inspired models of behavior to predict the behavior of both human\n",
            "and AI agents. The predicted behavior, and associated performance with respect\n",
            "to a certain goal, is used to delegate control between humans and AI agents\n",
            "through the use of an intermediary entity. As we demonstrate, this allows\n",
            "overcoming potential shortcomings of either humans or agents in the pursuit of\n",
            "a goal. \n",
            "URL: http://arxiv.org/pdf/2204.02889v2 \n",
            "\n",
            "\n",
            "87\n",
            "cs\n",
            "Title: Artificial Intelligence and its Role in Near Future \n",
            "Authors: Jahanzaib Shabbir, Tarique Anwer \n",
            "Date: 2018-04-01 23:12:30+00:00 \n",
            "Id: 1804.01396 \n",
            "Summary: AI technology has a long history which is actively and constantly changing\n",
            "and growing. It focuses on intelligent agents, which contain devices that\n",
            "perceive the environment and based on which takes actions in order to maximize\n",
            "goal success chances. In this paper, we will explain the modern AI basics and\n",
            "various representative applications of AI. In the context of the modern\n",
            "digitalized world, AI is the property of machines, computer programs, and\n",
            "systems to perform the intellectual and creative functions of a person,\n",
            "independently find ways to solve problems, be able to draw conclusions and make\n",
            "decisions. Most artificial intelligence systems have the ability to learn,\n",
            "which allows people to improve their performance over time. The recent research\n",
            "on AI tools, including machine learning, deep learning and predictive analysis\n",
            "intended toward increasing the planning, learning, reasoning, thinking and\n",
            "action taking ability. Based on which, the proposed research intends towards\n",
            "exploring on how the human intelligence differs from the artificial\n",
            "intelligence. Moreover, we critically analyze what AI of today is capable of\n",
            "doing, why it still cannot reach human intelligence and what are the open\n",
            "challenges existing in front of AI to reach and outperform human level of\n",
            "intelligence. Furthermore, it will explore the future predictions for\n",
            "artificial intelligence and based on which potential solution will be\n",
            "recommended to solve it within next decades. \n",
            "URL: http://arxiv.org/pdf/1804.01396v1 \n",
            "\n",
            "\n",
            "88\n",
            "cs\n",
            "Title: Conceptual Modeling and Artificial Intelligence: Mutual Benefits from Complementary Worlds \n",
            "Authors: Dominik Bork \n",
            "Date: 2021-10-16 18:42:09+00:00 \n",
            "Id: 2110.08637 \n",
            "Summary: Conceptual modeling (CM) applies abstraction to reduce the complexity of a\n",
            "system under study (e.g., an excerpt of reality). As a result of the conceptual\n",
            "modeling process a human interpretable, formalized representation (i.e., a\n",
            "conceptual model) is derived which enables understanding and communication\n",
            "among humans, and processing by machines. Artificial Intelligence (AI)\n",
            "algorithms are also applied to complex realities (regularly represented by vast\n",
            "amounts of data) to identify patterns or to classify entities in the data.\n",
            "Aside from the commonalities of both approaches, a significant difference can\n",
            "be observed by looking at the results. While conceptual models are\n",
            "comprehensible, reproducible, and explicit knowledge representations, AI\n",
            "techniques are capable of efficiently deriving an output from a given input\n",
            "while acting as a black box. AI solutions often lack comprehensiveness and\n",
            "reproducibility. Even the developers of AI systems can't explain why a certain\n",
            "output is derived. In the Conceptual Modeling meets Artificial Intelligence\n",
            "(CMAI) workshop, we are interested in tackling the intersection of the two,\n",
            "thus far, mostly isolated approached disciplines of CM and AI. The workshop\n",
            "embraces the assumption, that manifold mutual benefits can be realized by i)\n",
            "investigating what Conceptual Modeling (CM) can contribute to AI, and ii) the\n",
            "other way around, what Artificial Intelligence (AI) can contribute to CM. \n",
            "URL: http://arxiv.org/pdf/2110.08637v1 \n",
            "\n",
            "\n",
            "89\n",
            "cs\n",
            "Title: Artificial Intelligence in Software Testing : Impact, Problems, Challenges and Prospect \n",
            "Authors: Zubair Khaliq, Sheikh Umar Farooq, Dawood Ashraf Khan \n",
            "Date: 2022-01-14 10:21:51+00:00 \n",
            "Id: 2201.05371 \n",
            "Summary: Artificial Intelligence (AI) is making a significant impact in multiple areas\n",
            "like medical, military, industrial, domestic, law, arts as AI is capable to\n",
            "perform several roles such as managing smart factories, driving autonomous\n",
            "vehicles, creating accurate weather forecasts, detecting cancer and personal\n",
            "assistants, etc. Software testing is the process of putting the software to\n",
            "test for some abnormal behaviour of the software. Software testing is a\n",
            "tedious, laborious and most time-consuming process. Automation tools have been\n",
            "developed that help to automate some activities of the testing process to\n",
            "enhance quality and timely delivery. Over time with the inclusion of continuous\n",
            "integration and continuous delivery (CI/CD) pipeline, automation tools are\n",
            "becoming less effective. The testing community is turning to AI to fill the gap\n",
            "as AI is able to check the code for bugs and errors without any human\n",
            "intervention and in a much faster way than humans. In this study, we aim to\n",
            "recognize the impact of AI technologies on various software testing activities\n",
            "or facets in the STLC. Further, the study aims to recognize and explain some of\n",
            "the biggest challenges software testers face while applying AI to testing. The\n",
            "paper also proposes some key contributions of AI in the future to the domain of\n",
            "software testing. \n",
            "URL: http://arxiv.org/pdf/2201.05371v1 \n",
            "\n",
            "\n",
            "90\n",
            "cs\n",
            "Title: Building AI Innovation Labs together with Companies \n",
            "Authors: Jens Heidrich, Andreas Jedlitschka, Adam Trendowicz, Anna Maria Vollmer \n",
            "Date: 2022-03-16 08:45:52+00:00 \n",
            "Id: 2203.08465 \n",
            "Summary: In the future, most companies will be confronted with the topic of Artificial\n",
            "Intelligence (AI) and will have to decide on their strategy in this regards.\n",
            "Currently, a lot of companies are thinking about whether and how AI and the\n",
            "usage of data will impact their business model and what potential use cases\n",
            "could look like. One of the biggest challenges lies in coming up with\n",
            "innovative solution ideas with a clear business value. This requires business\n",
            "competencies on the one hand and technical competencies in AI and data\n",
            "analytics on the other hand. In this article, we present the concept of AI\n",
            "innovation labs and demonstrate a comprehensive framework, from coming up with\n",
            "the right ideas to incrementally implementing and evaluating them regarding\n",
            "their business value and their feasibility based on a company's capabilities.\n",
            "The concept is the result of nine years of working on data-driven innovations\n",
            "with companies from various domains. Furthermore, we share some lessons learned\n",
            "from its practical applications. Even though a lot of technical publications\n",
            "can be found in the literature regarding the development of AI models and many\n",
            "consultancy companies provide corresponding services for building AI\n",
            "innovations, we found very few publications sharing details about what an\n",
            "end-to-end framework could look like. \n",
            "URL: http://arxiv.org/pdf/2203.08465v1 \n",
            "\n",
            "\n",
            "91\n",
            "cs\n",
            "Title: Confidence Inference in Bayesian Networks \n",
            "Authors: Jian Cheng, Marek J. Druzdzel \n",
            "Date: 2013-01-10 16:22:53+00:00 \n",
            "Id: 1301.2260 \n",
            "Summary: We present two sampling algorithms for probabilistic confidence inference in\n",
            "Bayesian networks. These two algorithms (we call them AIS-BN-mu and\n",
            "AIS-BN-sigma algorithms) guarantee that estimates of posterior probabilities\n",
            "are with a given probability within a desired precision bound. Our algorithms\n",
            "are based on recent advances in sampling algorithms for (1) estimating the mean\n",
            "of bounded random variables and (2) adaptive importance sampling in Bayesian\n",
            "networks. In addition to a simple stopping rule for sampling that they provide,\n",
            "the AIS-BN-mu and AIS-BN-sigma algorithms are capable of guiding the learning\n",
            "process in the AIS-BN algorithm. An empirical evaluation of the proposed\n",
            "algorithms shows excellent performance, even for very unlikely evidence. \n",
            "URL: http://arxiv.org/pdf/1301.2260v1 \n",
            "\n",
            "\n",
            "92\n",
            "cs\n",
            "Title: Artificial Intelligence for the Public Sector: Opportunities and challenges of cross-sector collaboration \n",
            "Authors: Slava Jankin Mikhaylov, Marc Esteve, Averill Campion \n",
            "Date: 2018-09-12 13:12:07+00:00 \n",
            "Id: 1809.04399 \n",
            "Summary: Public sector organisations are increasingly interested in using data science\n",
            "and artificial intelligence capabilities to deliver policy and generate\n",
            "efficiencies in high uncertainty environments. The long-term success of data\n",
            "science and AI in the public sector relies on effectively embedding it into\n",
            "delivery solutions for policy implementation. However, governments cannot do\n",
            "this integration of AI into public service delivery on their own. The UK\n",
            "Government Industrial Strategy is clear that delivering on the AI grand\n",
            "challenge requires collaboration between universities and public and private\n",
            "sectors. This cross-sectoral collaborative approach is the norm in applied AI\n",
            "centres of excellence around the world. Despite their popularity, cross-sector\n",
            "collaborations entail serious management challenges that hinder their success.\n",
            "In this article we discuss the opportunities and challenges from AI for public\n",
            "sector. Finally, we propose a series of strategies to successfully manage these\n",
            "cross-sectoral collaborations. \n",
            "URL: http://arxiv.org/pdf/1809.04399v1 \n",
            "\n",
            "\n",
            "93\n",
            "cs\n",
            "Title: Challenges for an Ontology of Artificial Intelligence \n",
            "Authors: Scott H. Hawley \n",
            "Date: 2019-02-25 19:30:56+00:00 \n",
            "Id: 1903.03171 \n",
            "Summary: Of primary importance in formulating a response to the increasing prevalence\n",
            "and power of artificial intelligence (AI) applications in society are questions\n",
            "of ontology. Questions such as: What \"are\" these systems? How are they to be\n",
            "regarded? How does an algorithm come to be regarded as an agent? We discuss\n",
            "three factors which hinder discussion and obscure attempts to form a clear\n",
            "ontology of AI: (1) the various and evolving definitions of AI, (2) the\n",
            "tendency for pre-existing technologies to be assimilated and regarded as\n",
            "\"normal,\" and (3) the tendency of human beings to anthropomorphize. This list\n",
            "is not intended as exhaustive, nor is it seen to preclude entirely a clear\n",
            "ontology, however, these challenges are a necessary set of topics for\n",
            "consideration. Each of these factors is seen to present a 'moving target' for\n",
            "discussion, which poses a challenge for both technical specialists and\n",
            "non-practitioners of AI systems development (e.g., philosophers and\n",
            "theologians) to speak meaningfully given that the corpus of AI structures and\n",
            "capabilities evolves at a rapid pace. Finally, we present avenues for moving\n",
            "forward, including opportunities for collaborative synthesis for scholars in\n",
            "philosophy and science. \n",
            "URL: http://arxiv.org/pdf/1903.03171v1 \n",
            "\n",
            "\n",
            "94\n",
            "cs\n",
            "Title: AI Programmer: Autonomously Creating Software Programs Using Genetic Algorithms \n",
            "Authors: Kory Becker, Justin Gottschlich \n",
            "Date: 2017-09-17 18:17:55+00:00 \n",
            "Id: 1709.05703 \n",
            "Summary: In this paper, we present the first-of-its-kind machine learning (ML) system,\n",
            "called AI Programmer, that can automatically generate full software programs\n",
            "requiring only minimal human guidance. At its core, AI Programmer uses genetic\n",
            "algorithms (GA) coupled with a tightly constrained programming language that\n",
            "minimizes the overhead of its ML search space. Part of AI Programmer's novelty\n",
            "stems from (i) its unique system design, including an embedded, hand-crafted\n",
            "interpreter for efficiency and security and (ii) its augmentation of GAs to\n",
            "include instruction-gene randomization bindings and programming\n",
            "language-specific genome construction and elimination techniques. We provide a\n",
            "detailed examination of AI Programmer's system design, several examples\n",
            "detailing how the system works, and experimental data demonstrating its\n",
            "software generation capabilities and performance using only mainstream CPUs. \n",
            "URL: http://arxiv.org/pdf/1709.05703v1 \n",
            "\n",
            "\n",
            "95\n",
            "cs\n",
            "Title: Beating humans in a penny-matching game by leveraging cognitive hierarchy theory and Bayesian learning \n",
            "Authors: Ran Tian, Nan Li, Ilya Kolmanovsky, Anouck Girard \n",
            "Date: 2019-09-27 14:16:50+00:00 \n",
            "Id: 1909.12701 \n",
            "Summary: It is a long-standing goal of artificial intelligence (AI) to be superior to\n",
            "human beings in decision making. Games are suitable for testing AI capabilities\n",
            "of making good decisions in non-numerical tasks. In this paper, we develop a\n",
            "new AI algorithm to play the penny-matching game considered in Shannon's\n",
            "\"mind-reading machine\" (1953) against human players. In particular, we exploit\n",
            "cognitive hierarchy theory and Bayesian learning techniques to continually\n",
            "evolve a model for predicting human player decisions, and let the AI player\n",
            "make decisions according to the model predictions to pursue the best chance of\n",
            "winning. Experimental results show that our AI algorithm beats 27 out of 30\n",
            "volunteer human players. \n",
            "URL: http://arxiv.org/pdf/1909.12701v3 \n",
            "\n",
            "\n",
            "96\n",
            "cs\n",
            "Title: AI Benchmark: All About Deep Learning on Smartphones in 2019 \n",
            "Authors: Andrey Ignatov, Radu Timofte, Andrei Kulik, Seungsoo Yang, Ke Wang, Felix Baum, Max Wu, Lirong Xu, Luc Van Gool \n",
            "Date: 2019-10-15 11:31:36+00:00 \n",
            "Id: 1910.06663 \n",
            "Summary: The performance of mobile AI accelerators has been evolving rapidly in the\n",
            "past two years, nearly doubling with each new generation of SoCs. The current\n",
            "4th generation of mobile NPUs is already approaching the results of\n",
            "CUDA-compatible Nvidia graphics cards presented not long ago, which together\n",
            "with the increased capabilities of mobile deep learning frameworks makes it\n",
            "possible to run complex and deep AI models on mobile devices. In this paper, we\n",
            "evaluate the performance and compare the results of all chipsets from Qualcomm,\n",
            "HiSilicon, Samsung, MediaTek and Unisoc that are providing hardware\n",
            "acceleration for AI inference. We also discuss the recent changes in the\n",
            "Android ML pipeline and provide an overview of the deployment of deep learning\n",
            "models on mobile devices. All numerical results provided in this paper can be\n",
            "found and are regularly updated on the official project website:\n",
            "http://ai-benchmark.com. \n",
            "URL: http://arxiv.org/pdf/1910.06663v1 \n",
            "\n",
            "\n",
            "97\n",
            "cs\n",
            "Title: Social and Governance Implications of Improved Data Efficiency \n",
            "Authors: Aaron D. Tucker, Markus Anderljung, Allan Dafoe \n",
            "Date: 2020-01-14 22:26:12+00:00 \n",
            "Id: 2001.05068 \n",
            "Summary: Many researchers work on improving the data efficiency of machine learning.\n",
            "What would happen if they succeed? This paper explores the social-economic\n",
            "impact of increased data efficiency. Specifically, we examine the intuition\n",
            "that data efficiency will erode the barriers to entry protecting incumbent\n",
            "data-rich AI firms, exposing them to more competition from data-poor firms. We\n",
            "find that this intuition is only partially correct: data efficiency makes it\n",
            "easier to create ML applications, but large AI firms may have more to gain from\n",
            "higher performing AI systems. Further, we find that the effect on privacy, data\n",
            "markets, robustness, and misuse are complex. For example, while it seems\n",
            "intuitive that misuse risk would increase along with data efficiency -- as more\n",
            "actors gain access to any level of capability -- the net effect crucially\n",
            "depends on how much defensive measures are improved. More investigation into\n",
            "data efficiency, as well as research into the \"AI production function\", will be\n",
            "key to understanding the development of the AI industry and its societal\n",
            "impacts. \n",
            "URL: http://arxiv.org/pdf/2001.05068v1 \n",
            "\n",
            "\n",
            "99\n",
            "cs\n",
            "Title: KubeEdge.AI: AI Platform for Edge Devices \n",
            "Authors: Sean Wang, Yuxiao Hu, Jason Wu \n",
            "Date: 2020-07-07 23:36:23+00:00 \n",
            "Id: 2007.09227 \n",
            "Summary: The demand for smartness in embedded systems has been mounting up drastically\n",
            "in the past few years. Embedded system today must address the fundamental\n",
            "challenges introduced by cloud computing and artificial intelligence. KubeEdge\n",
            "[1] is an edge computing framework build on top of Kubernetes [2]. It provides\n",
            "compute resource management, deployment, runtime and operation capabilities on\n",
            "geo-located edge computing resources, from the cloud, which is a natural fit\n",
            "for embedded systems. Here we propose KubeEdge.AI, an edge AI framework on top\n",
            "of KubeEdge. It provides a set of key modules and interfaces: a data handling\n",
            "and processing engine, a concise AI runtime, a decision engine, and a\n",
            "distributed data query interface. KubeEdge.AI will help reduce the burdens for\n",
            "developing specific edge/embedded AI systems and promote edge-cloud\n",
            "coordination and synergy. \n",
            "URL: http://arxiv.org/pdf/2007.09227v1 \n",
            "\n",
            "\n",
            "100\n",
            "cs\n",
            "Title: Neurosymbolic AI for Situated Language Understanding \n",
            "Authors: Nikhil Krishnaswamy, James Pustejovsky \n",
            "Date: 2020-12-05 05:03:28+00:00 \n",
            "Id: 2012.02947 \n",
            "Summary: In recent years, data-intensive AI, particularly the domain of natural\n",
            "language processing and understanding, has seen significant progress driven by\n",
            "the advent of large datasets and deep neural networks that have sidelined more\n",
            "classic AI approaches to the field. These systems can apparently demonstrate\n",
            "sophisticated linguistic understanding or generation capabilities, but often\n",
            "fail to transfer their skills to situations they have not encountered before.\n",
            "We argue that computational situated grounding provides a solution to some of\n",
            "these learning challenges by creating situational representations that both\n",
            "serve as a formal model of the salient phenomena, and contain rich amounts of\n",
            "exploitable, task-appropriate data for training new, flexible computational\n",
            "models. Our model reincorporates some ideas of classic AI into a framework of\n",
            "neurosymbolic intelligence, using multimodal contextual modeling of interactive\n",
            "situations, events, and object properties. We discuss how situated grounding\n",
            "provides diverse data and multiple levels of modeling for a variety of AI\n",
            "learning challenges, including learning how to interact with object\n",
            "affordances, learning semantics for novel structures and configurations, and\n",
            "transferring such learned knowledge to new objects and situations. \n",
            "URL: http://arxiv.org/pdf/2012.02947v1 \n",
            "\n",
            "\n",
            "101\n",
            "cs\n",
            "Title: Explainability via Interactivity? Supporting Nonexperts' Sensemaking of Pretrained CNN by Interacting with Their Daily Surroundings \n",
            "Authors: Chao Wang, Pengcheng An \n",
            "Date: 2021-05-31 19:22:53+00:00 \n",
            "Id: 2107.01996 \n",
            "Summary: Current research on Explainable AI (XAI) heavily targets on expert users\n",
            "(data scientists or AI developers). However, increasing importance has been\n",
            "argued for making AI more understandable to nonexperts, who are expected to\n",
            "leverage AI techniques, but have limited knowledge about AI. We present a\n",
            "mobile application to support nonexperts to interactively make sense of\n",
            "Convolutional Neural Networks (CNN); it allows users to play with a pretrained\n",
            "CNN by taking pictures of their surrounding objects. We use an up-to-date XAI\n",
            "technique (Class Activation Map) to intuitively visualize the model's decision\n",
            "(the most important image regions that lead to a certain result). Deployed in a\n",
            "university course, this playful learning tool was found to support design\n",
            "students to gain vivid understandings about the capabilities and limitations of\n",
            "pretrained CNNs in real-world environments. Concrete examples of students'\n",
            "playful explorations are reported to characterize their sensemaking processes\n",
            "reflecting different depths of thought. \n",
            "URL: http://arxiv.org/pdf/2107.01996v1 \n",
            "\n",
            "\n",
            "102\n",
            "cs\n",
            "Title: Toward AI Assistants That Let Designers Design \n",
            "Authors: Sebastiaan De Peuter, Antti Oulasvirta, Samuel Kaski \n",
            "Date: 2021-07-22 10:29:36+00:00 \n",
            "Id: 2107.13074 \n",
            "Summary: AI for supporting designers needs to be rethought. It should aim to\n",
            "cooperate, not automate, by supporting and leveraging the creativity and\n",
            "problem-solving of designers. The challenge for such AI is how to infer\n",
            "designers' goals and then help them without being needlessly disruptive. We\n",
            "present AI-assisted design: a framework for creating such AI, built around\n",
            "generative user models which enable reasoning about designers' goals,\n",
            "reasoning, and capabilities. \n",
            "URL: http://arxiv.org/pdf/2107.13074v1 \n",
            "\n",
            "\n",
            "104\n",
            "cs\n",
            "Title: Making AI 'Smart': Bridging AI and Cognitive Science \n",
            "Authors: Madhav Agarwal, Siddhant Bansal \n",
            "Date: 2021-12-31 09:30:44+00:00 \n",
            "Id: 2112.15360 \n",
            "Summary: The last two decades have seen tremendous advances in Artificial\n",
            "Intelligence. The exponential growth in terms of computation capabilities has\n",
            "given us hope of developing humans like robots. The question is: are we there\n",
            "yet? Maybe not. With the integration of cognitive science, the 'artificial'\n",
            "characteristic of Artificial Intelligence (AI) might soon be replaced with\n",
            "'smart'. This will help develop more powerful AI systems and simultaneously\n",
            "gives us a better understanding of how the human brain works. We discuss the\n",
            "various possibilities and challenges of bridging these two fields and how they\n",
            "can benefit each other. We argue that the possibility of AI taking over human\n",
            "civilization is low as developing such an advanced system requires a better\n",
            "understanding of the human brain first. \n",
            "URL: http://arxiv.org/pdf/2112.15360v2 \n",
            "\n",
            "\n",
            "105\n",
            "cs\n",
            "Title: Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support \n",
            "Authors: Anna Kawakami, Venkatesh Sivaraman, Hao-Fei Cheng, Logan Stapleton, Yanghuidi Cheng, Diana Qing, Adam Perer, Zhiwei Steven Wu, Haiyi Zhu, Kenneth Holstein \n",
            "Date: 2022-04-05 16:10:49+00:00 \n",
            "Id: 2204.02310 \n",
            "Summary: AI-based decision support tools (ADS) are increasingly used to augment human\n",
            "decision-making in high-stakes, social contexts. As public sector agencies\n",
            "begin to adopt ADS, it is critical that we understand workers' experiences with\n",
            "these systems in practice. In this paper, we present findings from a series of\n",
            "interviews and contextual inquiries at a child welfare agency, to understand\n",
            "how they currently make AI-assisted child maltreatment screening decisions.\n",
            "Overall, we observe how workers' reliance upon the ADS is guided by (1) their\n",
            "knowledge of rich, contextual information beyond what the AI model captures,\n",
            "(2) their beliefs about the ADS's capabilities and limitations relative to\n",
            "their own, (3) organizational pressures and incentives around the use of the\n",
            "ADS, and (4) awareness of misalignments between algorithmic predictions and\n",
            "their own decision-making objectives. Drawing upon these findings, we discuss\n",
            "design implications towards supporting more effective human-AI decision-making. \n",
            "URL: http://arxiv.org/pdf/2204.02310v1 \n",
            "\n",
            "\n",
            "106\n",
            "cs\n",
            "Title: Big Tech Companies Impact on Research at the Faculty of Information Technology and Electrical Engineering \n",
            "Authors: Ahmad Hassanpour, An Thi Nguyen, Anshul Rani, Sarang Shaikh, Ying Xu, Haoyu Zhang \n",
            "Date: 2022-04-10 12:28:08+00:00 \n",
            "Id: 2205.01039 \n",
            "Summary: Artificial intelligence is gaining momentum, ongoing pandemic is fuel to that\n",
            "with more opportunities in every sector specially in health and education\n",
            "sector. But with the growth in technology, challenges associated with ethics\n",
            "also grow (Katharine Schwab, 2021). Whenever a new AI product is developed,\n",
            "companies publicize that their systems are transparent, fair, and are in\n",
            "accordance with the existing laws and regulations as the methods and procedures\n",
            "followed by a big tech company for ensuring AI ethics, not only affect the\n",
            "trust and perception of public, but it also challenges the capabilities of the\n",
            "companies towards business strategies in different regions, and the kind of\n",
            "brains it can attract for their projects. AI Big Tech companies have influence\n",
            "over AI ethics as many influencing ethical-AI researchers have roots in Big\n",
            "Tech or its associated labs. \n",
            "URL: http://arxiv.org/pdf/2205.01039v1 \n",
            "\n",
            "\n",
            "107\n",
            "cs\n",
            "Title: Differential Assessment of Black-Box AI Agents \n",
            "Authors: Rashmeet Kaur Nayyar, Pulkit Verma, Siddharth Srivastava \n",
            "Date: 2022-03-24 17:48:58+00:00 \n",
            "Id: 2203.13236 \n",
            "Summary: Much of the research on learning symbolic models of AI agents focuses on\n",
            "agents with stationary models. This assumption fails to hold in settings where\n",
            "the agent's capabilities may change as a result of learning, adaptation, or\n",
            "other post-deployment modifications. Efficient assessment of agents in such\n",
            "settings is critical for learning the true capabilities of an AI system and for\n",
            "ensuring its safe usage. In this work, we propose a novel approach to\n",
            "\"differentially\" assess black-box AI agents that have drifted from their\n",
            "previously known models. As a starting point, we consider the fully observable\n",
            "and deterministic setting. We leverage sparse observations of the drifted\n",
            "agent's current behavior and knowledge of its initial model to generate an\n",
            "active querying policy that selectively queries the agent and computes an\n",
            "updated model of its functionality. Empirical evaluation shows that our\n",
            "approach is much more efficient than re-learning the agent model from scratch.\n",
            "We also show that the cost of differential assessment using our method is\n",
            "proportional to the amount of drift in the agent's functionality. \n",
            "URL: http://arxiv.org/pdf/2203.13236v2 \n",
            "\n",
            "\n",
            "108\n",
            "cs\n",
            "Title: Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions \n",
            "Authors: Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Samuel Yang, Peter W. Eklund, Thien Huynh-The, Thanh Tam Nguyen, Quoc-Viet Pham, Imran Razzak, Edbert B. Hsu \n",
            "Date: 2020-07-30 11:11:55+00:00 \n",
            "Id: 2008.07343 \n",
            "Summary: Artificial intelligence (AI) has been applied widely in our daily lives in a\n",
            "variety of ways with numerous success stories. AI has also contributed to\n",
            "dealing with the coronavirus disease (COVID-19) pandemic, which has been\n",
            "happening around the globe. This paper presents a survey of AI methods being\n",
            "used in various applications in the fight against the COVID-19 outbreak and\n",
            "outlines the crucial role of AI research in this unprecedented battle. We touch\n",
            "on areas where AI plays as an essential component, from medical image\n",
            "processing, data analytics, text mining and natural language processing, the\n",
            "Internet of Things, to computational biology and medicine. A summary of\n",
            "COVID-19 related data sources that are available for research purposes is also\n",
            "presented. Research directions on exploring the potential of AI and enhancing\n",
            "its capability and power in the pandemic battle are thoroughly discussed. We\n",
            "identify 13 groups of problems related to the COVID-19 pandemic and highlight\n",
            "promising AI methods and tools that can be used to address these problems. It\n",
            "is envisaged that this study will provide AI researchers and the wider\n",
            "community with an overview of the current status of AI applications, and\n",
            "motivate researchers to harness AI's potential in the fight against COVID-19. \n",
            "URL: http://arxiv.org/pdf/2008.07343v4 \n",
            "\n",
            "\n",
            "109\n",
            "cs\n",
            "Title: Immune Moral Models? Pro-Social Rule Breaking as a Moral Enhancement Approach for Ethical AI \n",
            "Authors: Rajitha Ramanayake, Philipp Wicke, Vivek Nallur \n",
            "Date: 2021-06-17 18:44:55+00:00 \n",
            "Id: 2107.04022 \n",
            "Summary: We are moving towards a future where Artificial Intelligence (AI) based\n",
            "agents make many decisions on behalf of humans. From healthcare decision making\n",
            "to social media censoring, these agents face problems, and make decisions with\n",
            "ethical and societal implications. Ethical behaviour is a critical\n",
            "characteristic that we would like in a human-centric AI. A common observation\n",
            "in human-centric industries, like the service industry and healthcare, is that\n",
            "their professionals tend to break rules, if necessary, for pro-social reasons.\n",
            "This behaviour among humans is defined as pro-social rule breaking. To make AI\n",
            "agents more human centric, we argue that there is a need for a mechanism that\n",
            "helps AI agents identify when to break rules set by their designers. To\n",
            "understand when AI agents need to break rules, we examine the conditions under\n",
            "which humans break rules for pro-social reasons. In this paper, we present a\n",
            "study that introduces a 'vaccination strategy dilemma' to human participants\n",
            "and analyses their responses. In this dilemma, one needs to decide whether they\n",
            "would distribute Covid-19 vaccines only to members of a high-risk group (follow\n",
            "the enforced rule) or, in selected cases, administer the vaccine to a few\n",
            "social influencers (break the rule), which might yield an overall greater\n",
            "benefit to society. The results of the empirical study suggest a relationship\n",
            "between stakeholder utilities and pro-social rule breaking (PSRB), which\n",
            "neither deontological nor utilitarian ethics completely explain. Finally, the\n",
            "paper discusses the design characteristics of an ethical agent capable of PSRB\n",
            "and the future research directions on PSRB in the AI realm. We hope that this\n",
            "will inform the design of future AI agents, and their decision-making\n",
            "behaviour. \n",
            "URL: http://arxiv.org/pdf/2107.04022v2 \n",
            "\n",
            "\n",
            "110\n",
            "cs\n",
            "Title: Human $\\neq$ AGI \n",
            "Authors: Roman V. Yampolskiy \n",
            "Date: 2020-07-11 14:06:13+00:00 \n",
            "Id: 2007.07710 \n",
            "Summary: Terms Artificial General Intelligence (AGI) and Human-Level Artificial\n",
            "Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail\n",
            "of Artificial Intelligence (AI) research, creation of a machine capable of\n",
            "achieving goals in a wide range of environments. However, widespread implicit\n",
            "assumption of equivalence between capabilities of AGI and HLAI appears to be\n",
            "unjustified, as humans are not general intelligences. In this paper, we will\n",
            "prove this distinction. \n",
            "URL: http://arxiv.org/pdf/2007.07710v1 \n",
            "\n",
            "\n",
            "111\n",
            "cs\n",
            "Title: Machine Common Sense Concept Paper \n",
            "Authors: David Gunning \n",
            "Date: 2018-10-17 13:31:41+00:00 \n",
            "Id: 1810.07528 \n",
            "Summary: This paper summarizes some of the technical background, research ideas, and\n",
            "possible development strategies for achieving machine common sense. Machine\n",
            "common sense has long been a critical-but-missing component of Artificial\n",
            "Intelligence (AI). Recent advances in machine learning have resulted in new AI\n",
            "capabilities, but in all of these applications, machine reasoning is narrow and\n",
            "highly specialized. Developers must carefully train or program systems for\n",
            "every situation. General commonsense reasoning remains elusive. The absence of\n",
            "common sense prevents intelligent systems from understanding their world,\n",
            "behaving reasonably in unforeseen situations, communicating naturally with\n",
            "people, and learning from new experiences. Its absence is perhaps the most\n",
            "significant barrier between the narrowly focused AI applications we have today\n",
            "and the more general, human-like AI systems we would like to build in the\n",
            "future. Machine common sense remains a broad, potentially unbounded problem in\n",
            "AI. There are a wide range of strategies that could be employed to make\n",
            "progress on this difficult challenge. This paper discusses two diverse\n",
            "strategies for focusing development on two different machine commonsense\n",
            "services: (1) a service that learns from experience, like a child, to construct\n",
            "computational models that mimic the core domains of child cognition for objects\n",
            "(intuitive physics), agents (intentional actors), and places (spatial\n",
            "navigation); and (2) service that learns from reading the Web, like a research\n",
            "librarian, to construct a commonsense knowledge repository capable of answering\n",
            "natural language and image-based questions about commonsense phenomena. \n",
            "URL: http://arxiv.org/pdf/1810.07528v1 \n",
            "\n",
            "\n",
            "112\n",
            "cs\n",
            "Title: Adversarial vs behavioural-based defensive AI with joint, continual and active learning: automated evaluation of robustness to deception, poisoning and concept drift \n",
            "Authors: Alexandre Dey, Marc Velay, Jean-Philippe Fauvelle, Sylvain Navers \n",
            "Date: 2020-01-13 13:54:36+00:00 \n",
            "Id: 2001.11821 \n",
            "Summary: Recent advancements in Artificial Intelligence (AI) have brought new\n",
            "capabilities to behavioural analysis (UEBA) for cyber-security consisting in\n",
            "the detection of hostile action based on the unusual nature of events observed\n",
            "on the Information System.In our previous work (presented at C\\&ESAR 2018 and\n",
            "FIC 2019), we have associated deep neural networks auto-encoders for anomaly\n",
            "detection and graph-based events correlation to address major limitations in\n",
            "UEBA systems. This resulted in reduced false positive and false negative rates,\n",
            "improved alert explainability, while maintaining real-time performances and\n",
            "scalability. However, we did not address the natural evolution of behaviours\n",
            "through time, also known as concept drift. To maintain effective detection\n",
            "capabilities, an anomaly-based detection system must be continually trained,\n",
            "which opens a door to an adversary that can conduct the so-called\n",
            "\"frog-boiling\" attack by progressively distilling unnoticed attack traces\n",
            "inside the behavioural models until the complete attack is considered normal.\n",
            "In this paper, we present a solution to effectively mitigate this attack by\n",
            "improving the detection process and efficiently leveraging human expertise. We\n",
            "also present preliminary work on adversarial AI conducting deception attack,\n",
            "which, in term, will be used to help assess and improve the defense system.\n",
            "These defensive and offensive AI implement joint, continual and active\n",
            "learning, in a step that is necessary in assessing, validating and certifying\n",
            "AI-based defensive solutions. \n",
            "URL: http://arxiv.org/pdf/2001.11821v1 \n",
            "\n",
            "\n",
            "113\n",
            "cs\n",
            "Title: Safe Artificial General Intelligence via Distributed Ledger Technology \n",
            "Authors: Kristen W. Carlson \n",
            "Date: 2019-02-11 00:10:47+00:00 \n",
            "Id: 1902.03689 \n",
            "Summary: Background. Expert observers and artificial intelligence (AI) progression\n",
            "metrics indicate AI will exceed human intelligence within a few decades.\n",
            "Whether general AI that exceeds human capabilities (AGI) will be the single\n",
            "greatest boon in history or a disaster is unknown. No proofs exist that AGI\n",
            "will benefit humans or that AGI will not harm or eliminate humans.\n",
            "  Objective. I propose a set of logically distinct conceptual components that\n",
            "are necessary and sufficient to 1) ensure that most known AGI scenarios will\n",
            "not harm humanity and 2) robustly align AGI values and goals with human values.\n",
            "  Methods. By systematically addressing each pathway category to malevolent AI\n",
            "we can induce the methods/axioms required to redress the category.\n",
            "  Results and Discussion. Distributed ledger technology (DLT, blockchain) is\n",
            "integral to this proposal, e.g. to reduce the probability of hacking, provide\n",
            "an audit trail to detect and correct errors or identify components causing\n",
            "vulnerability or failure and replace them or shut them down remotely and/or\n",
            "automatically, and to separate and balance key AGI components via decentralized\n",
            "apps (dApps). Smart contracts based on DLT are necessary to address evolution\n",
            "of AI that will be too fast for human monitoring and intervention.\n",
            "  The proposed axioms. 1) Access to technology by market license. 2)\n",
            "Transparent ethics embodied in DLT. 3) Morality encrypted via DLT. 4) Behavior\n",
            "control structure with values (ethics) at roots. 5) Individual bar-code\n",
            "identification of all critical components. 6) Configuration Item (from business\n",
            "continuity/disaster recovery planning). 7) Identity verification secured via\n",
            "DLT. 8) Smart automated contracts based on DLT. 9) Decentralized applications -\n",
            "AI software code modules encrypted via DLT. 10) Audit trail of component usage\n",
            "stored via DLT. 11) Social ostracism (denial of societal resources) augmented\n",
            "by DLT petitions. \n",
            "URL: http://arxiv.org/pdf/1902.03689v2 \n",
            "\n",
            "\n",
            "115\n",
            "cs\n",
            "Title: Monitoring Misuse for Accountable 'Artificial Intelligence as a Service' \n",
            "Authors: Seyyed Ahmad Javadi, Richard Cloete, Jennifer Cobbe, Michelle Seng Ah Lee, Jatinder Singh \n",
            "Date: 2020-01-14 18:14:33+00:00 \n",
            "Id: 2001.09723 \n",
            "Summary: AI is increasingly being offered 'as a service' (AIaaS). This entails service\n",
            "providers offering customers access to pre-built AI models and services, for\n",
            "tasks such as object recognition, text translation, text-to-voice conversion,\n",
            "and facial recognition, to name a few. The offerings enable customers to easily\n",
            "integrate a range of powerful AI-driven capabilities into their applications.\n",
            "Customers access these models through the provider's APIs, sending particular\n",
            "data to which models are applied, the results of which returned. However, there\n",
            "are many situations in which the use of AI can be problematic. AIaaS services\n",
            "typically represent generic functionality, available 'at a click'. Providers\n",
            "may therefore, for reasons of reputation or responsibility, seek to ensure that\n",
            "the AIaaS services they offer are being used by customers for 'appropriate'\n",
            "purposes. This paper introduces and explores the concept whereby AIaaS\n",
            "providers uncover situations of possible service misuse by their customers.\n",
            "Illustrated through topical examples, we consider the technical usage patterns\n",
            "that could signal situations warranting scrutiny, and raise some of the legal\n",
            "and technical challenges of monitoring for misuse. In all, by introducing this\n",
            "concept, we indicate a potential area for further inquiry from a range of\n",
            "perspectives. \n",
            "URL: http://arxiv.org/pdf/2001.09723v1 \n",
            "\n",
            "\n",
            "116\n",
            "cs\n",
            "Title: Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications \n",
            "Authors: Khaled B. Letaief, Yuanming Shi, Jianmin Lu, Jianhua Lu \n",
            "Date: 2021-11-24 11:47:16+00:00 \n",
            "Id: 2111.12444 \n",
            "Summary: The thriving of artificial intelligence (AI) applications is driving the\n",
            "further evolution of wireless networks. It has been envisioned that 6G will be\n",
            "transformative and will revolutionize the evolution of wireless from \"connected\n",
            "things\" to \"connected intelligence\". However, state-of-the-art deep learning\n",
            "and big data analytics based AI systems require tremendous computation and\n",
            "communication resources, causing significant latency, energy consumption,\n",
            "network congestion, and privacy leakage in both of the training and inference\n",
            "processes. By embedding model training and inference capabilities into the\n",
            "network edge, edge AI stands out as a disruptive technology for 6G to\n",
            "seamlessly integrate sensing, communication, computation, and intelligence,\n",
            "thereby improving the efficiency, effectiveness, privacy, and security of 6G\n",
            "networks. In this paper, we shall provide our vision for scalable and\n",
            "trustworthy edge AI systems with integrated design of wireless communication\n",
            "strategies and decentralized machine learning models. New design principles of\n",
            "wireless networks, service-driven resource allocation optimization methods, as\n",
            "well as a holistic end-to-end system architecture to support edge AI will be\n",
            "described. Standardization, software and hardware platforms, and application\n",
            "scenarios are also discussed to facilitate the industrialization and\n",
            "commercialization of edge AI systems. \n",
            "URL: http://arxiv.org/pdf/2111.12444v1 \n",
            "\n",
            "\n",
            "118\n",
            "cs\n",
            "Title: Detecting Anomalous Process Behaviour using Second Generation Artificial Immune Systems \n",
            "Authors: Jamie Twycross, Uwe Aickelin, Amanda Whitbrook \n",
            "Date: 2010-06-18 09:55:04+00:00 \n",
            "Id: 1006.3654 \n",
            "Summary: Artificial Immune Systems have been successfully applied to a number of\n",
            "problem domains including fault tolerance and data mining, but have been shown\n",
            "to scale poorly when applied to computer intrusion detec- tion despite the fact\n",
            "that the biological immune system is a very effective anomaly detector. This\n",
            "may be because AIS algorithms have previously been based on the adaptive immune\n",
            "system and biologically-naive mod- els. This paper focuses on describing and\n",
            "testing a more complex and biologically-authentic AIS model, inspired by the\n",
            "interactions between the innate and adaptive immune systems. Its performance on\n",
            "a realistic process anomaly detection problem is shown to be better than\n",
            "standard AIS methods (negative-selection), policy-based anomaly detection\n",
            "methods (systrace), and an alternative innate AIS approach (the DCA). In\n",
            "addition, it is shown that runtime information can be used in combination with\n",
            "system call information to enhance detection capability. \n",
            "URL: http://arxiv.org/pdf/1006.3654v1 \n",
            "\n",
            "\n",
            "119\n",
            "cs\n",
            "Title: A Systems Approach to Achieving the Benefits of Artificial Intelligence in UK Defence \n",
            "Authors: Gavin Pearson, Phil Jolley, Geraint Evans \n",
            "Date: 2018-09-28 15:32:21+00:00 \n",
            "Id: 1809.11089 \n",
            "Summary: The ability to exploit the opportunities offered by AI within UK Defence\n",
            "calls for an understanding of systemic issues required to achieve an effective\n",
            "operational capability. This paper provides the authors' views of issues which\n",
            "currently block UK Defence from fully benefitting from AI technology. These are\n",
            "situated within a reference model for the AI Value Train, so enabling the\n",
            "community to address the exploitation of such data and software intensive\n",
            "systems in a systematic, end to end manner. The paper sets out the conditions\n",
            "for success including: Researching future solutions to known problems and\n",
            "clearly defined use cases; Addressing achievable use cases to show benefit;\n",
            "Enhancing the availability of Defence-relevant data; Enhancing Defence 'know\n",
            "how' in AI; Operating Software Intensive supply chain eco-systems at required\n",
            "breadth and pace; Governance and, the integration of software and platform\n",
            "supply chains and operating models. \n",
            "URL: http://arxiv.org/pdf/1809.11089v1 \n",
            "\n",
            "\n",
            "120\n",
            "cs\n",
            "Title: FinBrain: When Finance Meets AI 2.0 \n",
            "Authors: Xiaolin Zheng, Mengying Zhu, Qibing Li, Chaochao Chen, Yanchao Tan \n",
            "Date: 2018-08-26 03:12:50+00:00 \n",
            "Id: 1808.08497 \n",
            "Summary: Artificial intelligence (AI) is the core technology of technological\n",
            "revolution and industrial transformation. As one of the new intelligent needs\n",
            "in the AI 2.0 era, financial intelligence has elicited much attention from the\n",
            "academia and industry. In our current dynamic capital market, financial\n",
            "intelligence demonstrates a fast and accurate machine learning capability to\n",
            "handle complex data and has gradually acquired the potential to become a\n",
            "\"financial brain\". In this work, we survey existing studies on financial\n",
            "intelligence. First, we describe the concept of financial intelligence and\n",
            "elaborate on its position in the financial technology field. Second, we\n",
            "introduce the development of financial intelligence and review state-of-the-art\n",
            "techniques in wealth management, risk management, financial security, financial\n",
            "consulting, and blockchain. Finally, we propose a research framework called\n",
            "FinBrain and summarize four open issues, namely, explainable financial agents\n",
            "and causality, perception and prediction under uncertainty, risk-sensitive and\n",
            "robust decision making, and multi-agent game and mechanism design. We believe\n",
            "that these research directions can lay the foundation for the development of AI\n",
            "2.0 in the finance field. \n",
            "URL: http://arxiv.org/pdf/1808.08497v1 \n",
            "\n",
            "\n",
            "121\n",
            "cs\n",
            "Title: Deep Reinforcement Learning for Scheduling in Cellular Networks \n",
            "Authors: Jian Wang, Chen Xu, Yourui Huangfu, Rong Li, Yiqun Ge, Jun Wang \n",
            "Date: 2019-05-15 02:09:37+00:00 \n",
            "Id: 1905.05914 \n",
            "Summary: Integrating artificial intelligence (AI) into wireless networks has drawn\n",
            "significant interest in both industry and academia. A common solution is to\n",
            "replace partial or even all modules in the conventional systems, which is often\n",
            "lack of efficiency and robustness due to their ignoring of expert knowledge. In\n",
            "this paper, we take deep reinforcement learning (DRL) based scheduling as an\n",
            "example to investigate how expert knowledge can help with AI module in cellular\n",
            "networks. A simulation platform, which has considered link adaption, feedback\n",
            "and other practical mechanisms, is developed to facilitate the investigation.\n",
            "Besides the traditional way, which is learning directly from the environment,\n",
            "for training DRL agent, we propose two novel methods, i.e., learning from a\n",
            "dual AI module and learning from the expert solution. The results show that,\n",
            "for the considering scheduling problem, DRL training procedure can be improved\n",
            "on both performance and convergence speed by involving the expert knowledge.\n",
            "Hence, instead of replacing conventional scheduling module in the system,\n",
            "adding a newly introduced AI module, which is capable to interact with the\n",
            "conventional module and provide more flexibility, is a more feasible solution. \n",
            "URL: http://arxiv.org/pdf/1905.05914v2 \n",
            "\n",
            "\n",
            "122\n",
            "cs\n",
            "Title: Comparison and Benchmarking of AI Models and Frameworks on Mobile Devices \n",
            "Authors: Chunjie Luo, Xiwen He, Jianfeng Zhan, Lei Wang, Wanling Gao, Jiahui Dai \n",
            "Date: 2020-05-07 15:05:23+00:00 \n",
            "Id: 2005.05085 \n",
            "Summary: Due to increasing amounts of data and compute resources, deep learning\n",
            "achieves many successes in various domains. The application of deep learning on\n",
            "the mobile and embedded devices is taken more and more attentions, benchmarking\n",
            "and ranking the AI abilities of mobile and embedded devices becomes an urgent\n",
            "problem to be solved. Considering the model diversity and framework diversity,\n",
            "we propose a benchmark suite, AIoTBench, which focuses on the evaluation of the\n",
            "inference abilities of mobile and embedded devices. AIoTBench covers three\n",
            "typical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as\n",
            "three light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is\n",
            "implemented by three frameworks which are designed for mobile and embedded\n",
            "devices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI\n",
            "capabilities of the devices, we propose two unified metrics as the AI scores:\n",
            "Valid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we\n",
            "have compared and ranked 5 mobile devices using our benchmark. This list will\n",
            "be extended and updated soon after. \n",
            "URL: http://arxiv.org/pdf/2005.05085v1 \n",
            "\n",
            "\n",
            "124\n",
            "cs\n",
            "Title: Open-endedness in AI systems, cellular evolution and intellectual discussions \n",
            "Authors: Kushal Shah \n",
            "Date: 2018-12-28 06:11:56+00:00 \n",
            "Id: 1812.10900 \n",
            "Summary: One of the biggest challenges that artificial intelligence (AI) research is\n",
            "facing in recent times is to develop algorithms and systems that are not only\n",
            "good at performing a specific intelligent task but also good at learning a very\n",
            "diverse of skills somewhat like humans do. In other words, the goal is to be\n",
            "able to mimic biological evolution which has produced all the living species on\n",
            "this planet and which seems to have no end to its creativity. The process of\n",
            "intellectual discussions is also somewhat similar to biological evolution in\n",
            "this regard and is responsible for many of the innovative discoveries and\n",
            "inventions that scientists and engineers have made in the past. In this paper,\n",
            "we present an information theoretic analogy between the process of discussions\n",
            "and the molecular dynamics within a cell, showing that there is a common\n",
            "process of information exchange at the heart of these two seemingly different\n",
            "processes, which can perhaps help us in building AI systems capable of\n",
            "open-ended innovation. We also discuss the role of consciousness in this\n",
            "process and present a framework for the development of open-ended AI systems. \n",
            "URL: http://arxiv.org/pdf/1812.10900v1 \n",
            "\n",
            "\n",
            "125\n",
            "cs\n",
            "Title: Towards Empathetic Planning \n",
            "Authors: Maayan Shvo, Sheila A. McIlraith \n",
            "Date: 2019-06-14 23:36:53+00:00 \n",
            "Id: 1906.06436 \n",
            "Summary: Critical to successful human interaction is a capacity for empathy - the\n",
            "ability to understand and share the thoughts and feelings of another. As\n",
            "Artificial Intelligence (AI) systems are increasingly required to interact with\n",
            "humans in a myriad of settings, it is important to enable AI to wield empathy\n",
            "as a tool to benefit those it interacts with. In this paper, we work towards\n",
            "this goal by bringing together a number of important concepts: empathy, AI\n",
            "planning, and reasoning in the presence of knowledge and belief. We formalize\n",
            "the notion of Empathetic Planning which is informed by the beliefs and\n",
            "affective state of the empathizee. We appeal to an epistemic logic framework to\n",
            "represent the beliefs of the empathizee and propose AI planning-based\n",
            "computational approaches to compute empathetic solutions. We illustrate the\n",
            "potential benefits of our approach by conducting a study where we evaluate\n",
            "participants' perceptions of the agent's empathetic abilities and assistive\n",
            "capabilities. \n",
            "URL: http://arxiv.org/pdf/1906.06436v1 \n",
            "\n",
            "\n",
            "126\n",
            "cs\n",
            "Title: General Board Game Playing for Education and Research in Generic AI Game Learning \n",
            "Authors: Wolfgang Konen \n",
            "Date: 2019-07-11 13:02:25+00:00 \n",
            "Id: 1907.06508 \n",
            "Summary: We present a new general board game (GBG) playing and learning framework. GBG\n",
            "defines the common interfaces for board games, game states and their AI agents.\n",
            "It allows one to run competitions of different agents on different games. It\n",
            "standardizes those parts of board game playing and learning that otherwise\n",
            "would be tedious and repetitive parts in coding. GBG is suitable for arbitrary\n",
            "1-, 2-, ..., N-player board games. It makes a generic TD($\\lambda$)-n-tuple\n",
            "agent for the first time available to arbitrary games. On various games,\n",
            "TD($\\lambda$)-n-tuple is found to be superior to other generic agents like\n",
            "MCTS. GBG aims at the educational perspective, where it helps students to start\n",
            "faster in the area of game learning. GBG aims as well at the research\n",
            "perspective by collecting a growing set of games and AI agents to assess their\n",
            "strengths and generalization capabilities in meaningful competitions. Initial\n",
            "successful educational and research results are reported. \n",
            "URL: http://arxiv.org/pdf/1907.06508v1 \n",
            "\n",
            "\n",
            "127\n",
            "cs\n",
            "Title: Metrology for AI: From Benchmarks to Instruments \n",
            "Authors: Chris Welty, Praveen Paritosh, Lora Aroyo \n",
            "Date: 2019-11-05 15:30:08+00:00 \n",
            "Id: 1911.01875 \n",
            "Summary: In this paper we present the first steps towards hardening the science of\n",
            "measuring AI systems, by adopting metrology, the science of measurement and its\n",
            "application, and applying it to human (crowd) powered evaluations. We begin\n",
            "with the intuitive observation that evaluating the performance of an AI system\n",
            "is a form of measurement. In all other science and engineering disciplines, the\n",
            "devices used to measure are called instruments, and all measurements are\n",
            "recorded with respect to the characteristics of the instruments used. One does\n",
            "not report mass, speed, or length, for example, of a studied object without\n",
            "disclosing the precision (measurement variance) and resolution (smallest\n",
            "detectable change) of the instrument used. It is extremely common in the AI\n",
            "literature to compare the performance of two systems by using a crowd-sourced\n",
            "dataset as an instrument, but failing to report if the performance difference\n",
            "lies within the capability of that instrument to measure. To illustrate the\n",
            "adoption of metrology to benchmark datasets we use the word similarity\n",
            "benchmark WS353 and several previously published experiments that use it for\n",
            "evaluation. \n",
            "URL: http://arxiv.org/pdf/1911.01875v1 \n",
            "\n",
            "\n",
            "128\n",
            "cs\n",
            "Title: Scenarios and Recommendations for Ethical Interpretive AI \n",
            "Authors: John Licato, Zaid Marji, Sophia Abraham \n",
            "Date: 2019-11-05 16:23:01+00:00 \n",
            "Id: 1911.01917 \n",
            "Summary: Artificially intelligent systems, given a set of non-trivial ethical rules to\n",
            "follow, will inevitably be faced with scenarios which call into question the\n",
            "scope of those rules. In such cases, human reasoners typically will engage in\n",
            "interpretive reasoning, where interpretive arguments are used to support or\n",
            "attack claims that some rule should be understood a certain way. Artificially\n",
            "intelligent reasoners, however, currently lack the ability to carry out\n",
            "human-like interpretive reasoning, and we argue that bridging this gulf is of\n",
            "tremendous importance to human-centered AI. In order to better understand how\n",
            "future artificial reasoners capable of human-like interpretive reasoning must\n",
            "be developed, we have collected a dataset of ethical rules, scenarios designed\n",
            "to invoke interpretive reasoning, and interpretations of those scenarios. We\n",
            "perform a qualitative analysis of our dataset, and summarize our findings in\n",
            "the form of practical recommendations. \n",
            "URL: http://arxiv.org/pdf/1911.01917v1 \n",
            "\n",
            "\n",
            "131\n",
            "cs\n",
            "Title: Document-editing Assistants and Model-based Reinforcement Learning as a Path to Conversational AI \n",
            "Authors: Katya Kudashkina, Patrick M. Pilarski, Richard S. Sutton \n",
            "Date: 2020-08-27 13:05:51+00:00 \n",
            "Id: 2008.12095 \n",
            "Summary: Intelligent assistants that follow commands or answer simple questions, such\n",
            "as Siri and Google search, are among the most economically important\n",
            "applications of AI. Future conversational AI assistants promise even greater\n",
            "capabilities and a better user experience through a deeper understanding of the\n",
            "domain, the user, or the user's purposes. But what domain and what methods are\n",
            "best suited to researching and realizing this promise? In this article we argue\n",
            "for the domain of voice document editing and for the methods of model-based\n",
            "reinforcement learning. The primary advantages of voice document editing are\n",
            "that the domain is tightly scoped and that it provides something for the\n",
            "conversation to be about (the document) that is delimited and fully accessible\n",
            "to the intelligent assistant. The advantages of reinforcement learning in\n",
            "general are that its methods are designed to learn from interaction without\n",
            "explicit instruction and that it formalizes the purposes of the assistant.\n",
            "Model-based reinforcement learning is needed in order to genuinely understand\n",
            "the domain of discourse and thereby work efficiently with the user to achieve\n",
            "their goals. Together, voice document editing and model-based reinforcement\n",
            "learning comprise a promising research direction for achieving conversational\n",
            "AI. \n",
            "URL: http://arxiv.org/pdf/2008.12095v1 \n",
            "\n",
            "\n",
            "132\n",
            "cs\n",
            "Title: Training Ethically Responsible AI Researchers: a Case Study \n",
            "Authors: Hang Yuan, Claudia Vanea, Federica Lucivero, Nina Hallowell \n",
            "Date: 2020-11-20 14:12:50+00:00 \n",
            "Id: 2011.11393 \n",
            "Summary: Ethical oversight of AI research is beset by a number of problems. There are\n",
            "numerous ways to tackle these problems, however, they leave full responsibility\n",
            "for ethical reflection in the hands of review boards and committees. In this\n",
            "paper, we propose an alternative solution: the training of ethically\n",
            "responsible AI researchers. We showcase this solution through a case study of a\n",
            "centre for doctoral training and outline how ethics training is structured in\n",
            "the program. We go on to present two second-year students' reflections on their\n",
            "training which demonstrates some of their newly found capabilities as ethically\n",
            "responsible researchers. \n",
            "URL: http://arxiv.org/pdf/2011.11393v1 \n",
            "\n",
            "\n",
            "133\n",
            "cs\n",
            "Title: Uncertainty Quantification 360: A Holistic Toolkit for Quantifying and Communicating the Uncertainty of AI \n",
            "Authors: Soumya Ghosh, Q. Vera Liao, Karthikeyan Natesan Ramamurthy, Jiri Navratil, Prasanna Sattigeri, Kush R. Varshney, Yunfeng Zhang \n",
            "Date: 2021-06-02 18:29:04+00:00 \n",
            "Id: 2106.01410 \n",
            "Summary: In this paper, we describe an open source Python toolkit named Uncertainty\n",
            "Quantification 360 (UQ360) for the uncertainty quantification of AI models. The\n",
            "goal of this toolkit is twofold: first, to provide a broad range of\n",
            "capabilities to streamline as well as foster the common practices of\n",
            "quantifying, evaluating, improving, and communicating uncertainty in the AI\n",
            "application development lifecycle; second, to encourage further exploration of\n",
            "UQ's connections to other pillars of trustworthy AI such as fairness and\n",
            "transparency through the dissemination of latest research and education\n",
            "materials. Beyond the Python package (\\url{https://github.com/IBM/UQ360}), we\n",
            "have developed an interactive experience (\\url{http://uq360.mybluemix.net}) and\n",
            "guidance materials as educational tools to aid researchers and developers in\n",
            "producing and communicating high-quality uncertainties in an effective manner. \n",
            "URL: http://arxiv.org/pdf/2106.01410v2 \n",
            "\n",
            "\n",
            "134\n",
            "cs\n",
            "Title: Neuro-Symbolic AI: An Emerging Class of AI Workloads and their Characterization \n",
            "Authors: Zachary Susskind, Bryce Arden, Lizy K. John, Patrick Stockton, Eugene B. John \n",
            "Date: 2021-09-13 17:19:59+00:00 \n",
            "Id: 2109.06133 \n",
            "Summary: Neuro-symbolic artificial intelligence is a novel area of AI research which\n",
            "seeks to combine traditional rules-based AI approaches with modern deep\n",
            "learning techniques. Neuro-symbolic models have already demonstrated the\n",
            "capability to outperform state-of-the-art deep learning models in domains such\n",
            "as image and video reasoning. They have also been shown to obtain high accuracy\n",
            "with significantly less training data than traditional models. Due to the\n",
            "recency of the field's emergence and relative sparsity of published results,\n",
            "the performance characteristics of these models are not well understood. In\n",
            "this paper, we describe and analyze the performance characteristics of three\n",
            "recent neuro-symbolic models. We find that symbolic models have less potential\n",
            "parallelism than traditional neural models due to complex control flow and\n",
            "low-operational-intensity operations, such as scalar multiplication and tensor\n",
            "addition. However, the neural aspect of computation dominates the symbolic part\n",
            "in cases where they are clearly separable. We also find that data movement\n",
            "poses a potential bottleneck, as it does in many ML workloads. \n",
            "URL: http://arxiv.org/pdf/2109.06133v1 \n",
            "\n",
            "\n",
            "135\n",
            "cs\n",
            "Title: A curated, ontology-based, large-scale knowledge graph of artificial intelligence tasks and benchmarks \n",
            "Authors: Kathrin Blagec, Adriano Barbosa-Silva, Simon Ott, Matthias Samwald \n",
            "Date: 2021-10-04 13:25:53+00:00 \n",
            "Id: 2110.01434 \n",
            "Summary: Research in artificial intelligence (AI) is addressing a growing number of\n",
            "tasks through a rapidly growing number of models and methodologies. This makes\n",
            "it difficult to keep track of where novel AI methods are successfully -- or\n",
            "still unsuccessfully -- applied, how progress is measured, how different\n",
            "advances might synergize with each other, and how future research should be\n",
            "prioritized.\n",
            "  To help address these issues, we created the Intelligence Task Ontology and\n",
            "Knowledge Graph (ITO), a comprehensive, richly structured and manually curated\n",
            "resource on artificial intelligence tasks, benchmark results and performance\n",
            "metrics. The current version of ITO contain 685,560 edges, 1,100 classes\n",
            "representing AI processes and 1,995 properties representing performance\n",
            "metrics.\n",
            "  The goal of ITO is to enable precise and network-based analyses of the global\n",
            "landscape of AI tasks and capabilities. ITO is based on technologies that allow\n",
            "for easy integration and enrichment with external data, automated inference and\n",
            "continuous, collaborative expert curation of underlying ontological models. We\n",
            "make the ITO dataset and a collection of Jupyter notebooks utilising ITO openly\n",
            "available. \n",
            "URL: http://arxiv.org/pdf/2110.01434v2 \n",
            "\n",
            "\n",
            "136\n",
            "cs\n",
            "Title: Catch Me If You GAN: Using Artificial Intelligence for Fake Log Generation \n",
            "Authors: Christian Toemmel \n",
            "Date: 2021-12-22 16:29:21+00:00 \n",
            "Id: 2112.12006 \n",
            "Summary: With artificial intelligence (AI) becoming relevant in various parts of\n",
            "everyday life, other technologies are already widely influenced by the new way\n",
            "of handling large amounts of data. Although widespread already, AI has had only\n",
            "punctual influences on the cybersecurity field specifically. Many techniques\n",
            "and technologies used by cybersecurity experts function through manual labor\n",
            "and barely draw on automation, e.g., logs are often reviewed manually by system\n",
            "admins for potentially malicious keywords. This work evaluates the use of a\n",
            "special type of AI called generative adversarial networks (GANs) for log\n",
            "generation. More precisely, three different generative adversarial networks,\n",
            "SeqGAN, MaliGAN, and CoT, are reviewed in this research regarding their\n",
            "performance, focusing on generating new logs as a means of deceiving system\n",
            "admins for red teams. Although static generators for fake logs have been around\n",
            "for a while, their produces are usually easy to reveal as such. Using AI as an\n",
            "approach to this problem has not been widely researched. Identified challenges\n",
            "consist of formatting, dates and times, and overall consistency. Summing up the\n",
            "results, GANs seem not to be a good fit for generating fake logs. Their\n",
            "capability to detect fake logs, however, might be of use in practical\n",
            "scenarios. \n",
            "URL: http://arxiv.org/pdf/2112.12006v1 \n",
            "\n",
            "\n",
            "137\n",
            "cs\n",
            "Title: Interactive Attention AI to translate low light photos to captions for night scene understanding in women safety \n",
            "Authors: Rajagopal A, Nirmala V, Arun Muthuraj Vedamanickam \n",
            "Date: 2022-01-04 04:21:07+00:00 \n",
            "Id: 2201.00969 \n",
            "Summary: There is amazing progress in Deep Learning based models for Image captioning\n",
            "and Low Light image enhancement. For the first time in literature, this paper\n",
            "develops a Deep Learning model that translates night scenes to sentences,\n",
            "opening new possibilities for AI applications in the safety of visually\n",
            "impaired women. Inspired by Image Captioning and Visual Question Answering, a\n",
            "novel Interactive Image Captioning is developed. A user can make the AI focus\n",
            "on any chosen person of interest by influencing the attention scoring.\n",
            "Attention context vectors are computed from CNN feature vectors and\n",
            "user-provided start word. The Encoder-Attention-Decoder neural network learns\n",
            "to produce captions from low brightness images. This paper demonstrates how\n",
            "women safety can be enabled by researching a novel AI capability in the\n",
            "Interactive Vision-Language model for perception of the environment in the\n",
            "night. \n",
            "URL: http://arxiv.org/pdf/2201.00969v1 \n",
            "\n",
            "\n",
            "138\n",
            "cs\n",
            "Title: The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues \n",
            "Authors: Anaïs Tack, Chris Piech \n",
            "Date: 2022-05-16 09:36:30+00:00 \n",
            "Id: 2205.07540 \n",
            "Summary: How can we test whether state-of-the-art generative models, such as Blender\n",
            "and GPT-3, are good AI teachers, capable of replying to a student in an\n",
            "educational dialogue? Designing an AI teacher test is challenging: although\n",
            "evaluation methods are much-needed, there is no off-the-shelf solution to\n",
            "measuring pedagogical ability. This paper reports on a first attempt at an AI\n",
            "teacher test. We built a solution around the insight that you can run\n",
            "conversational agents in parallel to human teachers in real-world dialogues,\n",
            "simulate how different agents would respond to a student, and compare these\n",
            "counterpart responses in terms of three abilities: speak like a teacher,\n",
            "understand a student, help a student. Our method builds on the reliability of\n",
            "comparative judgments in education and uses a probabilistic model and Bayesian\n",
            "sampling to infer estimates of pedagogical ability. We find that, even though\n",
            "conversational agents (Blender in particular) perform well on conversational\n",
            "uptake, they are quantifiably worse than real teachers on several pedagogical\n",
            "dimensions, especially with regard to helpfulness (Blender: {\\Delta} ability =\n",
            "-0.75; GPT-3: {\\Delta} ability = -0.93). \n",
            "URL: http://arxiv.org/pdf/2205.07540v1 \n",
            "\n",
            "\n",
            "139\n",
            "cs\n",
            "Title: Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable \n",
            "Authors: Odest Chadwicke Jenkins, Daniel Lopresti, Melanie Mitchell \n",
            "Date: 2020-12-11 00:50:09+00:00 \n",
            "Id: 2012.06058 \n",
            "Summary: The history of AI has included several \"waves\" of ideas. The first wave, from\n",
            "the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded\n",
            "representations of knowledge, the foundations of so-called \"expert systems\".\n",
            "The second wave, starting in the 1990s, focused on statistics and machine\n",
            "learning, in which, instead of hand-programming rules for behavior, programmers\n",
            "constructed \"statistical learning algorithms\" that could be trained on large\n",
            "datasets. In the most recent wave research in AI has largely focused on deep\n",
            "(i.e., many-layered) neural networks, which are loosely inspired by the brain\n",
            "and trained by \"deep learning\" methods. However, while deep neural networks\n",
            "have led to many successes and new capabilities in computer vision, speech\n",
            "recognition, language processing, game-playing, and robotics, their potential\n",
            "for broad application remains limited by several factors.\n",
            "  A concerning limitation is that even the most successful of today's AI\n",
            "systems suffer from brittleness-they can fail in unexpected ways when faced\n",
            "with situations that differ sufficiently from ones they have been trained on.\n",
            "This lack of robustness also appears in the vulnerability of AI systems to\n",
            "adversarial attacks, in which an adversary can subtly manipulate data in a way\n",
            "to guarantee a specific wrong answer or action from an AI system. AI systems\n",
            "also can absorb biases-based on gender, race, or other factors-from their\n",
            "training data and further magnify these biases in their subsequent\n",
            "decision-making. Taken together, these various limitations have prevented AI\n",
            "systems such as automatic medical diagnosis or autonomous vehicles from being\n",
            "sufficiently trustworthy for wide deployment. The massive proliferation of AI\n",
            "across society will require radically new ideas to yield technology that will\n",
            "not sacrifice our productivity, our quality of life, or our values. \n",
            "URL: http://arxiv.org/pdf/2012.06058v1 \n",
            "\n",
            "\n",
            "141\n",
            "cs\n",
            "Title: Lawmaps: Enabling Legal AI development through Visualisation of the Implicit Structure of Legislation and Lawyerly Process \n",
            "Authors: Scott McLachlan, Evangelia Kyrimi, Kudakwashe Dube, Norman Fenton, Lisa Webley \n",
            "Date: 2020-11-01 18:36:04+00:00 \n",
            "Id: 2011.00586 \n",
            "Summary: Modelling that exploits visual elements and information visualisation are\n",
            "important areas that have contributed immensely to understanding and the\n",
            "computerisation advancements in many domains and yet remain unexplored for the\n",
            "benefit of the law and legal practice. This paper investigates the challenge of\n",
            "modelling and expressing structures and processes in legislation and the law by\n",
            "using visual modelling and information visualisation (InfoVis) to assist\n",
            "accessibility of legal knowledge, practice and knowledge formalisation as a\n",
            "basis for legal AI. The paper uses a subset of the well-defined Unified\n",
            "Modelling Language (UML) to visually express the structure and process of the\n",
            "legislation and the law to create visual flow diagrams called lawmaps, which\n",
            "form the basis of further formalisation. A lawmap development methodology is\n",
            "presented and evaluated by creating a set of lawmaps for the practice of\n",
            "conveyancing and the Landlords and Tenants Act 1954 of the United Kingdom. This\n",
            "paper is the first of a new breed of preliminary solutions capable of\n",
            "application across all aspects, from legislation to practice; and capable of\n",
            "accelerating development of legal AI. \n",
            "URL: http://arxiv.org/pdf/2011.00586v1 \n",
            "\n",
            "\n",
            "142\n",
            "cs\n",
            "Title: Software Architecture for Next-Generation AI Planning Systems \n",
            "Authors: Sebastian Graef, Ilche Georgievski \n",
            "Date: 2021-02-22 13:43:45+00:00 \n",
            "Id: 2102.10985 \n",
            "Summary: Artificial Intelligence (AI) planning is a flourishing research and\n",
            "development discipline that provides powerful tools for searching a course of\n",
            "action that achieves some user goal. While these planning tools show excellent\n",
            "performance on benchmark planning problems, they represent challenging software\n",
            "systems when it comes to their use and integration in real-world applications.\n",
            "In fact, even in-depth understanding of their internal mechanisms does not\n",
            "guarantee that one can successfully set up, use and manipulate existing\n",
            "planning tools. We contribute toward alleviating this situation by proposing a\n",
            "service-oriented planning architecture to be at the core of the ability to\n",
            "design, develop and use next-generation AI planning systems. We collect and\n",
            "classify common planning capabilities to form the building blocks of the\n",
            "planning architecture. We incorporate software design principles and patterns\n",
            "into the architecture to allow for usability, interoperability and reusability\n",
            "of the planning capabilities. Our prototype planning system demonstrates the\n",
            "potential of our approach for rapid prototyping and flexibility of system\n",
            "composition. Finally, we provide insight into the qualitative advantages of our\n",
            "approach when compared to a typical planning tool. \n",
            "URL: http://arxiv.org/pdf/2102.10985v1 \n",
            "\n",
            "\n",
            "143\n",
            "cs\n",
            "Title: Building Affordance Relations for Robotic Agents - A Review \n",
            "Authors: Paola Ardón, Èric Pairet, Katrin S. Lohan, Subramanian Ramamoorthy, Ronald P. A. Petrick \n",
            "Date: 2021-05-14 08:35:18+00:00 \n",
            "Id: 2105.06706 \n",
            "Summary: Affordances describe the possibilities for an agent to perform actions with\n",
            "an object. While the significance of the affordance concept has been previously\n",
            "studied from varied perspectives, such as psychology and cognitive science,\n",
            "these approaches are not always sufficient to enable direct transfer, in the\n",
            "sense of implementations, to artificial intelligence (AI)-based systems and\n",
            "robotics. However, many efforts have been made to pragmatically employ the\n",
            "concept of affordances, as it represents great potential for AI agents to\n",
            "effectively bridge perception to action. In this survey, we review and find\n",
            "common ground amongst different strategies that use the concept of affordances\n",
            "within robotic tasks, and build on these methods to provide guidance for\n",
            "including affordances as a mechanism to improve autonomy. To this end, we\n",
            "outline common design choices for building representations of affordance\n",
            "relations, and their implications on the generalisation capabilities of an\n",
            "agent when facing previously unseen scenarios. Finally, we identify and discuss\n",
            "a range of interesting research directions involving affordances that have the\n",
            "potential to improve the capabilities of an AI agent. \n",
            "URL: http://arxiv.org/pdf/2105.06706v1 \n",
            "\n",
            "\n",
            "144\n",
            "cs\n",
            "Title: Can Explainable AI Explain Unfairness? A Framework for Evaluating Explainable AI \n",
            "Authors: Kiana Alikhademi, Brianna Richardson, Emma Drobina, Juan E. Gilbert \n",
            "Date: 2021-06-14 15:14:03+00:00 \n",
            "Id: 2106.07483 \n",
            "Summary: Many ML models are opaque to humans, producing decisions too complex for\n",
            "humans to easily understand. In response, explainable artificial intelligence\n",
            "(XAI) tools that analyze the inner workings of a model have been created.\n",
            "Despite these tools' strength in translating model behavior, critiques have\n",
            "raised concerns about the impact of XAI tools as a tool for `fairwashing` by\n",
            "misleading users into trusting biased or incorrect models. In this paper, we\n",
            "created a framework for evaluating explainable AI tools with respect to their\n",
            "capabilities for detecting and addressing issues of bias and fairness as well\n",
            "as their capacity to communicate these results to their users clearly. We found\n",
            "that despite their capabilities in simplifying and explaining model behavior,\n",
            "many prominent XAI tools lack features that could be critical in detecting\n",
            "bias. Developers can use our framework to suggest modifications needed in their\n",
            "toolkits to reduce issues likes fairwashing. \n",
            "URL: http://arxiv.org/pdf/2106.07483v1 \n",
            "\n",
            "\n",
            "145\n",
            "cs\n",
            "Title: The Difficulty of Novelty Detection in Open-World Physical Domains: An Application to Angry Birds \n",
            "Authors: Vimukthini Pinto, Cheng Xue, Chathura Nagoda Gamage, Jochen Renz \n",
            "Date: 2021-06-16 10:14:09+00:00 \n",
            "Id: 2106.08670 \n",
            "Summary: Detecting and responding to novel situations in open-world environments is a\n",
            "key capability of human cognition. Current artificial intelligence (AI)\n",
            "researchers strive to develop systems that can perform in open-world\n",
            "environments. Novelty detection is an important ability of such AI systems. In\n",
            "an open-world, novelties appear in various forms and the difficulty to detect\n",
            "them varies. Therefore, to accurately evaluate the detection capability of AI\n",
            "systems, it is necessary to investigate the difficulty to detect novelties. In\n",
            "this paper, we propose a qualitative physics-based method to quantify the\n",
            "difficulty of novelty detection focusing on open-world physical domains. We\n",
            "apply our method in a popular physics simulation game, Angry Birds. We conduct\n",
            "an experiment with human players with different novelties in Angry Birds to\n",
            "validate our method. Results indicate that the calculated difficulty values are\n",
            "in line with the detection difficulty of the human players. \n",
            "URL: http://arxiv.org/pdf/2106.08670v1 \n",
            "\n",
            "\n",
            "146\n",
            "cs\n",
            "Title: A secondary immune response based on co-evolutive populations of agents for anomaly detection and characterization \n",
            "Authors: Pedro Pinacho-Davidson, Matías Lermanda, Ricardo Contreras, María A. Pinninghoff \n",
            "Date: 2021-09-11 21:28:48+00:00 \n",
            "Id: 2109.05376 \n",
            "Summary: The detection of anomalies in unknown environments is a problem that has been\n",
            "approached from different perspectives with variable results. Artificial Immune\n",
            "Systems (AIS) present particularly advantageous characteristics for the\n",
            "detection of such anomalies. This research is based on an existing detector\n",
            "model, named Artificial Bioindicators System (ABS) which identifies and solves\n",
            "its main weaknesses. An ABS based anomaly classifier model is presented,\n",
            "incorporating elements of the AIS. In this way, a new model (R-ABS) is\n",
            "developed which includes the advantageous capabilities of an ABS plus the\n",
            "reactive capabilities of an AIS to overcome its weaknesses and disadvantages.\n",
            "The RABS model was tested using the well-known DARPA'98 dataset, plus a dataset\n",
            "built to carry out a greater number of experiments. The performance of the RABS\n",
            "model was compared to the performance of the ABS model based on classical\n",
            "sensitivity and specificity metrics, plus a response time metric to illustrate\n",
            "the rapid response of R-ABS relative to ABS. The results showed a better\n",
            "performance of R-ABS, especially in terms of detection time. \n",
            "URL: http://arxiv.org/pdf/2109.05376v1 \n",
            "\n",
            "\n",
            "147\n",
            "cs\n",
            "Title: A Game-Theoretic Approach for AI-based Botnet Attack Defence \n",
            "Authors: Hooman Alavizadeh, Julian Jang-Jaccard, Tansu Alpcan, Seyit A. Camtepe \n",
            "Date: 2021-12-04 02:53:40+00:00 \n",
            "Id: 2112.02223 \n",
            "Summary: The new generation of botnets leverages Artificial Intelligent (AI)\n",
            "techniques to conceal the identity of botmasters and the attack intention to\n",
            "avoid detection. Unfortunately, there has not been an existing assessment tool\n",
            "capable of evaluating the effectiveness of existing defense strategies against\n",
            "this kind of AI-based botnet attack. In this paper, we propose a sequential\n",
            "game theory model that is capable to analyse the details of the potential\n",
            "strategies botnet attackers and defenders could use to reach Nash Equilibrium\n",
            "(NE). The utility function is computed under the assumption when the attacker\n",
            "launches the maximum number of DDoS attacks with the minimum attack cost while\n",
            "the defender utilises the maximum number of defense strategies with the minimum\n",
            "defense cost. We conduct a numerical analysis based on a various number of\n",
            "defense strategies involved on different (simulated) cloud-band sizes in\n",
            "relation to different attack success rate values. Our experimental results\n",
            "confirm that the success of defense highly depends on the number of defense\n",
            "strategies used according to careful evaluation of attack rates. \n",
            "URL: http://arxiv.org/pdf/2112.02223v1 \n",
            "\n",
            "\n",
            "148\n",
            "cs\n",
            "Title: Combining Fast and Slow Thinking for Human-like and Efficient Navigation in Constrained Environments \n",
            "Authors: Marianna B. Ganapini, Murray Campbell, Francesco Fabiano, Lior Horesh, Jon Lenchner, Andrea Loreggia, Nicholas Mattei, Taher Rahgooy, Francesca Rossi, Biplav Srivastava, Brent Venable \n",
            "Date: 2022-01-18 15:24:03+00:00 \n",
            "Id: 2201.07050 \n",
            "Summary: Current AI systems lack several important human capabilities, such as\n",
            "adaptability, generalizability, self-control, consistency, common sense, and\n",
            "causal reasoning. We believe that existing cognitive theories of human decision\n",
            "making, such as the thinking fast and slow theory, can provide insights on how\n",
            "to advance AI systems towards some of these capabilities. In this paper, we\n",
            "propose a general architecture that is based on fast/slow solvers and a\n",
            "metacognitive component. We then present experimental results on the behavior\n",
            "of an instance of this architecture, for AI systems that make decisions about\n",
            "navigating in a constrained environment. We show how combining the fast and\n",
            "slow decision modalities allows the system to evolve over time and gradually\n",
            "pass from slow to fast thinking with enough experience, and that this greatly\n",
            "helps in decision quality, resource consumption, and efficiency. \n",
            "URL: http://arxiv.org/pdf/2201.07050v2 \n",
            "\n",
            "\n",
            "150\n",
            "cs\n",
            "Title: General Video Game AI: Learning from Screen Capture \n",
            "Authors: Kamolwan Kunanusont, Simon M. Lucas, Diego Perez-Liebana \n",
            "Date: 2017-04-23 16:08:06+00:00 \n",
            "Id: 1704.06945 \n",
            "Summary: General Video Game Artificial Intelligence is a general game playing\n",
            "framework for Artificial General Intelligence research in the video-games\n",
            "domain. In this paper, we propose for the first time a screen capture learning\n",
            "agent for General Video Game AI framework. A Deep Q-Network algorithm was\n",
            "applied and improved to develop an agent capable of learning to play different\n",
            "games in the framework. After testing this algorithm using various games of\n",
            "different categories and difficulty levels, the results suggest that our\n",
            "proposed screen capture learning agent has the potential to learn many\n",
            "different games using only a single learning algorithm. \n",
            "URL: http://arxiv.org/pdf/1704.06945v1 \n",
            "\n",
            "\n",
            "152\n",
            "cs\n",
            "Title: Towards self-adaptable robots: from programming to training machines \n",
            "Authors: Víctor Mayoral, Risto Kojcev, Nora Etxezarreta, Alejandro Hernández, Irati Zamalloa \n",
            "Date: 2018-02-12 14:49:46+00:00 \n",
            "Id: 1802.04082 \n",
            "Summary: We argue that hardware modularity plays a key role in the convergence of\n",
            "Robotics and Artificial Intelligence (AI). We introduce a new approach for\n",
            "building robots that leads to more adaptable and capable machines. We present\n",
            "the concept of a self-adaptable robot that makes use of hardware modularity and\n",
            "AI techniques to reduce the effort and time required to be built. We\n",
            "demonstrate in simulation and with a real robot how, rather than programming,\n",
            "training produces behaviors in the robot that generalize fast and produce\n",
            "robust outputs in the presence of noise. In particular, we advocate for\n",
            "mammals. \n",
            "URL: http://arxiv.org/pdf/1802.04082v1 \n",
            "\n",
            "\n",
            "153\n",
            "cs\n",
            "Title: Towards Ophthalmologist Level Accurate Deep Learning System for OCT Screening and Diagnosis \n",
            "Authors: Mrinal Haloi \n",
            "Date: 2018-12-12 14:42:10+00:00 \n",
            "Id: 1812.07105 \n",
            "Summary: In this work, we propose an advanced AI based grading system for OCT images.\n",
            "The proposed system is a very deep fully convolutional attentive classification\n",
            "network trained with end to end advanced transfer learning with online random\n",
            "augmentation. It uses quasi random augmentation that outputs confidence values\n",
            "for diseases prevalence during inference. Its a fully automated retinal OCT\n",
            "analysis AI system capable of pathological lesions understanding without any\n",
            "offline preprocessing/postprocessing step or manual feature extraction. We\n",
            "present a state of the art performance on the publicly available Mendeley OCT\n",
            "dataset. \n",
            "URL: http://arxiv.org/pdf/1812.07105v1 \n",
            "\n",
            "\n",
            "154\n",
            "cs\n",
            "Title: Using Pupil Diameter to Measure Cognitive Load \n",
            "Authors: Georgios Minadakis, Katrin Lohan \n",
            "Date: 2018-11-29 20:31:45+00:00 \n",
            "Id: 1812.07653 \n",
            "Summary: In this paper, we will present a method for measuring cognitive load and\n",
            "online real-time feedback using the Tobii Pro 2 eye-tracking glasses. The\n",
            "system is envisaged to be capable of estimating high cognitive load states and\n",
            "situations, and adjust human-machine interfaces to the user's needs. The system\n",
            "is using well-known metrics such as average pupillary size over time. Our\n",
            "system can provide cognitive load feedback at 17-18 Hz. We will elaborate on\n",
            "our results of a HRI study using this tool to show it's functionality. \n",
            "URL: http://arxiv.org/pdf/1812.07653v1 \n",
            "\n",
            "\n",
            "155\n",
            "cs\n",
            "Title: Personal Universes: A Solution to the Multi-Agent Value Alignment Problem \n",
            "Authors: Roman V. Yampolskiy \n",
            "Date: 2019-01-01 18:05:43+00:00 \n",
            "Id: 1901.01851 \n",
            "Summary: AI Safety researchers attempting to align values of highly capable\n",
            "intelligent systems with those of humanity face a number of challenges\n",
            "including personal value extraction, multi-agent value merger and finally\n",
            "in-silico encoding. State-of-the-art research in value alignment shows\n",
            "difficulties in every stage in this process, but merger of incompatible\n",
            "preferences is a particularly difficult challenge to overcome. In this paper we\n",
            "assume that the value extraction problem will be solved and propose a possible\n",
            "way to implement an AI solution which optimally aligns with individual\n",
            "preferences of each user. We conclude by analyzing benefits and limitations of\n",
            "the proposed approach. \n",
            "URL: http://arxiv.org/pdf/1901.01851v1 \n",
            "\n",
            "\n",
            "156\n",
            "cs\n",
            "Title: Face Attribute Invertion \n",
            "Authors: X G Tu, Y Luo, H S Zhang, W J Ai, Z Ma, M Xie \n",
            "Date: 2020-01-14 08:41:52+00:00 \n",
            "Id: 2001.04665 \n",
            "Summary: Manipulating human facial images between two domains is an important and\n",
            "interesting problem. Most of the existing methods address this issue by\n",
            "applying two generators or one generator with extra conditional inputs. In this\n",
            "paper, we proposed a novel self-perception method based on GANs for automatical\n",
            "face attribute inverse. The proposed method takes face images as inputs and\n",
            "employs only one single generator without being conditioned on other inputs.\n",
            "Profiting from the multi-loss strategy and modified U-net structure, our model\n",
            "is quite stable in training and capable of preserving finer details of the\n",
            "original face images. \n",
            "URL: http://arxiv.org/pdf/2001.04665v1 \n",
            "\n",
            "\n",
            "158\n",
            "cs\n",
            "Title: The Work of Art in an Age of Mechanical Generation \n",
            "Authors: Steven J. Frank \n",
            "Date: 2021-01-27 18:32:58+00:00 \n",
            "Id: 2101.11587 \n",
            "Summary: Can we define what it means to be \"creative,\" and if so, can our definition\n",
            "drive artificial intelligence (AI) systems to feats of creativity\n",
            "indistinguishable from human efforts? This mixed question is considered from\n",
            "technological and social perspectives. Beginning with an exploration of the\n",
            "value we attach to authenticity in works of art, the article considers the\n",
            "ability of AI to detect forgeries of renowned paintings and, in so doing,\n",
            "somehow reveal the quiddity of a work of art. We conclude by considering\n",
            "whether evolving technical capability can revise traditional relationships\n",
            "among art, artist, and the market. \n",
            "URL: http://arxiv.org/pdf/2101.11587v1 \n",
            "\n",
            "\n",
            "159\n",
            "cs\n",
            "Title: Abstraction and Analogy-Making in Artificial Intelligence \n",
            "Authors: Melanie Mitchell \n",
            "Date: 2021-02-22 00:12:48+00:00 \n",
            "Id: 2102.10717 \n",
            "Summary: Conceptual abstraction and analogy-making are key abilities underlying\n",
            "humans' abilities to learn, reason, and robustly adapt their knowledge to new\n",
            "domains. Despite of a long history of research on constructing AI systems with\n",
            "these abilities, no current AI system is anywhere close to a capability of\n",
            "forming humanlike abstractions or analogies. This paper reviews the advantages\n",
            "and limitations of several approaches toward this goal, including symbolic\n",
            "methods, deep learning, and probabilistic program induction. The paper\n",
            "concludes with several proposals for designing challenge tasks and evaluation\n",
            "measures in order to make quantifiable and generalizable progress in this area. \n",
            "URL: http://arxiv.org/pdf/2102.10717v2 \n",
            "\n",
            "\n",
            "160\n",
            "cs\n",
            "Title: Towards Artificial Intelligence Enabled Financial Crime Detection \n",
            "Authors: Zeinab Rouhollahi \n",
            "Date: 2021-05-23 06:57:25+00:00 \n",
            "Id: 2105.10866 \n",
            "Summary: Recently, financial institutes have been dealing with an increase in\n",
            "financial crimes. In this context, financial services firms started to improve\n",
            "their vigilance and use new technologies and approaches to identify and predict\n",
            "financial fraud and crime possibilities. This task is challenging as\n",
            "institutions need to upgrade their data and analytics capabilities to enable\n",
            "new technologies such as Artificial Intelligence (AI) to predict and detect\n",
            "financial crimes. In this paper, we put a step towards AI-enabled financial\n",
            "crime detection in general and money laundering detection in particular to\n",
            "address this challenge. We study and analyse the recent works done in financial\n",
            "crime detection and present a novel model to detect money laundering cases with\n",
            "minimum human intervention needs. \n",
            "URL: http://arxiv.org/pdf/2105.10866v1 \n",
            "\n",
            "\n",
            "163\n",
            "cs\n",
            "Title: Improving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI \n",
            "Authors: Erico Tjoa, Hong Jing Khok, Tushar Chouhan, Guan Cuntai \n",
            "Date: 2021-12-30 12:46:23+00:00 \n",
            "Id: 2201.00009 \n",
            "Summary: This paper quantifies the quality of heatmap-based eXplainable AI methods\n",
            "w.r.t image classification problem. Here, a heatmap is considered desirable if\n",
            "it improves the probability of predicting the correct classes. Different XAI\n",
            "heatmap-based methods are empirically shown to improve classification\n",
            "confidence to different extents depending on the datasets, e.g. Saliency works\n",
            "best on ImageNet and Deconvolution on ChestX-Ray Pneumonia dataset. The novelty\n",
            "includes a new gap distribution that shows a stark difference between correct\n",
            "and wrong predictions. Finally, the generative augmentative explanation is\n",
            "introduced, a method to generate heatmaps maps capable of improving predictive\n",
            "confidence to a high level. \n",
            "URL: http://arxiv.org/pdf/2201.00009v2 \n",
            "\n",
            "\n",
            "164\n",
            "cs\n",
            "Title: A Policy Driven AI-Assisted PoW Framework \n",
            "Authors: Trisha Chakraborty, Shaswata Mitra, Sudip Mittal, Maxwell Young \n",
            "Date: 2022-03-21 01:36:55+00:00 \n",
            "Id: 2203.10698 \n",
            "Summary: Proof of Work (PoW) based cyberdefense systems require incoming network\n",
            "requests to expend effort solving an arbitrary mathematical puzzle. Current\n",
            "state of the art is unable to differentiate between trustworthy and\n",
            "untrustworthy connections, requiring all to solve complex puzzles. In this\n",
            "paper, we introduce an Artificial Intelligence (AI)-assisted PoW framework that\n",
            "utilizes IP traffic based features to inform an adaptive issuer which can then\n",
            "generate puzzles with varying hardness. The modular framework uses these\n",
            "capabilities to ensure that untrustworthy clients solve harder puzzles thereby\n",
            "incurring longer latency than authentic requests to receive a response from the\n",
            "server. Our preliminary findings reveal our approach effectively throttles\n",
            "untrustworthy traffic. \n",
            "URL: http://arxiv.org/pdf/2203.10698v1 \n",
            "\n",
            "\n",
            "165\n",
            "cs\n",
            "Title: AIS for Misbehavior Detection in Wireless Sensor Networks: Performance and Design Principles \n",
            "Authors: Martin Drozda, Sven Schaust, Helena Szczerbicka \n",
            "Date: 2009-06-18 15:31:29+00:00 \n",
            "Id: 0906.3461 \n",
            "Summary: A sensor network is a collection of wireless devices that are able to monitor\n",
            "physical or environmental conditions. These devices (nodes) are expected to\n",
            "operate autonomously, be battery powered and have very limited computational\n",
            "capabilities. This makes the task of protecting a sensor network against\n",
            "misbehavior or possible malfunction a challenging problem. In this document we\n",
            "discuss performance of Artificial immune systems (AIS) when used as the\n",
            "mechanism for detecting misbehavior.\n",
            "  We show that (i) mechanism of the AIS have to be carefully applied in order\n",
            "to avoid security weaknesses, (ii) the choice of genes and their interaction\n",
            "have a profound influence on the performance of the AIS, (iii) randomly created\n",
            "detectors do not comply with limitations imposed by communications protocols\n",
            "and (iv) the data traffic pattern seems not to impact significantly the overall\n",
            "performance.\n",
            "  We identified a specific MAC layer based gene that showed to be especially\n",
            "useful for detection; genes measure a network's performance from a node's\n",
            "viewpoint. Furthermore, we identified an interesting complementarity property\n",
            "of genes; this property exploits the local nature of sensor networks and moves\n",
            "the burden of excessive communication from normally behaving nodes to\n",
            "misbehaving nodes. These results have a direct impact on the design of AIS for\n",
            "sensor networks and on engineering of sensor networks. \n",
            "URL: http://arxiv.org/pdf/0906.3461v1 \n",
            "\n",
            "\n",
            "166\n",
            "cs\n",
            "Title: AI Enabling Technologies: A Survey \n",
            "Authors: Vijay Gadepally, Justin Goodwin, Jeremy Kepner, Albert Reuther, Hayley Reynolds, Siddharth Samsi, Jonathan Su, David Martinez \n",
            "Date: 2019-05-08 15:41:38+00:00 \n",
            "Id: 1905.03592 \n",
            "Summary: Artificial Intelligence (AI) has the opportunity to revolutionize the way the\n",
            "United States Department of Defense (DoD) and Intelligence Community (IC)\n",
            "address the challenges of evolving threats, data deluge, and rapid courses of\n",
            "action. Developing an end-to-end artificial intelligence system involves\n",
            "parallel development of different pieces that must work together in order to\n",
            "provide capabilities that can be used by decision makers, warfighters and\n",
            "analysts. These pieces include data collection, data conditioning, algorithms,\n",
            "computing, robust artificial intelligence, and human-machine teaming. While\n",
            "much of the popular press today surrounds advances in algorithms and computing,\n",
            "most modern AI systems leverage advances across numerous different fields.\n",
            "Further, while certain components may not be as visible to end-users as others,\n",
            "our experience has shown that each of these interrelated components play a\n",
            "major role in the success or failure of an AI system. This article is meant to\n",
            "highlight many of these technologies that are involved in an end-to-end AI\n",
            "system. The goal of this article is to provide readers with an overview of\n",
            "terminology, technical details and recent highlights from academia, industry\n",
            "and government. Where possible, we indicate relevant resources that can be used\n",
            "for further reading and understanding. \n",
            "URL: http://arxiv.org/pdf/1905.03592v1 \n",
            "\n",
            "\n",
            "167\n",
            "cs\n",
            "Title: A Deep Learning based Wearable Healthcare IoT Device for AI-enabled Hearing Assistance Automation \n",
            "Authors: Fraser Young, L Zhang, Richard Jiang, Han Liu, Conor Wall \n",
            "Date: 2020-05-16 19:42:16+00:00 \n",
            "Id: 2005.08076 \n",
            "Summary: With the recent booming of artificial intelligence (AI), particularly deep\n",
            "learning techniques, digital healthcare is one of the prevalent areas that\n",
            "could gain benefits from AI-enabled functionality. This research presents a\n",
            "novel AI-enabled Internet of Things (IoT) device operating from the ESP-8266\n",
            "platform capable of assisting those who suffer from impairment of hearing or\n",
            "deafness to communicate with others in conversations. In the proposed solution,\n",
            "a server application is created that leverages Google's online speech\n",
            "recognition service to convert the received conversations into texts, then\n",
            "deployed to a micro-display attached to the glasses to display the conversation\n",
            "contents to deaf people, to enable and assist conversation as normal with the\n",
            "general population. Furthermore, in order to raise alert of traffic or\n",
            "dangerous scenarios, an 'urban-emergency' classifier is developed using a deep\n",
            "learning model, Inception-v4, with transfer learning to detect/recognize\n",
            "alerting/alarming sounds, such as a horn sound or a fire alarm, with texts\n",
            "generated to alert the prospective user. The training of Inception-v4 was\n",
            "carried out on a consumer desktop PC and then implemented into the AI based IoT\n",
            "application. The empirical results indicate that the developed prototype system\n",
            "achieves an accuracy rate of 92% for sound recognition and classification with\n",
            "real-time performance. \n",
            "URL: http://arxiv.org/pdf/2005.08076v1 \n",
            "\n",
            "\n",
            "168\n",
            "cs\n",
            "Title: Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI \n",
            "Authors: Dakuo Wang, Justin D. Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, Alexander Gray \n",
            "Date: 2019-09-05 10:39:37+00:00 \n",
            "Id: 1909.02309 \n",
            "Summary: The rapid advancement of artificial intelligence (AI) is changing our lives\n",
            "in many ways. One application domain is data science. New techniques in\n",
            "automating the creation of AI, known as AutoAI or AutoML, aim to automate the\n",
            "work practices of data scientists. AutoAI systems are capable of autonomously\n",
            "ingesting and pre-processing data, engineering new features, and creating and\n",
            "scoring models based on a target objectives (e.g. accuracy or run-time\n",
            "efficiency). Though not yet widely adopted, we are interested in understanding\n",
            "how AutoAI will impact the practice of data science. We conducted interviews\n",
            "with 20 data scientists who work at a large, multinational technology company\n",
            "and practice data science in various business settings. Our goal is to\n",
            "understand their current work practices and how these practices might change\n",
            "with AutoAI. Reactions were mixed: while informants expressed concerns about\n",
            "the trend of automating their jobs, they also strongly felt it was inevitable.\n",
            "Despite these concerns, they remained optimistic about their future job\n",
            "security due to a view that the future of data science work will be a\n",
            "collaboration between humans and AI systems, in which both automation and human\n",
            "expertise are indispensable. \n",
            "URL: http://arxiv.org/pdf/1909.02309v1 \n",
            "\n",
            "\n",
            "169\n",
            "cs\n",
            "Title: Towards Effective Human-AI Teams: The Case of Collaborative Packing \n",
            "Authors: Gilwoo Lee, Christoforos Mavrogiannis, Siddhartha S. Srinivasa \n",
            "Date: 2019-09-14 04:13:35+00:00 \n",
            "Id: 1909.06527 \n",
            "Summary: We focus on the problem of designing an artificial agent (AI), capable of\n",
            "assisting a human user to complete a task. Our goal is to guide human users\n",
            "towards optimal task performance while keeping their cognitive load as low as\n",
            "possible. Our insight is that doing so requires an understanding of human\n",
            "decision making for the task domain at hand. In this work, we consider the\n",
            "domain of collaborative packing, in which an AI agent provides placement\n",
            "recommendations to a human user. As a first step, we explore the mechanisms\n",
            "underlying human packing strategies. We conducted a user study in which 100\n",
            "human participants completed a series of packing tasks in a virtual\n",
            "environment. We analyzed their packing strategies and discovered spatial and\n",
            "temporal patterns, such as that humans tend to place larger items at corners\n",
            "first. We expect that imbuing an artificial agent with an understanding of this\n",
            "spatiotemporal structure will enable improved assistance, which will be\n",
            "reflected in the task performance and the human perception of the AI. Ongoing\n",
            "work involves the development of a framework that incorporates the extracted\n",
            "insights to predict and manipulate human decision making towards an efficient\n",
            "trajectory of low cognitive load and high efficiency. A follow-up study will\n",
            "evaluate our framework against a set of baselines featuring alternative\n",
            "strategies of assistance. Our eventual goal is the deployment and evaluation of\n",
            "our framework on an autonomous robotic manipulator, actively assisting users on\n",
            "a packing task. \n",
            "URL: http://arxiv.org/pdf/1909.06527v3 \n",
            "\n",
            "\n",
            "170\n",
            "cs\n",
            "Title: Breaking the Memory Wall for AI Chip with a New Dimension \n",
            "Authors: Eugene Tam, Shenfei Jiang, Paul Duan, Shawn Meng, Yue Pang, Cayden Huang, Yi Han, Jacke Xie, Yuanjun Cui, Jinsong Yu, Minggui Lu \n",
            "Date: 2020-09-28 22:34:10+00:00 \n",
            "Id: 2009.13664 \n",
            "Summary: Recent advancements in deep learning have led to the widespread adoption of\n",
            "artificial intelligence (AI) in applications such as computer vision and\n",
            "natural language processing. As neural networks become deeper and larger, AI\n",
            "modeling demands outstrip the capabilities of conventional chip architectures.\n",
            "Memory bandwidth falls behind processing power. Energy consumption comes to\n",
            "dominate the total cost of ownership. Currently, memory capacity is\n",
            "insufficient to support the most advanced NLP models. In this work, we present\n",
            "a 3D AI chip, called Sunrise, with near-memory computing architecture to\n",
            "address these three challenges. This distributed, near-memory computing\n",
            "architecture allows us to tear down the performance-limiting memory wall with\n",
            "an abundance of data bandwidth. We achieve the same level of energy efficiency\n",
            "on 40nm technology as competing chips on 7nm technology. By moving to similar\n",
            "technologies as other AI chips, we project to achieve more than ten times the\n",
            "energy efficiency, seven times the performance of the current state-of-the-art\n",
            "chips, and twenty times of memory capacity as compared with the best chip in\n",
            "each benchmark. \n",
            "URL: http://arxiv.org/pdf/2009.13664v1 \n",
            "\n",
            "\n",
            "171\n",
            "cs\n",
            "Title: Legal Sentiment Analysis and Opinion Mining (LSAOM): Assimilating Advances in Autonomous AI Legal Reasoning \n",
            "Authors: Lance Eliot \n",
            "Date: 2020-10-02 04:15:21+00:00 \n",
            "Id: 2010.02726 \n",
            "Summary: An expanding field of substantive interest for the theory of the law and the\n",
            "practice-of-law entails Legal Sentiment Analysis and Opinion Mining (LSAOM),\n",
            "consisting of two often intertwined phenomena and actions underlying legal\n",
            "discussions and narratives: (1) Sentiment Analysis (SA) for the detection of\n",
            "expressed or implied sentiment about a legal matter within the context of a\n",
            "legal milieu, and (2) Opinion Mining (OM) for the identification and\n",
            "illumination of explicit or implicit opinion accompaniments immersed within\n",
            "legal discourse. Efforts to undertake LSAOM have historically been performed by\n",
            "human hand and cognition, and only thinly aided in more recent times by the use\n",
            "of computer-based approaches. Advances in Artificial Intelligence (AI)\n",
            "involving especially Natural Language Processing (NLP) and Machine Learning\n",
            "(ML) are increasingly bolstering how automation can systematically perform\n",
            "either or both of Sentiment Analysis and Opinion Mining, all of which is being\n",
            "inexorably carried over into engagement within a legal context for improving\n",
            "LSAOM capabilities. This research paper examines the evolving infusion of AI\n",
            "into Legal Sentiment Analysis and Opinion Mining and proposes an alignment with\n",
            "the Levels of Autonomy (LoA) of AI Legal Reasoning (AILR), plus provides\n",
            "additional insights regarding AI LSAOM in its mechanizations and potential\n",
            "impact to the study of law and the practicing of law. \n",
            "URL: http://arxiv.org/pdf/2010.02726v1 \n",
            "\n",
            "\n",
            "172\n",
            "cs\n",
            "Title: AI Song Contest: Human-AI Co-Creation in Songwriting \n",
            "Authors: Cheng-Zhi Anna Huang, Hendrik Vincent Koops, Ed Newton-Rex, Monica Dinculescu, Carrie J. Cai \n",
            "Date: 2020-10-12 01:27:41+00:00 \n",
            "Id: 2010.05388 \n",
            "Summary: Machine learning is challenging the way we make music. Although research in\n",
            "deep generative models has dramatically improved the capability and fluency of\n",
            "music models, recent work has shown that it can be challenging for humans to\n",
            "partner with this new class of algorithms. In this paper, we present findings\n",
            "on what 13 musician/developer teams, a total of 61 users, needed when\n",
            "co-creating a song with AI, the challenges they faced, and how they leveraged\n",
            "and repurposed existing characteristics of AI to overcome some of these\n",
            "challenges. Many teams adopted modular approaches, such as independently\n",
            "running multiple smaller models that align with the musical building blocks of\n",
            "a song, before re-combining their results. As ML models are not easily\n",
            "steerable, teams also generated massive numbers of samples and curated them\n",
            "post-hoc, or used a range of strategies to direct the generation, or\n",
            "algorithmically ranked the samples. Ultimately, teams not only had to manage\n",
            "the \"flare and focus\" aspects of the creative process, but also juggle them\n",
            "with a parallel process of exploring and curating multiple ML models and\n",
            "outputs. These findings reflect a need to design machine learning-powered music\n",
            "interfaces that are more decomposable, steerable, interpretable, and adaptive,\n",
            "which in return will enable artists to more effectively explore how AI can\n",
            "extend their personal expression. \n",
            "URL: http://arxiv.org/pdf/2010.05388v1 \n",
            "\n",
            "\n",
            "173\n",
            "cs\n",
            "Title: A framework for fostering transparency in shared artificial intelligence models by increasing visibility of contributions \n",
            "Authors: Iain Barclay, Harrison Taylor, Alun Preece, Ian Taylor, Dinesh Verma, Geeth de Mel \n",
            "Date: 2021-03-05 11:28:50+00:00 \n",
            "Id: 2103.03610 \n",
            "Summary: Increased adoption of artificial intelligence (AI) systems into scientific\n",
            "workflows will result in an increasing technical debt as the distance between\n",
            "the data scientists and engineers who develop AI system components and\n",
            "scientists, researchers and other users grows. This could quickly become\n",
            "problematic, particularly where guidance or regulations change and\n",
            "once-acceptable best practice becomes outdated, or where data sources are later\n",
            "discredited as biased or inaccurate. This paper presents a novel method for\n",
            "deriving a quantifiable metric capable of ranking the overall transparency of\n",
            "the process pipelines used to generate AI systems, such that users, auditors\n",
            "and other stakeholders can gain confidence that they will be able to validate\n",
            "and trust the data sources and contributors in the AI systems that they rely\n",
            "on. The methodology for calculating the metric, and the type of criteria that\n",
            "could be used to make judgements on the visibility of contributions to systems\n",
            "are evaluated through models published at ModelHub and PyTorch Hub, popular\n",
            "archives for sharing science resources, and is found to be helpful in driving\n",
            "consideration of the contributions made to generating AI systems and approaches\n",
            "towards effective documentation and improving transparency in machine learning\n",
            "assets shared within scientific communities. \n",
            "URL: http://arxiv.org/pdf/2103.03610v1 \n",
            "\n",
            "\n",
            "174\n",
            "cs\n",
            "Title: Hybrid Intelligence \n",
            "Authors: Dominik Dellermann, Philipp Ebel, Matthias Soellner, Jan Marco Leimeister \n",
            "Date: 2021-05-03 08:56:09+00:00 \n",
            "Id: 2105.00691 \n",
            "Summary: Research has a long history of discussing what is superior in predicting\n",
            "certain outcomes: statistical methods or the human brain. This debate has\n",
            "repeatedly been sparked off by the remarkable technological advances in the\n",
            "field of artificial intelligence (AI), such as solving tasks like object and\n",
            "speech recognition, achieving significant improvements in accuracy through\n",
            "deep-learning algorithms (Goodfellow et al. 2016), or combining various methods\n",
            "of computational intelligence, such as fuzzy logic, genetic algorithms, and\n",
            "case-based reasoning (Medsker 2012). One of the implicit promises that underlie\n",
            "these advancements is that machines will 1 day be capable of performing complex\n",
            "tasks or may even supersede humans in performing these tasks. This triggers new\n",
            "heated debates of when machines will ultimately replace humans (McAfee and\n",
            "Brynjolfsson 2017). While previous research has proved that AI performs well in\n",
            "some clearly defined tasks such as playing chess, playing Go or identifying\n",
            "objects on images, it is doubted that the development of an artificial general\n",
            "intelligence (AGI) which is able to solve multiple tasks at the same time can\n",
            "be achieved in the near future (e.g., Russell and Norvig 2016). Moreover, the\n",
            "use of AI to solve complex business problems in organizational contexts occurs\n",
            "scarcely, and applications for AI that solve complex problems remain mainly in\n",
            "laboratory settings instead of being implemented in practice. Since the road to\n",
            "AGI is still a long one, we argue that the most likely paradigm for the\n",
            "division of labor between humans and machines in the next decades is Hybrid\n",
            "Intelligence. This concept aims at using the complementary strengths of human\n",
            "intelligence and AI, so that they can perform better than each of the two could\n",
            "separately (e.g., Kamar 2016). \n",
            "URL: http://arxiv.org/pdf/2105.00691v1 \n",
            "\n",
            "\n",
            "175\n",
            "cs\n",
            "Title: Artificial Intelligence in Dry Eye Disease \n",
            "Authors: Andrea M. Storås, Inga Strümke, Michael A. Riegler, Jakob Grauslund, Hugo L. Hammer, Anis Yazidi, Pål Halvorsen, Kjell G. Gundersen, Tor P. Utheim, Catherine Jackson \n",
            "Date: 2021-09-02 10:17:50+00:00 \n",
            "Id: 2109.01658 \n",
            "Summary: Dry eye disease (DED) has a prevalence of between 5 and 50\\%, depending on\n",
            "the diagnostic criteria used and population under study. However, it remains\n",
            "one of the most underdiagnosed and undertreated conditions in ophthalmology.\n",
            "Many tests used in the diagnosis of DED rely on an experienced observer for\n",
            "image interpretation, which may be considered subjective and result in\n",
            "variation in diagnosis. Since artificial intelligence (AI) systems are capable\n",
            "of advanced problem solving, use of such techniques could lead to more\n",
            "objective diagnosis. Although the term `AI' is commonly used, recent success in\n",
            "its applications to medicine is mainly due to advancements in the sub-field of\n",
            "machine learning, which has been used to automatically classify images and\n",
            "predict medical outcomes. Powerful machine learning techniques have been\n",
            "harnessed to understand nuances in patient data and medical images, aiming for\n",
            "consistent diagnosis and stratification of disease severity. This is the first\n",
            "literature review on the use of AI in DED. We provide a brief introduction to\n",
            "AI, report its current use in DED research and its potential for application in\n",
            "the clinic. Our review found that AI has been employed in a wide range of DED\n",
            "clinical tests and research applications, primarily for interpretation of\n",
            "interferometry, slit-lamp and meibography images. While initial results are\n",
            "promising, much work is still needed on model development, clinical testing and\n",
            "standardisation. \n",
            "URL: http://arxiv.org/pdf/2109.01658v1 \n",
            "\n",
            "\n",
            "176\n",
            "cs\n",
            "Title: Edge-Cloud Polarization and Collaboration: A Comprehensive Survey for AI \n",
            "Authors: Jiangchao Yao, Shengyu Zhang, Yang Yao, Feng Wang, Jianxin Ma, Jianwei Zhang, Yunfei Chu, Luo Ji, Kunyang Jia, Tao Shen, Anpeng Wu, Fengda Zhang, Ziqi Tan, Kun Kuang, Chao Wu, Fei Wu, Jingren Zhou, Hongxia Yang \n",
            "Date: 2021-11-11 05:58:23+00:00 \n",
            "Id: 2111.06061 \n",
            "Summary: Influenced by the great success of deep learning via cloud computing and the\n",
            "rapid development of edge chips, research in artificial intelligence (AI) has\n",
            "shifted to both of the computing paradigms, i.e., cloud computing and edge\n",
            "computing. In recent years, we have witnessed significant progress in\n",
            "developing more advanced AI models on cloud servers that surpass traditional\n",
            "deep learning models owing to model innovations (e.g., Transformers, Pretrained\n",
            "families), explosion of training data and soaring computing capabilities.\n",
            "However, edge computing, especially edge and cloud collaborative computing, are\n",
            "still in its infancy to announce their success due to the resource-constrained\n",
            "IoT scenarios with very limited algorithms deployed. In this survey, we conduct\n",
            "a systematic review for both cloud and edge AI. Specifically, we are the first\n",
            "to set up the collaborative learning mechanism for cloud and edge modeling with\n",
            "a thorough review of the architectures that enable such mechanism. We also\n",
            "discuss potentials and practical experiences of some on-going advanced edge AI\n",
            "topics including pretraining models, graph neural networks and reinforcement\n",
            "learning. Finally, we discuss the promising directions and challenges in this\n",
            "field. \n",
            "URL: http://arxiv.org/pdf/2111.06061v3 \n",
            "\n",
            "\n",
            "177\n",
            "cs\n",
            "Title: A real-time spatiotemporal AI model analyzes skill in open surgical videos \n",
            "Authors: Emmett D. Goodman, Krishna K. Patel, Yilun Zhang, William Locke, Chris J. Kennedy, Rohan Mehrotra, Stephen Ren, Melody Y. Guan, Maren Downing, Hao Wei Chen, Jevin Z. Clark, Gabriel A. Brat, Serena Yeung \n",
            "Date: 2021-12-14 08:11:02+00:00 \n",
            "Id: 2112.07219 \n",
            "Summary: Open procedures represent the dominant form of surgery worldwide. Artificial\n",
            "intelligence (AI) has the potential to optimize surgical practice and improve\n",
            "patient outcomes, but efforts have focused primarily on minimally invasive\n",
            "techniques. Our work overcomes existing data limitations for training AI models\n",
            "by curating, from YouTube, the largest dataset of open surgical videos to date:\n",
            "1997 videos from 23 surgical procedures uploaded from 50 countries. Using this\n",
            "dataset, we developed a multi-task AI model capable of real-time understanding\n",
            "of surgical behaviors, hands, and tools - the building blocks of procedural\n",
            "flow and surgeon skill. We show that our model generalizes across diverse\n",
            "surgery types and environments. Illustrating this generalizability, we directly\n",
            "applied our YouTube-trained model to analyze open surgeries prospectively\n",
            "collected at an academic medical center and identified kinematic descriptors of\n",
            "surgical skill related to efficiency of hand motion. Our Annotated Videos of\n",
            "Open Surgery (AVOS) dataset and trained model will be made available for\n",
            "further development of surgical AI. \n",
            "URL: http://arxiv.org/pdf/2112.07219v1 \n",
            "\n",
            "\n",
            "178\n",
            "cs\n",
            "Title: Development and Validation of an AI-Driven Model for the La Rance Tidal Barrage: A Generalisable Case Study \n",
            "Authors: Túlio Marcondes Moreira, Jackson Geraldo de Faria Jr, Pedro O. S. Vaz-de-Melo, Gilberto Medeiros-Ribeiro \n",
            "Date: 2022-02-10 22:02:52+00:00 \n",
            "Id: 2202.05347 \n",
            "Summary: In this work, an AI-Driven (autonomous) model representation of the La Rance\n",
            "tidal barrage was developed using novel parametrisation and Deep Reinforcement\n",
            "Learning (DRL) techniques. Our model results were validated with experimental\n",
            "measurements, yielding the first Tidal Range Structure (TRS) model validated\n",
            "against a constructed tidal barrage and made available to academics. In order\n",
            "to proper model La Rance, parametrisation methodologies were developed for\n",
            "simulating (i) turbines (in pumping and power generation modes), (ii)\n",
            "transition ramp functions (for opening and closing hydraulic structures) and\n",
            "(iii) equivalent lagoon wetted area. Furthermore, an updated DRL method was\n",
            "implemented for optimising the operation of the hydraulic structures that\n",
            "compose La Rance. The achieved objective of this work was to verify the\n",
            "capabilities of an AI-Driven TRS model to appropriately predict (i) turbine\n",
            "power and (ii) lagoon water level variations. In addition, the observed\n",
            "operational strategy and yearly energy output of our AI-Driven model appeared\n",
            "to be comparable with those reported for the La Rance tidal barrage. The\n",
            "outcomes of this work (developed methodologies and DRL implementations) are\n",
            "generalisable and can be applied to other TRS projects. Furthermore, this work\n",
            "provided insights which allow for more realistic simulation of TRS operation,\n",
            "enabled through our AI-Driven model. \n",
            "URL: http://arxiv.org/pdf/2202.05347v1 \n",
            "\n",
            "\n",
            "179\n",
            "cs\n",
            "Title: LwHBench: A low-level hardware component benchmark and dataset for Single Board Computers \n",
            "Authors: Pedro Miguel Sánchez Sánchez, José María Jorquera Valero, Alberto Huertas Celdrán, Gérôme Bovet, Manuel Gil Pérez, Gregorio Martínez Pérez \n",
            "Date: 2022-04-18 18:58:38+00:00 \n",
            "Id: 2204.08516 \n",
            "Summary: In today's computing environment, where Artificial Intelligence (AI) and data\n",
            "processing are moving toward the Internet of Things (IoT) and the Edge\n",
            "computing paradigm, benchmarking resource-constrained devices is a critical\n",
            "task to evaluate their suitability and performance. The literature has\n",
            "extensively explored the performance of IoT devices when running high-level\n",
            "benchmarks specialized in particular application scenarios, such as AI or\n",
            "medical applications. However, lower-level benchmarking applications and\n",
            "datasets that analyze the hardware components of each device are needed. This\n",
            "low-level device understanding enables new AI solutions for network, system and\n",
            "service management based on device performance, such as individual device\n",
            "identification, so it is an area worth exploring more in detail. In this paper,\n",
            "we present LwHBench, a low-level hardware benchmarking application for\n",
            "Single-Board Computers that measures the performance of CPU, GPU, Memory and\n",
            "Storage taking into account the component constraints in these types of\n",
            "devices. LwHBench has been implemented for Raspberry Pi devices and run for 100\n",
            "days on a set of 45 devices to generate an extensive dataset that allows the\n",
            "usage of AI techniques in different application scenarios. Finally, to\n",
            "demonstrate the inter-scenario capability of the created dataset, a series of\n",
            "AI-enabled use cases about device identification and context impact on\n",
            "performance are presented as examples and exploration of the published data. \n",
            "URL: http://arxiv.org/pdf/2204.08516v1 \n",
            "\n",
            "\n",
            "180\n",
            "cs\n",
            "Title: Analyzing the Adoption Challenges of the Internet of Things (IoT) and Artificial Intelligence (AI) for Smart Cities in China \n",
            "Authors: Ke Wang, Yafei Zhao, Rajan Kumar Gangadhari, Zhixing Li \n",
            "Date: 2022-04-22 14:57:52+00:00 \n",
            "Id: 2205.01067 \n",
            "Summary: Smart cities play a vital role in the growth of a nation. In recent years,\n",
            "several countries have made huge investments in developing smart cities to\n",
            "offer sustainable living. However, there are some challenges to overcome in\n",
            "smart city development, such as traffic and transportation man-agement, energy\n",
            "and water distribution and management, air quality and waste management\n",
            "monitoring, etc. The capabilities of the Internet of Things (IoT) and\n",
            "artificial intelligence (AI) can help to achieve some goals of smart cities,\n",
            "and there are proven examples from some cities like Singapore, Copenhagen, etc.\n",
            "However, the adoption of AI and the IoT in developing countries has some\n",
            "challenges. The analysis of challenges hindering the adoption of AI and the IoT\n",
            "are very limited. This study aims to fill this research gap by analyzing the\n",
            "causal relationships among the challenges in smart city development, and\n",
            "contains several parts that conclude the previous scholars work, as well as\n",
            "independent research and investigation, such as data collection and analysis\n",
            "based on DEMATEL. In this paper, we have reviewed the literature to extract key\n",
            "chal-lenges for the adoption of AI and the IoT. These helped us to proceed with\n",
            "the investigation and analyze the adoption status. Therefore, using the PRISMA\n",
            "method, 10 challenges were identified from the literature review. Subsequently,\n",
            "determination of the causal inter-relationships among the key challenges based\n",
            "on expert opinions using DEMATEL is performed. This study explored the driving\n",
            "and dependent power of the challenges, and causal relationships between the\n",
            "barriers were established. \n",
            "URL: http://arxiv.org/pdf/2205.01067v1 \n",
            "\n",
            "\n",
            "181\n",
            "cs\n",
            "Title: Hi-Phy: A Benchmark for Hierarchical Physical Reasoning \n",
            "Authors: Cheng Xue, Vimukthini Pinto, Chathura Gamage, Peng Zhang, Jochen Renz \n",
            "Date: 2021-06-17 17:46:50+00:00 \n",
            "Id: 2106.09692 \n",
            "Summary: Reasoning about the behaviour of physical objects is a key capability of\n",
            "agents operating in physical worlds. Humans are very experienced in physical\n",
            "reasoning while it remains a major challenge for AI. To facilitate research\n",
            "addressing this problem, several benchmarks have been proposed recently.\n",
            "However, these benchmarks do not enable us to measure an agent's granular\n",
            "physical reasoning capabilities when solving a complex reasoning task. In this\n",
            "paper, we propose a new benchmark for physical reasoning that allows us to test\n",
            "individual physical reasoning capabilities. Inspired by how humans acquire\n",
            "these capabilities, we propose a general hierarchy of physical reasoning\n",
            "capabilities with increasing complexity. Our benchmark tests capabilities\n",
            "according to this hierarchy through generated physical reasoning tasks in the\n",
            "video game Angry Birds. This benchmark enables us to conduct a comprehensive\n",
            "agent evaluation by measuring the agent's granular physical reasoning\n",
            "capabilities. We conduct an evaluation with human players, learning agents, and\n",
            "heuristic agents and determine their capabilities. Our evaluation shows that\n",
            "learning agents, with good local generalization ability, still struggle to\n",
            "learn the underlying physical reasoning capabilities and perform worse than\n",
            "current state-of-the-art heuristic agents and humans. We believe that this\n",
            "benchmark will encourage researchers to develop intelligent agents with\n",
            "advanced, human-like physical reasoning capabilities. URL:\n",
            "https://github.com/Cheng-Xue/Hi-Phy \n",
            "URL: http://arxiv.org/pdf/2106.09692v2 \n",
            "\n",
            "\n",
            "182\n",
            "cs\n",
            "Title: The MineRL BASALT Competition on Learning from Human Feedback \n",
            "Authors: Rohin Shah, Cody Wild, Steven H. Wang, Neel Alex, Brandon Houghton, William Guss, Sharada Mohanty, Anssi Kanervisto, Stephanie Milani, Nicholay Topin, Pieter Abbeel, Stuart Russell, Anca Dragan \n",
            "Date: 2021-07-05 12:18:17+00:00 \n",
            "Id: 2107.01969 \n",
            "Summary: The last decade has seen a significant increase of interest in deep learning\n",
            "research, with many public successes that have demonstrated its potential. As\n",
            "such, these systems are now being incorporated into commercial products. With\n",
            "this comes an additional challenge: how can we build AI systems that solve\n",
            "tasks where there is not a crisp, well-defined specification? While multiple\n",
            "solutions have been proposed, in this competition we focus on one in\n",
            "particular: learning from human feedback. Rather than training AI systems using\n",
            "a predefined reward function or using a labeled dataset with a predefined set\n",
            "of categories, we instead train the AI system using a learning signal derived\n",
            "from some form of human feedback, which can evolve over time as the\n",
            "understanding of the task changes, or as the capabilities of the AI system\n",
            "improve.\n",
            "  The MineRL BASALT competition aims to spur forward research on this important\n",
            "class of techniques. We design a suite of four tasks in Minecraft for which we\n",
            "expect it will be hard to write down hardcoded reward functions. These tasks\n",
            "are defined by a paragraph of natural language: for example, \"create a\n",
            "waterfall and take a scenic picture of it\", with additional clarifying details.\n",
            "Participants must train a separate agent for each task, using any method they\n",
            "want. Agents are then evaluated by humans who have read the task description.\n",
            "To help participants get started, we provide a dataset of human demonstrations\n",
            "on each of the four tasks, as well as an imitation learning baseline that\n",
            "leverages these demonstrations.\n",
            "  Our hope is that this competition will improve our ability to build AI\n",
            "systems that do what their designers intend them to do, even when the intent\n",
            "cannot be easily formalized. Besides allowing AI to solve more tasks, this can\n",
            "also enable more effective regulation of AI systems, as well as making progress\n",
            "on the value alignment problem. \n",
            "URL: http://arxiv.org/pdf/2107.01969v1 \n",
            "\n",
            "\n",
            "183\n",
            "cs\n",
            "Title: Edge AI without Compromise: Efficient, Versatile and Accurate Neurocomputing in Resistive Random-Access Memory \n",
            "Authors: Weier Wan, Rajkumar Kubendran, Clemens Schaefer, S. Burc Eryilmaz, Wenqiang Zhang, Dabin Wu, Stephen Deiss, Priyanka Raina, He Qian, Bin Gao, Siddharth Joshi, Huaqiang Wu, H. -S. Philip Wong, Gert Cauwenberghs \n",
            "Date: 2021-08-17 21:08:51+00:00 \n",
            "Id: 2108.07879 \n",
            "Summary: Realizing today's cloud-level artificial intelligence functionalities\n",
            "directly on devices distributed at the edge of the internet calls for edge\n",
            "hardware capable of processing multiple modalities of sensory data (e.g. video,\n",
            "audio) at unprecedented energy-efficiency. AI hardware architectures today\n",
            "cannot meet the demand due to a fundamental \"memory wall\": data movement\n",
            "between separate compute and memory units consumes large energy and incurs long\n",
            "latency. Resistive random-access memory (RRAM) based compute-in-memory (CIM)\n",
            "architectures promise to bring orders of magnitude energy-efficiency\n",
            "improvement by performing computation directly within memory. However,\n",
            "conventional approaches to CIM hardware design limit its functional flexibility\n",
            "necessary for processing diverse AI workloads, and must overcome hardware\n",
            "imperfections that degrade inference accuracy. Such trade-offs between\n",
            "efficiency, versatility and accuracy cannot be addressed by isolated\n",
            "improvements on any single level of the design. By co-optimizing across all\n",
            "hierarchies of the design from algorithms and architecture to circuits and\n",
            "devices, we present NeuRRAM - the first multimodal edge AI chip using RRAM CIM\n",
            "to simultaneously deliver a high degree of versatility for diverse model\n",
            "architectures, record energy-efficiency $5\\times$ - $8\\times$ better than prior\n",
            "art across various computational bit-precisions, and inference accuracy\n",
            "comparable to software models with 4-bit weights on all measured standard AI\n",
            "benchmarks including accuracy of 99.0% on MNIST and 85.7% on CIFAR-10 image\n",
            "classification, 84.7% accuracy on Google speech command recognition, and a 70%\n",
            "reduction in image reconstruction error on a Bayesian image recovery task. This\n",
            "work paves a way towards building highly efficient and reconfigurable edge AI\n",
            "hardware platforms for the more demanding and heterogeneous AI applications of\n",
            "the future. \n",
            "URL: http://arxiv.org/pdf/2108.07879v1 \n",
            "\n",
            "\n",
            "184\n",
            "cs\n",
            "Title: Making a Bird AI Expert Work for You and Me \n",
            "Authors: Dongliang Chang, Kaiyue Pang, Ruoyi Du, Zhanyu Ma, Yi-Zhe Song, Jun Guo \n",
            "Date: 2021-12-06 02:47:21+00:00 \n",
            "Id: 2112.02747 \n",
            "Summary: As powerful as fine-grained visual classification (FGVC) is, responding your\n",
            "query with a bird name of \"Whip-poor-will\" or \"Mallard\" probably does not make\n",
            "much sense. This however commonly accepted in the literature, underlines a\n",
            "fundamental question interfacing AI and human -- what constitutes transferable\n",
            "knowledge for human to learn from AI? This paper sets out to answer this very\n",
            "question using FGVC as a test bed. Specifically, we envisage a scenario where a\n",
            "trained FGVC model (the AI expert) functions as a knowledge provider in\n",
            "enabling average people (you and me) to become better domain experts ourselves,\n",
            "i.e. those capable in distinguishing between \"Whip-poor-will\" and \"Mallard\".\n",
            "Fig. 1 lays out our approach in answering this question. Assuming an AI expert\n",
            "trained using expert human labels, we ask (i) what is the best transferable\n",
            "knowledge we can extract from AI, and (ii) what is the most practical means to\n",
            "measure the gains in expertise given that knowledge? On the former, we propose\n",
            "to represent knowledge as highly discriminative visual regions that are\n",
            "expert-exclusive. For that, we devise a multi-stage learning framework, which\n",
            "starts with modelling visual attention of domain experts and novices before\n",
            "discriminatively distilling their differences to acquire the expert exclusive\n",
            "knowledge. For the latter, we simulate the evaluation process as book guide to\n",
            "best accommodate the learning practice of what is accustomed to humans. A\n",
            "comprehensive human study of 15,000 trials shows our method is able to\n",
            "consistently improve people of divergent bird expertise to recognise once\n",
            "unrecognisable birds. Interestingly, our approach also leads to improved\n",
            "conventional FGVC performance when the extracted knowledge defined is utilised\n",
            "as means to achieve discriminative localisation. Codes are available at:\n",
            "https://github.com/PRIS-CV/Making-a-Bird-AI-Expert-Work-for-You-and-Me \n",
            "URL: http://arxiv.org/pdf/2112.02747v1 \n",
            "\n",
            "\n",
            "185\n",
            "cs\n",
            "Title: Real time Smart Contracts for IoT using Blockchain and Collaborative Intelligence based Dynamic Pricing for the next generation Smart Toll Application \n",
            "Authors: Misha Abraham, Himajit Aithal, Krishnan Mohan \n",
            "Date: 2020-02-28 11:16:26+00:00 \n",
            "Id: 2002.12654 \n",
            "Summary: The confluence of Internet of Things(IoT) , Blockchain(BC) and Artificial\n",
            "Intelligence(AI) acts as a key accelerator for enabling Machine Economy. To be\n",
            "ready for future businesses these technologies needs to be adapted by extending\n",
            "the IoT capabilities to Economy of Things (EoT) capabilities. In this paper we\n",
            "focus on one such implementation experience for Smart Toll Transaction\n",
            "application in the domain of mobility. Our paper showcases a possible solution\n",
            "by leveraging negotiations, decision making, distributed learning capabilities\n",
            "at the devices level using AI-enabled Multi-Agent Systems and the real-time\n",
            "smart contracts between the Cars and Tolls using Blockchain. This solution also\n",
            "showcases the monetization of real time data coming from various IoT devices\n",
            "which are part of vehicles and infrastructure. While blockchain secures the\n",
            "privacy of the participants it also acts as an economic transactional layer and\n",
            "governance layer between the devices in the networ \n",
            "URL: http://arxiv.org/pdf/2002.12654v1 \n",
            "\n",
            "\n",
            "186\n",
            "cs\n",
            "Title: CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities \n",
            "Authors: Mina Lee, Percy Liang, Qian Yang \n",
            "Date: 2022-01-18 07:51:57+00:00 \n",
            "Id: 2201.06796 \n",
            "Summary: Large language models (LMs) offer unprecedented language generation\n",
            "capabilities and exciting opportunities for interaction design. However, their\n",
            "highly context-dependent capabilities are difficult to grasp and are often\n",
            "subjectively interpreted. In this paper, we argue that by curating and\n",
            "analyzing large interaction datasets, the HCI community can foster more\n",
            "incisive examinations of LMs' generative capabilities. Exemplifying this\n",
            "approach, we present CoAuthor, a dataset designed for revealing GPT-3's\n",
            "capabilities in assisting creative and argumentative writing. CoAuthor captures\n",
            "rich interactions between 63 writers and four instances of GPT-3 across 1445\n",
            "writing sessions. We demonstrate that CoAuthor can address questions about\n",
            "GPT-3's language, ideation, and collaboration capabilities, and reveal its\n",
            "contribution as a writing \"collaborator\" under various definitions of good\n",
            "collaboration. Finally, we discuss how this work may facilitate a more\n",
            "principled discussion around LMs' promises and pitfalls in relation to\n",
            "interaction design. The dataset and an interface for replaying the writing\n",
            "sessions are publicly available at https://coauthor.stanford.edu. \n",
            "URL: http://arxiv.org/pdf/2201.06796v2 \n",
            "\n",
            "\n",
            "187\n",
            "cs\n",
            "Title: From Seed AI to Technological Singularity via Recursively Self-Improving Software \n",
            "Authors: Roman V. Yampolskiy \n",
            "Date: 2015-02-23 17:08:30+00:00 \n",
            "Id: 1502.06512 \n",
            "Summary: Software capable of improving itself has been a dream of computer scientists\n",
            "since the inception of the field. In this work we provide definitions for\n",
            "Recursively Self-Improving software, survey different types of self-improving\n",
            "software, review the relevant literature, analyze limits on computation\n",
            "restricting recursive self-improvement and introduce RSI Convergence Theory\n",
            "which aims to predict general behavior of RSI systems. Finally, we address\n",
            "security implications from self-improving intelligent software. \n",
            "URL: http://arxiv.org/pdf/1502.06512v1 \n",
            "\n",
            "\n",
            "188\n",
            "cs\n",
            "Title: Are You Robert or RoBERTa? Deceiving Online Authorship Attribution Models Using Neural Text Generators \n",
            "Authors: Keenan Jones, Jason R. C. Nurse, Shujun Li \n",
            "Date: 2022-03-18 09:19:14+00:00 \n",
            "Id: 2203.09813 \n",
            "Summary: Recently, there has been a rise in the development of powerful pre-trained\n",
            "natural language models, including GPT-2, Grover, and XLM. These models have\n",
            "shown state-of-the-art capabilities towards a variety of different NLP tasks,\n",
            "including question answering, content summarisation, and text generation.\n",
            "Alongside this, there have been many studies focused on online authorship\n",
            "attribution (AA). That is, the use of models to identify the authors of online\n",
            "texts. Given the power of natural language models in generating convincing\n",
            "texts, this paper examines the degree to which these language models can\n",
            "generate texts capable of deceiving online AA models. Experimenting with both\n",
            "blog and Twitter data, we utilise GPT-2 language models to generate texts using\n",
            "the existing posts of online users. We then examine whether these AI-based text\n",
            "generators are capable of mimicking authorial style to such a degree that they\n",
            "can deceive typical AA models. From this, we find that current AI-based text\n",
            "generators are able to successfully mimic authorship, showing capabilities\n",
            "towards this on both datasets. Our findings, in turn, highlight the current\n",
            "capacity of powerful natural language models to generate original online posts\n",
            "capable of mimicking authorial style sufficiently to deceive popular AA\n",
            "methods; a key finding given the proposed role of AA in real world applications\n",
            "such as spam-detection and forensic investigation. \n",
            "URL: http://arxiv.org/pdf/2203.09813v1 \n",
            "\n",
            "\n",
            "189\n",
            "cs\n",
            "Title: An intracardiac electrogram model to bridge virtual hearts and implantable cardiac devices \n",
            "Authors: Weiwei Ai, Nitish Patel, Partha Roop, Avinash Malik, Nathan Allen, Mark L. Trew \n",
            "Date: 2017-03-03 10:46:47+00:00 \n",
            "Id: 1703.01107 \n",
            "Summary: Virtual heart models have been proposed to enhance the safety of implantable\n",
            "cardiac devices through closed loop validation. To communicate with a virtual\n",
            "heart, devices have been driven by cardiac signals at specific sites. As a\n",
            "result, only the action potentials of these sites are sensed. However, the real\n",
            "device implanted in the heart will sense a complex combination of near and\n",
            "far-field extracellular potential signals. Therefore many device functions,\n",
            "such as blanking periods and refractory periods, are designed to handle these\n",
            "unexpected signals. To represent these signals, we develop an intracardiac\n",
            "electrogram (IEGM) model as an interface between the virtual heart and the\n",
            "device. The model can capture not only the local excitation but also far-field\n",
            "signals and pacing afterpotentials. Moreover, the sensing controller can\n",
            "specify unipolar or bipolar electrogram (EGM) sensing configurations and\n",
            "introduce various oversensing and undersensing modes. The simulation results\n",
            "show that the model is able to reproduce clinically observed sensing problems,\n",
            "which significantly extends the capabilities of the virtual heart model in the\n",
            "context of device validation. \n",
            "URL: http://arxiv.org/pdf/1703.01107v1 \n",
            "\n",
            "\n",
            "190\n",
            "cs\n",
            "Title: Algorithms for the Greater Good! On Mental Modeling and Acceptable Symbiosis in Human-AI Collaboration \n",
            "Authors: Tathagata Chakraborti, Subbarao Kambhampati \n",
            "Date: 2018-01-30 05:23:28+00:00 \n",
            "Id: 1801.09854 \n",
            "Summary: Effective collaboration between humans and AI-based systems requires\n",
            "effective modeling of the human in the loop, both in terms of the mental state\n",
            "as well as the physical capabilities of the latter. However, these models can\n",
            "also open up pathways for manipulating and exploiting the human in the hopes of\n",
            "achieving some greater good, especially when the intent or values of the AI and\n",
            "the human are not aligned or when they have an asymmetrical relationship with\n",
            "respect to knowledge or computation power. In fact, such behavior does not\n",
            "necessarily require any malicious intent but can rather be borne out of\n",
            "cooperative scenarios. It is also beyond simple misinterpretation of intents,\n",
            "as in the case of value alignment problems, and thus can be effectively\n",
            "engineered if desired. Such techniques already exist and pose several\n",
            "unresolved ethical and moral questions with regards to the design of autonomy.\n",
            "In this paper, we illustrate some of these issues in a teaming scenario and\n",
            "investigate how they are perceived by participants in a thought experiment. \n",
            "URL: http://arxiv.org/pdf/1801.09854v1 \n",
            "\n",
            "\n",
            "191\n",
            "cs\n",
            "Title: Towards security defect prediction with AI \n",
            "Authors: Carson D. Sestili, William S. Snavely, Nathan M. VanHoudnos \n",
            "Date: 2018-08-29 15:57:27+00:00 \n",
            "Id: 1808.09897 \n",
            "Summary: In this study, we investigate the limits of the current state of the art AI\n",
            "system for detecting buffer overflows and compare it with current static\n",
            "analysis tools. To do so, we developed a code generator, s-bAbI, capable of\n",
            "producing an arbitrarily large number of code samples of controlled complexity.\n",
            "We found that the static analysis engines we examined have good precision, but\n",
            "poor recall on this dataset, except for a sound static analyzer that has good\n",
            "precision and recall. We found that the state of the art AI system, a memory\n",
            "network modeled after Choi et al. [1], can achieve similar performance to the\n",
            "static analysis engines, but requires an exhaustive amount of training data in\n",
            "order to do so. Our work points towards future approaches that may solve these\n",
            "problems; namely, using representations of code that can capture appropriate\n",
            "scope information and using deep learning methods that are able to perform\n",
            "arithmetic operations. \n",
            "URL: http://arxiv.org/pdf/1808.09897v2 \n",
            "\n",
            "\n",
            "192\n",
            "cs\n",
            "Title: Digital Normativity: A challenge for human subjectivization and free will \n",
            "Authors: Éric Fourneret, Blaise Yvert \n",
            "Date: 2019-05-23 15:53:21+00:00 \n",
            "Id: 1905.09735 \n",
            "Summary: Over the past decade, artificial intelligence has demonstrated its efficiency\n",
            "in many different applications and a huge number of algorithms have become\n",
            "central and ubiquitous in our life. Their growing interest is essentially based\n",
            "on their capability to synthesize and process large amounts of data, and to\n",
            "help humans making decisions in a world of increasing complexity. Yet, the\n",
            "effectiveness of algorithms in bringing more and more relevant recommendations\n",
            "to humans may start to compete with human-alone decisions based on values other\n",
            "than pure efficacy. Here, we examine this tension in light of the emergence of\n",
            "several forms of digital normativity, and analyze how this normative role of AI\n",
            "may influence the ability of humans to remain subject of their life. The advent\n",
            "of AI technology imposes a need to achieve a balance between concrete material\n",
            "progress and progress of the mind to avoid any form of servitude. It has become\n",
            "essential that an ethical reflection accompany the current developments of\n",
            "intelligent algorithms beyond the sole question of their social acceptability.\n",
            "Such reflection should be anchored where AI technologies are being developed as\n",
            "well as in educational programs where their implications can be explained. \n",
            "URL: http://arxiv.org/pdf/1905.09735v1 \n",
            "\n",
            "\n",
            "193\n",
            "cs\n",
            "Title: AI and Accessibility: A Discussion of Ethical Considerations \n",
            "Authors: Meredith Ringel Morris \n",
            "Date: 2019-08-21 17:00:25+00:00 \n",
            "Id: 1908.08939 \n",
            "Summary: According to the World Health Organization, more than one billion people\n",
            "worldwide have disabilities. The field of disability studies defines disability\n",
            "through a social lens; people are disabled to the extent that society creates\n",
            "accessibility barriers. AI technologies offer the possibility of removing many\n",
            "accessibility barriers; for example, computer vision might help people who are\n",
            "blind better sense the visual world, speech recognition and translation\n",
            "technologies might offer real time captioning for people who are hard of\n",
            "hearing, and new robotic systems might augment the capabilities of people with\n",
            "limited mobility. Considering the needs of users with disabilities can help\n",
            "technologists identify high-impact challenges whose solutions can advance the\n",
            "state of AI for all users; however, ethical challenges such as inclusivity,\n",
            "bias, privacy, error, expectation setting, simulated data, and social\n",
            "acceptability must be considered. \n",
            "URL: http://arxiv.org/pdf/1908.08939v3 \n",
            "\n",
            "\n",
            "194\n",
            "cs\n",
            "Title: General Video Game AI: a Multi-Track Framework for Evaluating Agents, Games and Content Generation Algorithms \n",
            "Authors: Diego Perez-Liebana, Jialin Liu, Ahmed Khalifa, Raluca D. Gaina, Julian Togelius, Simon M. Lucas \n",
            "Date: 2018-02-28 11:23:16+00:00 \n",
            "Id: 1802.10363 \n",
            "Summary: General Video Game Playing (GVGP) aims at designing an agent that is capable\n",
            "of playing multiple video games with no human intervention. In 2014, The\n",
            "General Video Game AI (GVGAI) competition framework was created and released\n",
            "with the purpose of providing researchers a common open-source and easy to use\n",
            "platform for testing their AI methods with potentially infinity of games\n",
            "created using Video Game Description Language (VGDL). The framework has been\n",
            "expanded into several tracks during the last few years to meet the demand of\n",
            "different research directions. The agents are required either to play multiple\n",
            "unknown games with or without access to game simulations, or to design new game\n",
            "levels or rules. This survey paper presents the VGDL, the GVGAI framework,\n",
            "existing tracks, and reviews the wide use of GVGAI framework in research,\n",
            "education and competitions five years after its birth. A future plan of\n",
            "framework improvements is also described. \n",
            "URL: http://arxiv.org/pdf/1802.10363v4 \n",
            "\n",
            "\n",
            "195\n",
            "cs\n",
            "Title: A multidisciplinary task-based perspective for evaluating the impact of AI autonomy and generality on the future of work \n",
            "Authors: Enrique Fernández-Macías, Emilia Gómez, José Hernández-Orallo, Bao Sheng Loe, Bertin Martens, Fernando Martínez-Plumed, Songül Tolan \n",
            "Date: 2018-07-06 13:52:23+00:00 \n",
            "Id: 1807.02416 \n",
            "Summary: This paper presents a multidisciplinary task approach for assessing the\n",
            "impact of artificial intelligence on the future of work. We provide definitions\n",
            "of a task from two main perspectives: socio-economic and computational. We\n",
            "propose to explore ways in which we can integrate or map these perspectives,\n",
            "and link them with the skills or capabilities required by them, for humans and\n",
            "AI systems. Finally, we argue that in order to understand the dynamics of\n",
            "tasks, we have to explore the relevance of autonomy and generality of AI\n",
            "systems for the automation or alteration of the workplace. \n",
            "URL: http://arxiv.org/pdf/1807.02416v1 \n",
            "\n",
            "\n",
            "196\n",
            "cs\n",
            "Title: Characterizing machine learning process: A maturity framework \n",
            "Authors: Rama Akkiraju, Vibha Sinha, Anbang Xu, Jalal Mahmud, Pritam Gundecha, Zhe Liu, Xiaotong Liu, John Schumacher \n",
            "Date: 2018-11-12 17:32:24+00:00 \n",
            "Id: 1811.04871 \n",
            "Summary: Academic literature on machine learning modeling fails to address how to make\n",
            "machine learning models work for enterprises. For example, existing machine\n",
            "learning processes cannot address how to define business use cases for an AI\n",
            "application, how to convert business requirements from offering managers into\n",
            "data requirements for data scientists, and how to continuously improve AI\n",
            "applications in term of accuracy and fairness, and how to customize general\n",
            "purpose machine learning models with industry, domain, and use case specific\n",
            "data to make them more accurate for specific situations etc. Making AI work for\n",
            "enterprises requires special considerations, tools, methods and processes. In\n",
            "this paper we present a maturity framework for machine learning model lifecycle\n",
            "management for enterprises. Our framework is a re-interpretation of the\n",
            "software Capability Maturity Model (CMM) for machine learning model development\n",
            "process. We present a set of best practices from our personal experience of\n",
            "building large scale real-world machine learning models to help organizations\n",
            "achieve higher levels of maturity independent of their starting point. \n",
            "URL: http://arxiv.org/pdf/1811.04871v1 \n",
            "\n",
            "\n",
            "197\n",
            "cs\n",
            "Title: Anticipation in collaborative music performance using fuzzy systems: a case study \n",
            "Authors: Oscar Thörn, Peter Fögel, Peter Knudsen, Luis de Miranda, Alessandro Saffiotti \n",
            "Date: 2019-06-05 17:26:50+00:00 \n",
            "Id: 1906.02155 \n",
            "Summary: In order to collaborate and co-create with humans, an AI system must be\n",
            "capable of both reactive and anticipatory behavior. We present a case study of\n",
            "such a system in the domain of musical improvisation. We consider a duo\n",
            "consisting of a human pianist accompained by an off-the-shelf virtual drummer,\n",
            "and we design an AI system to control the perfomance parameters of the drummer\n",
            "(e.g., patterns, intensity, or complexity) as a function of what the human\n",
            "pianist is playing. The AI system utilizes a model elicited from the musicians\n",
            "and encoded through fuzzy logic. This paper outlines the methodology, design,\n",
            "and development process of this system. An evaluation in public concerts is\n",
            "upcoming. This case study is seen as a step in the broader investigation of\n",
            "anticipation and creative processes in mixed human-robot, or \"anthrobotic\"\n",
            "systems. \n",
            "URL: http://arxiv.org/pdf/1906.02155v1 \n",
            "\n",
            "\n",
            "198\n",
            "cs\n",
            "Title: Solving Service Robot Tasks: UT Austin Villa@Home 2019 Team Report \n",
            "Authors: Rishi Shah, Yuqian Jiang, Haresh Karnan, Gilberto Briscoe-Martinez, Dominick Mulder, Ryan Gupta, Rachel Schlossman, Marika Murphy, Justin W. Hart, Luis Sentis, Peter Stone \n",
            "Date: 2019-09-14 04:39:14+00:00 \n",
            "Id: 1909.06529 \n",
            "Summary: RoboCup@Home is an international robotics competition based on domestic tasks\n",
            "requiring autonomous capabilities pertaining to a large variety of AI\n",
            "technologies. Research challenges are motivated by these tasks both at the\n",
            "level of individual technologies and the integration of subsystems into a fully\n",
            "functional, robustly autonomous system. We describe the progress made by the UT\n",
            "Austin Villa 2019 RoboCup@Home team which represents a significant step forward\n",
            "in AI-based HRI due to the breadth of tasks accomplished within a unified\n",
            "system. Presented are the competition tasks, component technologies they rely\n",
            "on, our initial approaches both to the components and their integration, and\n",
            "directions for future research. \n",
            "URL: http://arxiv.org/pdf/1909.06529v1 \n",
            "\n",
            "\n",
            "199\n",
            "cs\n",
            "Title: (When) Is Truth-telling Favored in AI Debate? \n",
            "Authors: Vojtěch Kovařík, Ryan Carey \n",
            "Date: 2019-11-11 13:49:43+00:00 \n",
            "Id: 1911.04266 \n",
            "Summary: For some problems, humans may not be able to accurately judge the goodness of\n",
            "AI-proposed solutions. Irving et al. (2018) propose that in such cases, we may\n",
            "use a debate between two AI systems to amplify the problem-solving capabilities\n",
            "of a human judge. We introduce a mathematical framework that can model debates\n",
            "of this type and propose that the quality of debate designs should be measured\n",
            "by the accuracy of the most persuasive answer. We describe a simple instance of\n",
            "the debate framework called feature debate and analyze the degree to which such\n",
            "debates track the truth. We argue that despite being very simple, feature\n",
            "debates nonetheless capture many aspects of practical debates such as the\n",
            "incentives to confuse the judge or stall to prevent losing. We then outline how\n",
            "these models should be generalized to analyze a wider range of debate\n",
            "phenomena. \n",
            "URL: http://arxiv.org/pdf/1911.04266v3 \n",
            "\n",
            "\n",
            "200\n",
            "cs\n",
            "Title: Leveraging Rationales to Improve Human Task Performance \n",
            "Authors: Devleena Das, Sonia Chernova \n",
            "Date: 2020-02-11 04:51:35+00:00 \n",
            "Id: 2002.04202 \n",
            "Summary: Machine learning (ML) systems across many application areas are increasingly\n",
            "demonstrating performance that is beyond that of humans. In response to the\n",
            "proliferation of such models, the field of Explainable AI (XAI) has sought to\n",
            "develop techniques that enhance the transparency and interpretability of\n",
            "machine learning methods. In this work, we consider a question not previously\n",
            "explored within the XAI and ML communities: Given a computational system whose\n",
            "performance exceeds that of its human user, can explainable AI capabilities be\n",
            "leveraged to improve the performance of the human? We study this question in\n",
            "the context of the game of Chess, for which computational game engines that\n",
            "surpass the performance of the average player are widely available. We\n",
            "introduce the Rationale-Generating Algorithm, an automated technique for\n",
            "generating rationales for utility-based computational methods, which we\n",
            "evaluate with a multi-day user study against two baselines. The results show\n",
            "that our approach produces rationales that lead to statistically significant\n",
            "improvement in human task performance, demonstrating that rationales\n",
            "automatically generated from an AI's internal task model can be used not only\n",
            "to explain what the system is doing, but also to instruct the user and\n",
            "ultimately improve their task performance. \n",
            "URL: http://arxiv.org/pdf/2002.04202v1 \n",
            "\n",
            "\n",
            "201\n",
            "cs\n",
            "Title: MIP An AI Distributed Architectural Model to Introduce Cognitive computing capabilities in Cyber Physical Systems (CPS) \n",
            "Authors: Pasquale Giampa, Massimiliano Dibitonto \n",
            "Date: 2020-03-30 00:59:31+00:00 \n",
            "Id: 2003.13174 \n",
            "Summary: This paper introduces the MIP Platform architecture model, a novel AI-based\n",
            "cognitive computing platform architecture. The goal of the proposed application\n",
            "of MIP is to reduce the implementation burden for the usage of AI algorithms\n",
            "applied to cognitive computing and fluent HMI interactions within the\n",
            "manufacturing process in a cyber-physical production system. The cognitive\n",
            "inferencing engine of MIP is a deterministic cognitive module that processes\n",
            "declarative goals, identifies Intents and Entities, selects suitable actions\n",
            "and associated algorithms, and invokes for the execution a processing logic\n",
            "(Function) configured in the internal Function-as-aService or Connectivity\n",
            "Engine. Constant observation and evaluation against performance criteria assess\n",
            "the performance of Lambda(s) for many and varying scenarios. The modular design\n",
            "with well-defined interfaces enables the reusability and extensibility of FaaS\n",
            "components. An integrated BigData platform implements this modular design\n",
            "supported by technologies such as Docker, Kubernetes for virtualization and\n",
            "orchestration of the individual components and their communication. The\n",
            "implementation of the architecture is evaluated using a real-world use case\n",
            "later discussed in this paper. \n",
            "URL: http://arxiv.org/pdf/2003.13174v1 \n",
            "\n",
            "\n",
            "202\n",
            "cs\n",
            "Title: Insightful Assistant: AI-compatible Operation Graph Representations for Enhancing Industrial Conversational Agents \n",
            "Authors: Bekir Bayrak, Florian Giger, Christian Meurisch \n",
            "Date: 2020-07-25 13:46:58+00:00 \n",
            "Id: 2007.12929 \n",
            "Summary: Advances in voice-controlled assistants paved the way into the consumer\n",
            "market. For professional or industrial use, the capabilities of such assistants\n",
            "are too limited or too time-consuming to implement due to the higher complexity\n",
            "of data, possible AI-based operations, and requests. In the light of these\n",
            "deficits, this paper presents Insightful Assistant---a pipeline concept based\n",
            "on a novel operation graph representation resulting from the intents detected.\n",
            "Using a predefined set of semantically annotated (executable) functions, each\n",
            "node of the operation graph is assigned to a function for execution. Besides\n",
            "basic operations, such functions can contain artificial intelligence (AI) based\n",
            "operations (e.g., anomaly detection). The result is then visualized to the user\n",
            "according to type and extracted user preferences in an automated way. We\n",
            "further collected a unique crowd-sourced set of 869 requests, each with four\n",
            "different variants expected visualization, for an industrial dataset. The\n",
            "evaluation of our proof-of-concept prototype on this dataset shows its\n",
            "feasibility: it achieves an accuracy of up to 95.0% (74.5%) for simple\n",
            "(complex) request detection with different variants and a top3-accuracy up to\n",
            "95.4% for data-/user-adaptive visualization. \n",
            "URL: http://arxiv.org/pdf/2007.12929v1 \n",
            "\n",
            "\n",
            "203\n",
            "cs\n",
            "Title: Explainable AI based Interventions for Pre-season Decision Making in Fashion Retail \n",
            "Authors: Shravan Sajja, Nupur Aggarwal, Sumanta Mukherjee, Kushagra Manglik, Satyam Dwivedi, Vikas Raykar \n",
            "Date: 2020-07-27 08:16:09+00:00 \n",
            "Id: 2008.07376 \n",
            "Summary: Future of sustainable fashion lies in adoption of AI for a better\n",
            "understanding of consumer shopping behaviour and using this understanding to\n",
            "further optimize product design, development and sourcing to finally reduce the\n",
            "probability of overproducing inventory. Explainability and interpretability are\n",
            "highly effective in increasing the adoption of AI based tools in creative\n",
            "domains like fashion. In a fashion house, stakeholders like buyers,\n",
            "merchandisers and financial planners have a more quantitative approach towards\n",
            "decision making with primary goals of high sales and reduced dead inventory.\n",
            "Whereas, designers have a more intuitive approach based on observing market\n",
            "trends, social media and runways shows. Our goal is to build an explainable new\n",
            "product forecasting tool with capabilities of interventional analysis such that\n",
            "all the stakeholders (with competing goals) can participate in collaborative\n",
            "decision making process of new product design, development and launch. \n",
            "URL: http://arxiv.org/pdf/2008.07376v1 \n",
            "\n",
            "\n",
            "204\n",
            "cs\n",
            "Title: Domain-Level Explainability -- A Challenge for Creating Trust in Superhuman AI Strategies \n",
            "Authors: Jonas Andrulis, Ole Meyer, Grégory Schott, Samuel Weinbach, Volker Gruhn \n",
            "Date: 2020-11-12 21:42:02+00:00 \n",
            "Id: 2011.06665 \n",
            "Summary: For strategic problems, intelligent systems based on Deep Reinforcement\n",
            "Learning (DRL) have demonstrated an impressive ability to learn advanced\n",
            "solutions that can go far beyond human capabilities, especially when dealing\n",
            "with complex scenarios. While this creates new opportunities for the\n",
            "development of intelligent assistance systems with groundbreaking\n",
            "functionalities, applying this technology to real-world problems carries\n",
            "significant risks and therefore requires trust in their transparency and\n",
            "reliability. With superhuman strategies being non-intuitive and complex by\n",
            "definition and real-world scenarios prohibiting a reliable performance\n",
            "evaluation, the key components for trust in these systems are difficult to\n",
            "achieve. Explainable AI (XAI) has successfully increased transparency for\n",
            "modern AI systems through a variety of measures, however, XAI research has not\n",
            "yet provided approaches enabling domain level insights for expert users in\n",
            "strategic situations. In this paper, we discuss the existence of superhuman\n",
            "DRL-based strategies, their properties, the requirements and challenges for\n",
            "transforming them into real-world environments, and the implications for trust\n",
            "through explainability as a key technology. \n",
            "URL: http://arxiv.org/pdf/2011.06665v1 \n",
            "\n",
            "\n",
            "205\n",
            "cs\n",
            "Title: Explainable AI for System Failures: Generating Explanations that Improve Human Assistance in Fault Recovery \n",
            "Authors: Devleena Das, Siddhartha Banerjee, Sonia Chernova \n",
            "Date: 2020-11-18 17:08:50+00:00 \n",
            "Id: 2011.09407 \n",
            "Summary: With the growing capabilities of intelligent systems, the integration of\n",
            "artificial intelligence (AI) and robots in everyday life is increasing.\n",
            "However, when interacting in such complex human environments, the failure of\n",
            "intelligent systems, such as robots, can be inevitable, requiring recovery\n",
            "assistance from users. In this work, we develop automated, natural language\n",
            "explanations for failures encountered during an AI agents' plan execution.\n",
            "These explanations are developed with a focus of helping non-expert users\n",
            "understand different point of failures to better provide recovery assistance.\n",
            "Specifically, we introduce a context-based information type for explanations\n",
            "that can both help non-expert users understand the underlying cause of a system\n",
            "failure, and select proper failure recoveries. Additionally, we extend an\n",
            "existing sequence-to-sequence methodology to automatically generate our\n",
            "context-based explanations. By doing so, we are able develop a model that can\n",
            "generalize context-based explanations over both different failure types and\n",
            "failure scenarios. \n",
            "URL: http://arxiv.org/pdf/2011.09407v2 \n",
            "\n",
            "\n",
            "206\n",
            "cs\n",
            "Title: Interactive Teaching for Conversational AI \n",
            "Authors: Qing Ping, Feiyang Niu, Govind Thattai, Joel Chengottusseriyil, Qiaozi Gao, Aishwarya Reganti, Prashanth Rajagopal, Gokhan Tur, Dilek Hakkani-Tur, Prem Nataraja \n",
            "Date: 2020-12-02 04:08:49+00:00 \n",
            "Id: 2012.00958 \n",
            "Summary: Current conversational AI systems aim to understand a set of pre-designed\n",
            "requests and execute related actions, which limits them to evolve naturally and\n",
            "adapt based on human interactions. Motivated by how children learn their first\n",
            "language interacting with adults, this paper describes a new Teachable AI\n",
            "system that is capable of learning new language nuggets called concepts,\n",
            "directly from end users using live interactive teaching sessions. The proposed\n",
            "setup uses three models to: a) Identify gaps in understanding automatically\n",
            "during live conversational interactions, b) Learn the respective\n",
            "interpretations of such unknown concepts from live interactions with users, and\n",
            "c) Manage a classroom sub-dialogue specifically tailored for interactive\n",
            "teaching sessions. We propose state-of-the-art transformer based neural\n",
            "architectures of models, fine-tuned on top of pre-trained models, and show\n",
            "accuracy improvements on the respective components. We demonstrate that this\n",
            "method is very promising in leading way to build more adaptive and personalized\n",
            "language understanding models. \n",
            "URL: http://arxiv.org/pdf/2012.00958v1 \n",
            "\n",
            "\n",
            "207\n",
            "cs\n",
            "Title: Toward Native Artificial Intelligence in 6G Networks: System Design, Architectures, and Paradigms \n",
            "Authors: Jianjun Wu, Rongpeng Li, Xueli An, Chenghui Peng, Zhe Liu, Jon Crowcroft, Honggang Zhang \n",
            "Date: 2021-03-04 03:56:55+00:00 \n",
            "Id: 2103.02823 \n",
            "Summary: The mobile communication system has transformed to be the fundamental\n",
            "infrastructure to support digital demands from all industry sectors, and 6G is\n",
            "envisioned to go far beyond the communication-only purpose. There is coming to\n",
            "a consensus that 6G will treat Artificial Intelligence (AI) as the cornerstone\n",
            "and has a potential capability to provide \"intelligence inclusion\", which\n",
            "implies to enable the access of AI services at anytime and anywhere by anyone.\n",
            "Apparently, the intelligent inclusion vision produces far-reaching influence on\n",
            "the corresponding network architecture design in 6G and deserves a clean-slate\n",
            "rethink. In this article, we propose an end-to-end system architecture design\n",
            "scope for 6G, and talk about the necessity to incorporate an independent data\n",
            "plane and a novel intelligent plane with particular emphasis on end-to-end AI\n",
            "workflow orchestration, management and operation. We also highlight the\n",
            "advantages to provision converged connectivity and computing services at the\n",
            "network function plane. Benefiting from these approaches, we believe that 6G\n",
            "will turn to an \"everything as a service\" (XaaS) platform with significantly\n",
            "enhanced business merits. \n",
            "URL: http://arxiv.org/pdf/2103.02823v1 \n",
            "\n",
            "\n",
            "208\n",
            "cs\n",
            "Title: Towards Designing Computer Vision-based Explainable-AI Solution: A Use Case of Livestock Mart Industry \n",
            "Authors: Devam Dave, Het Naik, Smiti Singhal, Rudresh Dwivedi, Pankesh Patel \n",
            "Date: 2021-02-08 17:11:19+00:00 \n",
            "Id: 2103.03096 \n",
            "Summary: The objective of an online Mart is to match buyers and sellers, to weigh\n",
            "animals and to oversee their sale. A reliable pricing method can be developed\n",
            "by ML models that can read through historical sales data. However, when AI\n",
            "models suggest or recommend a price, that in itself does not reveal too much\n",
            "(i.e., it acts like a black box) about the qualities and the abilities of an\n",
            "animal. An interested buyer would like to know more about the salient features\n",
            "of an animal before making the right choice based on his requirements. A model\n",
            "capable of explaining the different factors that impact the price point is\n",
            "essential for the needs of the market. It can also inspire confidence in buyers\n",
            "and sellers about the price point offered. To achieve these objectives, we have\n",
            "been working with the team at MartEye, a startup based in Portershed in Galway\n",
            "City, Ireland. Through this paper, we report our work-in-progress research\n",
            "towards building a smart video analytic platform, leveraging Explainable AI\n",
            "techniques. \n",
            "URL: http://arxiv.org/pdf/2103.03096v1 \n",
            "\n",
            "\n",
            "209\n",
            "cs\n",
            "Title: SocialAI 0.1: Towards a Benchmark to Stimulate Research on Socio-Cognitive Abilities in Deep Reinforcement Learning Agents \n",
            "Authors: Grgur Kovač, Rémy Portelas, Katja Hofmann, Pierre-Yves Oudeyer \n",
            "Date: 2021-04-27 14:16:29+00:00 \n",
            "Id: 2104.13207 \n",
            "Summary: Building embodied autonomous agents capable of participating in social\n",
            "interactions with humans is one of the main challenges in AI. This problem\n",
            "motivated many research directions on embodied language use. Current approaches\n",
            "focus on language as a communication tool in very simplified and non diverse\n",
            "social situations: the \"naturalness\" of language is reduced to the concept of\n",
            "high vocabulary size and variability. In this paper, we argue that aiming\n",
            "towards human-level AI requires a broader set of key social skills: 1) language\n",
            "use in complex and variable social contexts; 2) beyond language, complex\n",
            "embodied communication in multimodal settings within constantly evolving social\n",
            "worlds. In this work we explain how concepts from cognitive sciences could help\n",
            "AI to draw a roadmap towards human-like intelligence, with a focus on its\n",
            "social dimensions. We then study the limits of a recent SOTA Deep RL approach\n",
            "when tested on a first grid-world environment from the upcoming SocialAI, a\n",
            "benchmark to assess the social skills of Deep RL agents. Videos and code are\n",
            "available at https://sites.google.com/view/socialai01 . \n",
            "URL: http://arxiv.org/pdf/2104.13207v1 \n",
            "\n",
            "\n",
            "210\n",
            "cs\n",
            "Title: Federated Learning for Privacy-Preserving Open Innovation Future on Digital Health \n",
            "Authors: Guodong Long, Tao Shen, Yue Tan, Leah Gerrard, Allison Clarke, Jing Jiang \n",
            "Date: 2021-08-24 14:08:55+00:00 \n",
            "Id: 2108.10761 \n",
            "Summary: Privacy protection is an ethical issue with broad concern in Artificial\n",
            "Intelligence (AI). Federated learning is a new machine learning paradigm to\n",
            "learn a shared model across users or organisations without direct access to the\n",
            "data. It has great potential to be the next-general AI model training framework\n",
            "that offers privacy protection and therefore has broad implications for the\n",
            "future of digital health and healthcare informatics. Implementing an open\n",
            "innovation framework in the healthcare industry, namely open health, is to\n",
            "enhance innovation and creative capability of health-related organisations by\n",
            "building a next-generation collaborative framework with partner organisations\n",
            "and the research community. In particular, this game-changing collaborative\n",
            "framework offers knowledge sharing from diverse data with a privacy-preserving.\n",
            "This chapter will discuss how federated learning can enable the development of\n",
            "an open health ecosystem with the support of AI. Existing challenges and\n",
            "solutions for federated learning will be discussed. \n",
            "URL: http://arxiv.org/pdf/2108.10761v1 \n",
            "\n",
            "\n",
            "211\n",
            "cs\n",
            "Title: The five Is: Key principles for interpretable and safe conversational AI \n",
            "Authors: Mattias Wahde, Marco Virgolin \n",
            "Date: 2021-08-31 11:38:48+00:00 \n",
            "Id: 2108.13766 \n",
            "Summary: In this position paper, we present five key principles, namely\n",
            "interpretability, inherent capability to explain, independent data, interactive\n",
            "learning, and inquisitiveness, for the development of conversational AI that,\n",
            "unlike the currently popular black box approaches, is transparent and\n",
            "accountable. At present, there is a growing concern with the use of black box\n",
            "statistical language models: While displaying impressive average performance,\n",
            "such systems are also prone to occasional spectacular failures, for which there\n",
            "is no clear remedy. In an effort to initiate a discussion on possible\n",
            "alternatives, we outline and exemplify how our five principles enable the\n",
            "development of conversational AI systems that are transparent and thus safer\n",
            "for use. We also present some of the challenges inherent in the implementation\n",
            "of those principles. \n",
            "URL: http://arxiv.org/pdf/2108.13766v1 \n",
            "\n",
            "\n",
            "212\n",
            "cs\n",
            "Title: Unifying AI Algorithms with Probabilistic Programming using Implicitly Defined Representations \n",
            "Authors: Avi Pfeffer, Michael Harradon, Joseph Campolongo, Sanja Cvijic \n",
            "Date: 2021-10-05 19:49:30+00:00 \n",
            "Id: 2110.02325 \n",
            "Summary: We introduce Scruff, a new framework for developing AI systems using\n",
            "probabilistic programming. Scruff enables a variety of representations to be\n",
            "included, such as code with stochastic choices, neural networks, differential\n",
            "equations, and constraint systems. These representations are defined implicitly\n",
            "using a set of standardized operations that can be performed on them.\n",
            "General-purpose algorithms are then implemented using these operations,\n",
            "enabling generalization across different representations. Zero, one, or more\n",
            "operation implementations can be provided for any given representation, giving\n",
            "algorithms the flexibility to use the most appropriate available\n",
            "implementations for their purposes and enabling representations to be used in\n",
            "ways that suit their capabilities. In this paper, we explain the general\n",
            "approach of implicitly defined representations and provide a variety of\n",
            "examples of representations at varying degrees of abstraction. We also show how\n",
            "a relatively small set of operations can serve to unify a variety of AI\n",
            "algorithms. Finally, we discuss how algorithms can use policies to choose which\n",
            "operation implementations to use during execution. \n",
            "URL: http://arxiv.org/pdf/2110.02325v1 \n",
            "\n",
            "\n",
            "213\n",
            "cs\n",
            "Title: Provably Robust Model-Centric Explanations for Critical Decision-Making \n",
            "Authors: Cecilia G. Morales, Nicholas Gisolfi, Robert Edman, James K. Miller, Artur Dubrawski \n",
            "Date: 2021-10-26 18:05:49+00:00 \n",
            "Id: 2110.13937 \n",
            "Summary: We recommend using a model-centric, Boolean Satisfiability (SAT) formalism to\n",
            "obtain useful explanations of trained model behavior, different and\n",
            "complementary to what can be gleaned from LIME and SHAP, popular data-centric\n",
            "explanation tools in Artificial Intelligence (AI). We compare and contrast\n",
            "these methods, and show that data-centric methods may yield brittle\n",
            "explanations of limited practical utility. The model-centric framework,\n",
            "however, can offer actionable insights into risks of using AI models in\n",
            "practice. For critical applications of AI, split-second decision making is best\n",
            "informed by robust explanations that are invariant to properties of data, the\n",
            "capability offered by model-centric frameworks. \n",
            "URL: http://arxiv.org/pdf/2110.13937v1 \n",
            "\n",
            "\n",
            "214\n",
            "cs\n",
            "Title: Zero-Touch Network on Industrial IoT: An End-to-End Machine Learning Approach \n",
            "Authors: Shih-Chun Lin, Chia-Hung Lin, Wei-Chi Chen \n",
            "Date: 2022-04-26 21:41:43+00:00 \n",
            "Id: 2204.12605 \n",
            "Summary: Industry 4.0-enabled smart factory is expected to realize the next revolution\n",
            "for manufacturers. Although artificial intelligence (AI) technologies have\n",
            "improved productivity, current use cases belong to small-scale and single-task\n",
            "operations. To unbound the potential of smart factory, this paper develops\n",
            "zero-touch network systems for intelligent manufacturing and facilitates\n",
            "distributed AI applications in both training and inferring stages in a\n",
            "large-scale manner. The open radio access network (O-RAN) architecture is first\n",
            "introduced for the zero-touch platform to enable globally controlling\n",
            "communications and computation infrastructure capability in the field. The\n",
            "designed serverless framework allows intelligent and efficient learning\n",
            "assignments and resource allocations. Hence, requested learning tasks can be\n",
            "assigned to appropriate robots, and the underlying infrastructure can be used\n",
            "to support the learning tasks without expert knowledge. Moreover, due to the\n",
            "proposed network system's flexibility, powerful AI-enabled networking\n",
            "algorithms can be utilized to ensure service-level agreements and superior\n",
            "performances for factory workloads. Finally, three open research directions of\n",
            "backward compatibility, end-to-end enhancements, and cybersecurity are\n",
            "discussed for zero-touch smart factory. \n",
            "URL: http://arxiv.org/pdf/2204.12605v1 \n",
            "\n",
            "\n",
            "215\n",
            "cs\n",
            "Title: The Rise of AI-Driven Simulators: Building a New Crystal Ball \n",
            "Authors: Ian Foster, David Parkes, Stephan Zheng \n",
            "Date: 2020-12-11 00:13:40+00:00 \n",
            "Id: 2012.06049 \n",
            "Summary: The use of computational simulation is by now so pervasive in society that it\n",
            "is no exaggeration to say that continued U.S. and international prosperity,\n",
            "security, and health depend in part on continued improvements in simulation\n",
            "capabilities. What if we could predict weather two weeks out, guide the design\n",
            "of new drugs for new viral diseases, or manage new manufacturing processes that\n",
            "cut production costs and times by an order of magnitude? What if we could\n",
            "predict collective human behavior, for example, response to an evacuation\n",
            "request during a natural disaster, or labor response to fiscal stimulus? (See\n",
            "also the companion CCC Quad Paper on Pandemic Informatics, which discusses\n",
            "features that would be essential to solving large-scale problems like\n",
            "preparation for, and response to, the inevitable next pandemic.)\n",
            "  The past decade has brought remarkable advances in complementary areas: in\n",
            "sensors, which can now capture enormous amounts of data about the world, and in\n",
            "AI methods capable of learning to extract predictive patterns from those data.\n",
            "These advances may lead to a new era in computational simulation, in which\n",
            "sensors of many kinds are used to produce vast quantities of data, AI methods\n",
            "identify patterns in those data, and new AI-driven simulators combine\n",
            "machine-learned and mathematical rules to make accurate and actionable\n",
            "predictions. At the same time, there are new challenges -- computers in some\n",
            "important regards are no longer getting faster, and in some areas we are\n",
            "reaching the limits of mathematical understanding, or at least of our ability\n",
            "to translate mathematical understanding into efficient simulation. In this\n",
            "paper, we lay out some themes that we envision forming part of a cohesive,\n",
            "multi-disciplinary, and application-inspired research agenda on AI-driven\n",
            "simulators. \n",
            "URL: http://arxiv.org/pdf/2012.06049v1 \n",
            "\n",
            "\n",
            "216\n",
            "cs\n",
            "Title: Open Problems in Cooperative AI \n",
            "Authors: Allan Dafoe, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin R. McKee, Joel Z. Leibo, Kate Larson, Thore Graepel \n",
            "Date: 2020-12-15 21:39:50+00:00 \n",
            "Id: 2012.08630 \n",
            "Summary: Problems of cooperation--in which agents seek ways to jointly improve their\n",
            "welfare--are ubiquitous and important. They can be found at scales ranging from\n",
            "our daily routines--such as driving on highways, scheduling meetings, and\n",
            "working collaboratively--to our global challenges--such as peace, commerce, and\n",
            "pandemic preparedness. Arguably, the success of the human species is rooted in\n",
            "our ability to cooperate. Since machines powered by artificial intelligence are\n",
            "playing an ever greater role in our lives, it will be important to equip them\n",
            "with the capabilities necessary to cooperate and to foster cooperation.\n",
            "  We see an opportunity for the field of artificial intelligence to explicitly\n",
            "focus effort on this class of problems, which we term Cooperative AI. The\n",
            "objective of this research would be to study the many aspects of the problems\n",
            "of cooperation and to innovate in AI to contribute to solving these problems.\n",
            "Central goals include building machine agents with the capabilities needed for\n",
            "cooperation, building tools to foster cooperation in populations of (machine\n",
            "and/or human) agents, and otherwise conducting AI research for insight relevant\n",
            "to problems of cooperation. This research integrates ongoing work on\n",
            "multi-agent systems, game theory and social choice, human-machine interaction\n",
            "and alignment, natural-language processing, and the construction of social\n",
            "tools and platforms. However, Cooperative AI is not the union of these existing\n",
            "areas, but rather an independent bet about the productivity of specific kinds\n",
            "of conversations that involve these and other areas. We see opportunity to more\n",
            "explicitly focus on the problem of cooperation, to construct unified theory and\n",
            "vocabulary, and to build bridges with adjacent communities working on\n",
            "cooperation, including in the natural, social, and behavioural sciences. \n",
            "URL: http://arxiv.org/pdf/2012.08630v1 \n",
            "\n",
            "\n",
            "218\n",
            "cs\n",
            "Title: NeuNetS: An Automated Synthesis Engine for Neural Network Design \n",
            "Authors: Atin Sood, Benjamin Elder, Benjamin Herta, Chao Xue, Costas Bekas, A. Cristiano I. Malossi, Debashish Saha, Florian Scheidegger, Ganesh Venkataraman, Gegi Thomas, Giovanni Mariani, Hendrik Strobelt, Horst Samulowitz, Martin Wistuba, Matteo Manica, Mihir Choudhury, Rong Yan, Roxana Istrate, Ruchir Puri, Tejaswini Pedapati \n",
            "Date: 2019-01-17 00:23:41+00:00 \n",
            "Id: 1901.06261 \n",
            "Summary: Application of neural networks to a vast variety of practical applications is\n",
            "transforming the way AI is applied in practice. Pre-trained neural network\n",
            "models available through APIs or capability to custom train pre-built neural\n",
            "network architectures with customer data has made the consumption of AI by\n",
            "developers much simpler and resulted in broad adoption of these complex AI\n",
            "models. While prebuilt network models exist for certain scenarios, to try and\n",
            "meet the constraints that are unique to each application, AI teams need to\n",
            "think about developing custom neural network architectures that can meet the\n",
            "tradeoff between accuracy and memory footprint to achieve the tight constraints\n",
            "of their unique use-cases. However, only a small proportion of data science\n",
            "teams have the skills and experience needed to create a neural network from\n",
            "scratch, and the demand far exceeds the supply. In this paper, we present\n",
            "NeuNetS : An automated Neural Network Synthesis engine for custom neural\n",
            "network design that is available as part of IBM's AI OpenScale's product.\n",
            "NeuNetS is available for both Text and Image domains and can build neural\n",
            "networks for specific tasks in a fraction of the time it takes today with human\n",
            "effort, and with accuracy similar to that of human-designed AI models. \n",
            "URL: http://arxiv.org/pdf/1901.06261v1 \n",
            "\n",
            "\n",
            "219\n",
            "cs\n",
            "Title: Self-explaining AI as an alternative to interpretable AI \n",
            "Authors: Daniel C. Elton \n",
            "Date: 2020-02-12 18:50:11+00:00 \n",
            "Id: 2002.05149 \n",
            "Summary: The ability to explain decisions made by AI systems is highly sought after,\n",
            "especially in domains where human lives are at stake such as medicine or\n",
            "autonomous vehicles. While it is often possible to approximate the input-output\n",
            "relations of deep neural networks with a few human-understandable rules, the\n",
            "discovery of the double descent phenomena suggests that such approximations do\n",
            "not accurately capture the mechanism by which deep neural networks work. Double\n",
            "descent indicates that deep neural networks typically operate by smoothly\n",
            "interpolating between data points rather than by extracting a few high level\n",
            "rules. As a result, neural networks trained on complex real world data are\n",
            "inherently hard to interpret and prone to failure if asked to extrapolate. To\n",
            "show how we might be able to trust AI despite these problems we introduce the\n",
            "concept of self-explaining AI. Self-explaining AIs are capable of providing a\n",
            "human-understandable explanation of each decision along with confidence levels\n",
            "for both the decision and explanation. For this approach to work, it is\n",
            "important that the explanation actually be related to the decision, ideally\n",
            "capturing the mechanism used to arrive at the explanation. Finally, we argue it\n",
            "is important that deep learning based systems include a \"warning light\" based\n",
            "on techniques from applicability domain analysis to warn the user if a model is\n",
            "asked to extrapolate outside its training distribution. For a video\n",
            "presentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& . \n",
            "URL: http://arxiv.org/pdf/2002.05149v6 \n",
            "\n",
            "\n",
            "220\n",
            "cs\n",
            "Title: AI from concrete to abstract: demystifying artificial intelligence to the general public \n",
            "Authors: Rubens Lacerda Queiroz, Fábio Ferrentini Sampaio, Cabral Lima, Priscila Machado Vieira Lima \n",
            "Date: 2020-06-07 01:14:06+00:00 \n",
            "Id: 2006.04013 \n",
            "Summary: Artificial Intelligence (AI) has been adopted in a wide range of domains.\n",
            "This shows the imperative need to develop means to endow common people with a\n",
            "minimum understanding of what AI means. Combining visual programming and WiSARD\n",
            "weightless artificial neural networks, this article presents a new methodology,\n",
            "AI from concrete to abstract (AIcon2abs), to enable general people (including\n",
            "children) to achieve this goal. The main strategy adopted by is to promote a\n",
            "demystification of artificial intelligence via practical activities related to\n",
            "the development of learning machines, as well as through the observation of\n",
            "their learning process. Thus, it is possible to provide subjects with skills\n",
            "that contributes to making them insightful actors in debates and decisions\n",
            "involving the adoption of artificial intelligence mechanisms. Currently,\n",
            "existing approaches to the teaching of basic AI concepts through programming\n",
            "treat machine intelligence as an external element/module. After being trained,\n",
            "that external module is coupled to the main application being developed by the\n",
            "learners. In the methodology herein presented, both training and classification\n",
            "tasks are blocks that compose the main program, just as the other programming\n",
            "constructs. As a beneficial side effect of AIcon2abs, the difference between a\n",
            "program capable of learning from data and a conventional computer program\n",
            "becomes more evident. In addition, the simplicity of the WiSARD weightless\n",
            "artificial neural network model enables easy visualization and understanding of\n",
            "training and classification tasks internal realization. \n",
            "URL: http://arxiv.org/pdf/2006.04013v5 \n",
            "\n",
            "\n",
            "221\n",
            "cs\n",
            "Title: Towards a Policy-as-a-Service Framework to Enable Compliant, Trustworthy AI and HRI Systems in the Wild \n",
            "Authors: Alexis Morris, Hallie Siegel, Jonathan Kelly \n",
            "Date: 2020-10-06 18:32:31+00:00 \n",
            "Id: 2010.07022 \n",
            "Summary: Building trustworthy autonomous systems is challenging for many reasons\n",
            "beyond simply trying to engineer agents that 'always do the right thing.' There\n",
            "is a broader context that is often not considered within AI and HRI: that the\n",
            "problem of trustworthiness is inherently socio-technical and ultimately\n",
            "involves a broad set of complex human factors and multidimensional\n",
            "relationships that can arise between agents, humans, organizations, and even\n",
            "governments and legal institutions, each with their own understanding and\n",
            "definitions of trust. This complexity presents a significant barrier to the\n",
            "development of trustworthy AI and HRI systems---while systems developers may\n",
            "desire to have their systems 'always do the right thing,' they generally lack\n",
            "the practical tools and expertise in law, regulation, policy and ethics to\n",
            "ensure this outcome. In this paper, we emphasize the \"fuzzy\" socio-technical\n",
            "aspects of trustworthiness and the need for their careful consideration during\n",
            "both design and deployment. We hope to contribute to the discussion of\n",
            "trustworthy engineering in AI and HRI by i) describing the policy landscape\n",
            "that must be considered when addressing trustworthy computing and the need for\n",
            "usable trust models, ii) highlighting an opportunity for trustworthy-by-design\n",
            "intervention within the systems engineering process, and iii) introducing the\n",
            "concept of a \"policy-as-a-service\" (PaaS) framework that can be readily applied\n",
            "by AI systems engineers to address the fuzzy problem of trust during the\n",
            "development and (eventually) runtime process. We envision that the PaaS\n",
            "approach, which offloads the development of policy design parameters and\n",
            "maintenance of policy standards to policy experts, will enable runtime trust\n",
            "capabilities intelligent systems in the wild. \n",
            "URL: http://arxiv.org/pdf/2010.07022v1 \n",
            "\n",
            "\n",
            "222\n",
            "cs\n",
            "Title: Answer Set Programming Modulo `Space-Time' \n",
            "Authors: Carl Schultz, Mehul Bhatt, Jakob Suchan, Przemysław Wałęga \n",
            "Date: 2018-05-17 17:05:30+00:00 \n",
            "Id: 1805.06861 \n",
            "Summary: We present ASP Modulo `Space-Time', a declarative representational and\n",
            "computational framework to perform commonsense reasoning about regions with\n",
            "both spatial and temporal components. Supported are capabilities for mixed\n",
            "qualitative-quantitative reasoning, consistency checking, and inferring\n",
            "compositions of space-time relations; these capabilities combine and synergise\n",
            "for applications in a range of AI application areas where the processing and\n",
            "interpretation of spatio-temporal data is crucial. The framework and resulting\n",
            "system is the only general KR-based method for declaratively reasoning about\n",
            "the dynamics of `space-time' regions as first-class objects. We present an\n",
            "empirical evaluation (with scalability and robustness results), and include\n",
            "diverse application examples involving interpretation and control tasks. \n",
            "URL: http://arxiv.org/pdf/1805.06861v1 \n",
            "\n",
            "\n",
            "223\n",
            "cs\n",
            "Title: Learning from few examples with nonlinear feature maps \n",
            "Authors: Ivan Y. Tyukin, Oliver Sutton, Alexander N. Gorban \n",
            "Date: 2022-03-31 10:36:50+00:00 \n",
            "Id: 2203.16935 \n",
            "Summary: In this work we consider the problem of data classification in post-classical\n",
            "settings were the number of training examples consists of mere few data points.\n",
            "We explore the phenomenon and reveal key relationships between dimensionality\n",
            "of AI model's feature space, non-degeneracy of data distributions, and the\n",
            "model's generalisation capabilities. The main thrust of our present analysis is\n",
            "on the influence of nonlinear feature transformations mapping original data\n",
            "into higher- and possibly infinite-dimensional spaces on the resulting model's\n",
            "generalisation capabilities. Subject to appropriate assumptions, we establish\n",
            "new relationships between intrinsic dimensions of the transformed data and the\n",
            "probabilities to learn successfully from few presentations. \n",
            "URL: http://arxiv.org/pdf/2203.16935v1 \n",
            "\n",
            "\n",
            "224\n",
            "cs\n",
            "Title: Wikipedia for Smart Machines and Double Deep Machine Learning \n",
            "Authors: Moshe BenBassat \n",
            "Date: 2017-11-17 12:59:22+00:00 \n",
            "Id: 1711.06517 \n",
            "Summary: Very important breakthroughs in data centric deep learning algorithms led to\n",
            "impressive performance in transactional point applications of Artificial\n",
            "Intelligence (AI) such as Face Recognition, or EKG classification. With all due\n",
            "appreciation, however, knowledge blind data only machine learning algorithms\n",
            "have severe limitations for non-transactional AI applications, such as medical\n",
            "diagnosis beyond the EKG results. Such applications require deeper and broader\n",
            "knowledge in their problem solving capabilities, e.g. integrating anatomy and\n",
            "physiology knowledge with EKG results and other patient findings. Following a\n",
            "review and illustrations of such limitations for several real life AI\n",
            "applications, we point at ways to overcome them. The proposed Wikipedia for\n",
            "Smart Machines initiative aims at building repositories of software structures\n",
            "that represent humanity science & technology knowledge in various parts of\n",
            "life; knowledge that we all learn in schools, universities and during our\n",
            "professional life. Target readers for these repositories are smart machines;\n",
            "not human. AI software developers will have these Reusable Knowledge structures\n",
            "readily available, hence, the proposed name ReKopedia. Big Data is by now a\n",
            "mature technology, it is time to focus on Big Knowledge. Some will be derived\n",
            "from data, some will be obtained from mankind gigantic repository of knowledge.\n",
            "Wikipedia for smart machines along with the new Double Deep Learning approach\n",
            "offer a paradigm for integrating datacentric deep learning algorithms with\n",
            "algorithms that leverage deep knowledge, e.g. evidential reasoning and\n",
            "causality reasoning. For illustration, a project is described to produce\n",
            "ReKopedia knowledge modules for medical diagnosis of about 1,000 disorders.\n",
            "Data is important, but knowledge deep, basic, and commonsense is equally\n",
            "important. \n",
            "URL: http://arxiv.org/pdf/1711.06517v2 \n",
            "\n",
            "\n",
            "225\n",
            "cs\n",
            "Title: The Risk to Population Health Equity Posed by Automated Decision Systems: A Narrative Review \n",
            "Authors: Mitchell Burger \n",
            "Date: 2020-01-18 06:52:47+00:00 \n",
            "Id: 2001.06615 \n",
            "Summary: Artificial intelligence is already ubiquitous, and is increasingly being used\n",
            "to autonomously make ever more consequential decisions. However, there has been\n",
            "relatively little research into the existing and possible consequences for\n",
            "population health equity. A narrative review was undertaken using a hermeneutic\n",
            "approach to explore current and future uses of narrow AI and automated decision\n",
            "systems (ADS) in medicine and public health, issues that have emerged, and\n",
            "implications for equity. Accounts reveal a tremendous expectation on AI to\n",
            "transform medical and public health practices. Prominent demonstrations of AI\n",
            "capability - particularly in diagnostic decision making, risk prediction, and\n",
            "surveillance - are stimulating rapid adoption, spurred by COVID-19. Automated\n",
            "decisions being made have significant consequences for individual and\n",
            "population health and wellbeing. Meanwhile, it is evident that hazards\n",
            "including bias, incontestability, and privacy erosion have emerged in sensitive\n",
            "domains such as criminal justice where narrow AI and ADS are in common use.\n",
            "Reports of issues arising from their use in health are already appearing. As\n",
            "the use of ADS in health expands, it is probable that these hazards will\n",
            "manifest more widely. Bias, incontestability, and privacy erosion give rise to\n",
            "mechanisms by which existing social, economic and health disparities are\n",
            "perpetuated and amplified. Consequently, there is a significant risk that use\n",
            "of ADS in health will exacerbate existing population health inequities. The\n",
            "industrial scale and rapidity with which ADS can be applied heightens the risk\n",
            "to population health equity. It is incumbent on health practitioners and policy\n",
            "makers therefore to explore the potential implications of using ADS, to ensure\n",
            "the use of artificial intelligence promotes population health and equity. \n",
            "URL: http://arxiv.org/pdf/2001.06615v2 \n",
            "\n",
            "\n",
            "226\n",
            "cs\n",
            "Title: Sparse Optimization for Green Edge AI Inference \n",
            "Authors: Xiangyu Yang, Sheng Hua, Yuanming Shi, Hao Wang, Jun Zhang, Khaled B. Letaief \n",
            "Date: 2020-02-24 05:21:58+00:00 \n",
            "Id: 2002.10080 \n",
            "Summary: With the rapid upsurge of deep learning tasks at the network edge, effective\n",
            "edge artificial intelligence (AI) inference becomes critical to provide\n",
            "low-latency intelligent services for mobile users via leveraging the edge\n",
            "computing capability. In such scenarios, energy efficiency becomes a primary\n",
            "concern. In this paper, we present a joint inference task selection and\n",
            "downlink beamforming strategy to achieve energy-efficient edge AI inference\n",
            "through minimizing the overall power consumption consisting of both computation\n",
            "and transmission power consumption, yielding a mixed combinatorial optimization\n",
            "problem. By exploiting the inherent connections between the set of task\n",
            "selection and group sparsity structural transmit beamforming vector, we\n",
            "reformulate the optimization as a group sparse beamforming problem. To solve\n",
            "this challenging problem, we propose a log-sum function based three-stage\n",
            "approach. By adopting the log-sum function to enhance the group sparsity, a\n",
            "proximal iteratively reweighted algorithm is developed. Furthermore, we\n",
            "establish the global convergence analysis and provide the ergodic worst-case\n",
            "convergence rate for this algorithm. Simulation results will demonstrate the\n",
            "effectiveness of the proposed approach for improving energy efficiency in edge\n",
            "AI inference systems. \n",
            "URL: http://arxiv.org/pdf/2002.10080v2 \n",
            "\n",
            "\n",
            "227\n",
            "cs\n",
            "Title: A Neuro-AI Interface for Evaluating Generative Adversarial Networks \n",
            "Authors: Zhengwei Wang, Qi She, Alan F. Smeaton, Tomas E. Ward, Graham Healy \n",
            "Date: 2020-03-05 17:53:43+00:00 \n",
            "Id: 2003.03193 \n",
            "Summary: Generative adversarial networks (GANs) are increasingly attracting attention\n",
            "in the computer vision, natural language processing, speech synthesis and\n",
            "similar domains. However, evaluating the performance of GANs is still an open\n",
            "and challenging problem. Existing evaluation metrics primarily measure the\n",
            "dissimilarity between real and generated images using automated statistical\n",
            "methods. They often require large sample sizes for evaluation and do not\n",
            "directly reflect human perception of image quality. In this work, we introduce\n",
            "an evaluation metric called Neuroscore, for evaluating the performance of GANs,\n",
            "that more directly reflects psychoperceptual image quality through the\n",
            "utilization of brain signals. Our results show that Neuroscore has superior\n",
            "performance to the current evaluation metrics in that: (1) It is more\n",
            "consistent with human judgment; (2) The evaluation process needs much smaller\n",
            "numbers of samples; and (3) It is able to rank the quality of images on a per\n",
            "GAN basis. A convolutional neural network (CNN) based neuro-AI interface is\n",
            "proposed to predict Neuroscore from GAN-generated images directly without the\n",
            "need for neural responses. Importantly, we show that including neural responses\n",
            "during the training phase of the network can significantly improve the\n",
            "prediction capability of the proposed model. Codes and data can be referred at\n",
            "this link: https://github.com/villawang/Neuro-AI-Interface. \n",
            "URL: http://arxiv.org/pdf/2003.03193v2 \n",
            "\n",
            "\n",
            "228\n",
            "cs\n",
            "Title: DAISI: Database for AI Surgical Instruction \n",
            "Authors: Edgar Rojas-Muñoz, Kyle Couperus, Juan Wachs \n",
            "Date: 2020-03-22 22:07:43+00:00 \n",
            "Id: 2004.02809 \n",
            "Summary: Telementoring surgeons as they perform surgery can be essential in the\n",
            "treatment of patients when in situ expertise is not available. Nonetheless,\n",
            "expert mentors are often unavailable to provide trainees with real-time medical\n",
            "guidance. When mentors are unavailable, a fallback autonomous mechanism should\n",
            "provide medical practitioners with the required guidance. However,\n",
            "AI/autonomous mentoring in medicine has been limited by the availability of\n",
            "generalizable prediction models, and surgical procedures datasets to train\n",
            "those models with. This work presents the initial steps towards the development\n",
            "of an intelligent artificial system for autonomous medical mentoring.\n",
            "Specifically, we present the first Database for AI Surgical Instruction\n",
            "(DAISI). DAISI leverages on images and instructions to provide step-by-step\n",
            "demonstrations of how to perform procedures from various medical disciplines.\n",
            "The dataset was acquired from real surgical procedures and data from academic\n",
            "textbooks. We used DAISI to train an encoder-decoder neural network capable of\n",
            "predicting medical instructions given a current view of the surgery.\n",
            "Afterwards, the instructions predicted by the network were evaluated using\n",
            "cumulative BLEU scores and input from expert physicians. According to the BLEU\n",
            "scores, the predicted and ground truth instructions were as high as 67%\n",
            "similar. Additionally, expert physicians subjectively assessed the algorithm\n",
            "using Likert scale, and considered that the predicted descriptions were related\n",
            "to the images. This work provides a baseline for AI algorithms to assist in\n",
            "autonomous medical mentoring. \n",
            "URL: http://arxiv.org/pdf/2004.02809v1 \n",
            "\n",
            "\n",
            "229\n",
            "cs\n",
            "Title: Bias in Multimodal AI: Testbed for Fair Automatic Recruitment \n",
            "Authors: Alejandro Peña, Ignacio Serna, Aythami Morales, Julian Fierrez \n",
            "Date: 2020-04-15 15:58:05+00:00 \n",
            "Id: 2004.07173 \n",
            "Summary: The presence of decision-making algorithms in society is rapidly increasing\n",
            "nowadays, while concerns about their transparency and the possibility of these\n",
            "algorithms becoming new sources of discrimination are arising. In fact, many\n",
            "relevant automated systems have been shown to make decisions based on sensitive\n",
            "information or discriminate certain social groups (e.g. certain biometric\n",
            "systems for person recognition). With the aim of studying how current\n",
            "multimodal algorithms based on heterogeneous sources of information are\n",
            "affected by sensitive elements and inner biases in the data, we propose a\n",
            "fictitious automated recruitment testbed: FairCVtest. We train automatic\n",
            "recruitment algorithms using a set of multimodal synthetic profiles consciously\n",
            "scored with gender and racial biases. FairCVtest shows the capacity of the\n",
            "Artificial Intelligence (AI) behind such recruitment tool to extract sensitive\n",
            "information from unstructured data, and exploit it in combination to data\n",
            "biases in undesirable (unfair) ways. Finally, we present a list of recent works\n",
            "developing techniques capable of removing sensitive information from the\n",
            "decision-making process of deep learning architectures. We have used one of\n",
            "these algorithms (SensitiveNets) to experiment discrimination-aware learning\n",
            "for the elimination of sensitive information in our multimodal AI framework.\n",
            "Our methodology and results show how to generate fairer AI-based tools in\n",
            "general, and in particular fairer automated recruitment systems. \n",
            "URL: http://arxiv.org/pdf/2004.07173v1 \n",
            "\n",
            "\n",
            "230\n",
            "cs\n",
            "Title: Using Semantic Web Services for AI-Based Research in Industry 4.0 \n",
            "Authors: Lukas Malburg, Patrick Klein, Ralph Bergmann \n",
            "Date: 2020-07-07 15:58:10+00:00 \n",
            "Id: 2007.03580 \n",
            "Summary: The transition to Industry 4.0 requires smart manufacturing systems that are\n",
            "easily configurable and provide a high level of flexibility during\n",
            "manufacturing in order to achieve mass customization or to support cloud\n",
            "manufacturing. To realize this, Cyber-Physical Systems (CPSs) combined with\n",
            "Artificial Intelligence (AI) methods find their way into manufacturing shop\n",
            "floors. For using AI methods in the context of Industry 4.0, semantic web\n",
            "services are indispensable to provide a reasonable abstraction of the\n",
            "underlying manufacturing capabilities. In this paper, we present semantic web\n",
            "services for AI-based research in Industry 4.0. Therefore, we developed more\n",
            "than 300 semantic web services for a physical simulation factory based on Web\n",
            "Ontology Language for Web Services (OWL-S) and Web Service Modeling Ontology\n",
            "(WSMO) and linked them to an already existing domain ontology for intelligent\n",
            "manufacturing control. Suitable for the requirements of CPS environments, our\n",
            "pre- and postconditions are verified in near real-time by invoking other\n",
            "semantic web services in contrast to complex reasoning within the knowledge\n",
            "base. Finally, we evaluate our implementation by executing a cyber-physical\n",
            "workflow composed of semantic web services using a workflow management system. \n",
            "URL: http://arxiv.org/pdf/2007.03580v1 \n",
            "\n",
            "\n",
            "231\n",
            "cs\n",
            "Title: Artificial Intelligence at the Edge \n",
            "Authors: Elisa Bertino, Sujata Banerjee \n",
            "Date: 2020-12-10 02:08:47+00:00 \n",
            "Id: 2012.05410 \n",
            "Summary: The Internet of Things (IoT) and edge computing applications aim to support a\n",
            "variety of societal needs, including the global pandemic situation that the\n",
            "entire world is currently experiencing and responses to natural disasters.\n",
            "  The need for real-time interactive applications such as immersive video\n",
            "conferencing, augmented/virtual reality, and autonomous vehicles, in education,\n",
            "healthcare, disaster recovery and other domains, has never been higher. At the\n",
            "same time, there have been recent technological breakthroughs in highly\n",
            "relevant fields such as artificial intelligence (AI)/machine learning (ML),\n",
            "advanced communication systems (5G and beyond), privacy-preserving\n",
            "computations, and hardware accelerators. 5G mobile communication networks\n",
            "increase communication capacity, reduce transmission latency and error, and\n",
            "save energy -- capabilities that are essential for new applications. The\n",
            "envisioned future 6G technology will integrate many more technologies,\n",
            "including for example visible light communication, to support groundbreaking\n",
            "applications, such as holographic communications and high precision\n",
            "manufacturing. Many of these applications require computations and analytics\n",
            "close to application end-points: that is, at the edge of the network, rather\n",
            "than in a centralized cloud. AI techniques applied at the edge have tremendous\n",
            "potential both to power new applications and to need more efficient operation\n",
            "of edge infrastructure. However, it is critical to understand where to deploy\n",
            "AI systems within complex ecosystems consisting of advanced applications and\n",
            "the specific real-time requirements towards AI systems. \n",
            "URL: http://arxiv.org/pdf/2012.05410v1 \n",
            "\n",
            "\n",
            "232\n",
            "cs\n",
            "Title: Proceedings of the 1st International Workshop on Adaptive Cyber Defense \n",
            "Authors: Damian Marriott, Kimberly Ferguson-Walter, Sunny Fugate, Marco Carvalho \n",
            "Date: 2021-08-19 03:41:48+00:00 \n",
            "Id: 2108.08476 \n",
            "Summary: The 1st International Workshop on Adaptive Cyber Defense was held as part of\n",
            "the 2021 International Joint Conference on Artificial Intelligence. This\n",
            "workshop was organized to share research that explores unique applications of\n",
            "Artificial Intelligence (AI) and Machine Learning (ML) as foundational\n",
            "capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot\n",
            "currently be reliably and effectively defended without extensive reliance on\n",
            "human experts. Skilled cyber defenders are in short supply and often cannot\n",
            "respond fast enough to cyber threats.\n",
            "  Building on recent advances in AI and ML the Cyber defense research community\n",
            "has been motivated to develop new dynamic and sustainable defenses through the\n",
            "adoption of AI and ML techniques to both cyber and non-cyber settings. Bridging\n",
            "critical gaps between AI and Cyber researchers and practitioners can accelerate\n",
            "efforts to create semi-autonomous cyber defenses that can learn to recognize\n",
            "and respond to cyber attacks or discover and mitigate weaknesses in cooperation\n",
            "with other cyber operation systems and human experts. Furthermore, these\n",
            "defenses are expected to be adaptive and able to evolve over time to thwart\n",
            "changes in attacker behavior, changes in the system health and readiness, and\n",
            "natural shifts in user behavior over time.\n",
            "  The Workshop (held on August 19th and 20th 2021 in Montreal-themed virtual\n",
            "reality) was comprised of technical presentations and a panel discussion\n",
            "focused on open problems and potential research solutions. Workshop submissions\n",
            "were peer reviewed by a panel of domain experts with a proceedings consisting\n",
            "of 10 technical articles exploring challenging problems of critical importance\n",
            "to national and global security. Participation in this workshop offered new\n",
            "opportunities to stimulate research and innovation in the emerging domain of\n",
            "adaptive and autonomous cyber defense. \n",
            "URL: http://arxiv.org/pdf/2108.08476v1 \n",
            "\n",
            "\n",
            "233\n",
            "cs\n",
            "Title: How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI \n",
            "Authors: Ashwin Kalyan, Abhinav Kumar, Arjun Chandrasekaran, Ashish Sabharwal, Peter Clark \n",
            "Date: 2021-10-27 06:39:33+00:00 \n",
            "Id: 2110.14207 \n",
            "Summary: Many real-world problems require the combined application of multiple\n",
            "reasoning abilities employing suitable abstractions, commonsense knowledge, and\n",
            "creative synthesis of problem-solving strategies. To help advance AI systems\n",
            "towards such capabilities, we propose a new reasoning challenge, namely Fermi\n",
            "Problems (FPs), which are questions whose answers can only be approximately\n",
            "estimated because their precise computation is either impractical or\n",
            "impossible. For example, \"How much would the sea level rise if all ice in the\n",
            "world melted?\" FPs are commonly used in quizzes and interviews to bring out and\n",
            "evaluate the creative reasoning abilities of humans. To do the same for AI\n",
            "systems, we present two datasets: 1) A collection of 1k real-world FPs sourced\n",
            "from quizzes and olympiads; and 2) a bank of 10k synthetic FPs of intermediate\n",
            "complexity to serve as a sandbox for the harder real-world challenge. In\n",
            "addition to question answer pairs, the datasets contain detailed solutions in\n",
            "the form of an executable program and supporting facts, helping in supervision\n",
            "and evaluation of intermediate steps. We demonstrate that even extensively\n",
            "fine-tuned large scale language models perform poorly on these datasets, on\n",
            "average making estimates that are off by two orders of magnitude. Our\n",
            "contribution is thus the crystallization of several unsolved AI problems into a\n",
            "single, new challenge that we hope will spur further advances in building\n",
            "systems that can reason. \n",
            "URL: http://arxiv.org/pdf/2110.14207v2 \n",
            "\n",
            "\n",
            "234\n",
            "cs\n",
            "Title: Mimicking Playstyle by Adapting Parameterized Behavior Trees in RTS Games \n",
            "Authors: Andrzej Kozik, Tomasz Machalewski, Mariusz Marek, Adrian Ochmann \n",
            "Date: 2021-11-23 20:36:28+00:00 \n",
            "Id: 2111.12144 \n",
            "Summary: The discovery of Behavior Trees (BTs) impacted the field of Artificial\n",
            "Intelligence (AI) in games, by providing flexible and natural representation of\n",
            "non-player characters (NPCs) logic, manageable by game-designers. Nevertheless,\n",
            "increased pressure on ever better NPCs AI-agents forced complexity of\n",
            "handcrafted BTs to became barely-tractable and error-prone. On the other hand,\n",
            "while many just-launched on-line games suffer from player-shortage, the\n",
            "existence of AI with a broad-range of capabilities could increase players\n",
            "retention. Therefore, to handle above challenges, recent trends in the field\n",
            "focused on automatic creation of AI-agents: from deep- and\n",
            "reinforcementlearning techniques to combinatorial (constrained) optimization\n",
            "and evolution of BTs. In this paper, we present a novel approach to\n",
            "semi-automatic construction of AI-agents, that mimic and generalize given human\n",
            "gameplays by adapting and tuning of expert-created BT under a developed\n",
            "similarity metric between source and BT gameplays. To this end, we formulated\n",
            "mixed discrete-continuous optimization problem, in which topological and\n",
            "functional changes of the BT are reflected in numerical variables, and\n",
            "constructed a dedicated hybrid-metaheuristic. The performance of presented\n",
            "approach was verified experimentally in a prototype real-time strategy game.\n",
            "Carried out experiments confirmed efficiency and perspectives of presented\n",
            "approach, which is going to be applied in a commercial game. \n",
            "URL: http://arxiv.org/pdf/2111.12144v1 \n",
            "\n",
            "\n",
            "235\n",
            "cs\n",
            "Title: Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention \n",
            "Authors: Yichong Xu, Chenguang Zhu, Shuohang Wang, Siqi Sun, Hao Cheng, Xiaodong Liu, Jianfeng Gao, Pengcheng He, Michael Zeng, Xuedong Huang \n",
            "Date: 2021-12-06 18:59:02+00:00 \n",
            "Id: 2112.03254 \n",
            "Summary: Most of today's AI systems focus on using self-attention mechanisms and\n",
            "transformer architectures on large amounts of diverse data to achieve\n",
            "impressive performance gains. In this paper, we propose to augment the\n",
            "transformer architecture with an external attention mechanism to bring external\n",
            "knowledge and context to bear. By integrating external information into the\n",
            "prediction process, we hope to reduce the need for ever-larger models and\n",
            "increase the democratization of AI systems. We find that the proposed external\n",
            "attention mechanism can significantly improve the performance of existing AI\n",
            "systems, allowing practitioners to easily customize foundation AI models to\n",
            "many diverse downstream applications. In particular, we focus on the task of\n",
            "Commonsense Reasoning, demonstrating that the proposed external attention\n",
            "mechanism can augment existing transformer models and significantly improve the\n",
            "model's reasoning capabilities. The proposed system, Knowledgeable External\n",
            "Attention for commonsense Reasoning (KEAR), reaches human parity on the open\n",
            "CommonsenseQA research benchmark with an accuracy of 89.4\\% in comparison to\n",
            "the human accuracy of 88.9\\%. \n",
            "URL: http://arxiv.org/pdf/2112.03254v3 \n",
            "\n",
            "\n",
            "237\n",
            "cs\n",
            "Title: Cognitive Database: A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities \n",
            "Authors: Rajesh Bordawekar, Bortik Bandyopadhyay, Oded Shmueli \n",
            "Date: 2017-12-19 20:49:26+00:00 \n",
            "Id: 1712.07199 \n",
            "Summary: We propose Cognitive Databases, an approach for transparently enabling\n",
            "Artificial Intelligence (AI) capabilities in relational databases. A novel\n",
            "aspect of our design is to first view the structured data source as meaningful\n",
            "unstructured text, and then use the text to build an unsupervised neural\n",
            "network model using a Natural Language Processing (NLP) technique called word\n",
            "embedding. This model captures the hidden inter-/intra-column relationships\n",
            "between database tokens of different types. For each database token, the model\n",
            "includes a vector that encodes contextual semantic relationships. We seamlessly\n",
            "integrate the word embedding model into existing SQL query infrastructure and\n",
            "use it to enable a new class of SQL-based analytics queries called cognitive\n",
            "intelligence (CI) queries. CI queries use the model vectors to enable complex\n",
            "queries such as semantic matching, inductive reasoning queries such as\n",
            "analogies, predictive queries using entities not present in a database, and,\n",
            "more generally, using knowledge from external sources. We demonstrate unique\n",
            "capabilities of Cognitive Databases using an Apache Spark based prototype to\n",
            "execute inductive reasoning CI queries over a multi-modal database containing\n",
            "text and images. We believe our first-of-a-kind system exemplifies using AI\n",
            "functionality to endow relational databases with capabilities that were\n",
            "previously very hard to realize in practice. \n",
            "URL: http://arxiv.org/pdf/1712.07199v1 \n",
            "\n",
            "\n",
            "238\n",
            "cs\n",
            "Title: Digital Twin: From Concept to Practice \n",
            "Authors: Ashwin Agrawal, Martin Fischer, Vishal Singh \n",
            "Date: 2022-01-14 17:41:26+00:00 \n",
            "Id: 2201.06912 \n",
            "Summary: Recent technological developments and advances in Artificial Intelligence\n",
            "(AI) have enabled sophisticated capabilities to be a part of Digital Twin (DT),\n",
            "virtually making it possible to introduce automation into all aspects of work\n",
            "processes. Given these possibilities that DT can offer, practitioners are\n",
            "facing increasingly difficult decisions regarding what capabilities to select\n",
            "while deploying a DT in practice. The lack of research in this field has not\n",
            "helped either. It has resulted in the rebranding and reuse of emerging\n",
            "technological capabilities like prediction, simulation, AI, and Machine\n",
            "Learning (ML) as necessary constituents of DT. Inappropriate selection of\n",
            "capabilities in a DT can result in missed opportunities, strategic\n",
            "misalignments, inflated expectations, and risk of it being rejected as just\n",
            "hype by the practitioners. To alleviate this challenge, this paper proposes the\n",
            "digitalization framework, designed and developed by following a Design Science\n",
            "Research (DSR) methodology over a period of 18 months. The framework can help\n",
            "practitioners select an appropriate level of sophistication in a DT by weighing\n",
            "the pros and cons for each level, deciding evaluation criteria for the digital\n",
            "twin system, and assessing the implications of the selected DT on the\n",
            "organizational processes and strategies, and value creation. Three real-life\n",
            "case studies illustrate the application and usefulness of the framework. \n",
            "URL: http://arxiv.org/pdf/2201.06912v1 \n",
            "\n",
            "\n",
            "239\n",
            "cs\n",
            "Title: Planning With Discrete Harmonic Potential Fields \n",
            "Authors: Ahmad A. Masoud \n",
            "Date: 2016-08-21 12:48:45+00:00 \n",
            "Id: 1608.05931 \n",
            "Summary: In this work a discrete counterpart to the continuous harmonic potential\n",
            "field approach is suggested. The extension to the discrete case makes use of\n",
            "the strong relation HPF-based planning has to connectionist artificial\n",
            "intelligence (AI). Connectionist AI systems are networks of simple,\n",
            "interconnected processors running in parallel within the confines of the\n",
            "environment in which the planning action is to be synthesized. It is not hard\n",
            "to see that such a paradigm naturally lends itself to planning on weighted\n",
            "graphs where the processors may be seen as the vertices of the graph and the\n",
            "relations among them as its edges. Electrical networks are an effective\n",
            "realization of connectionist AI. The utility of the discrete HPF (DHPF)\n",
            "approach is demonstrated in three ways. First, the capability of the DHPF\n",
            "approach to generate new, abstract, planning techniques is demonstrated by\n",
            "constructing a novel, efficient, optimal, discrete planning method called the\n",
            "M* algorithm. Also, its ability to augment the capabilities of existing\n",
            "planners is demonstrated by suggesting a generic solution to the lower bound\n",
            "problem faced by the A* algorithm. The DHPF approach is shown to be useful in\n",
            "solving specific planning problems in communication. It is demonstrated that\n",
            "the discrete HPF paradigm can support routing on-the-fly while the network is\n",
            "still in a transient state. It is shown by simulation that if a path to the\n",
            "target always exist and the switching delays in the routers are negligible, a\n",
            "packet will reach its destination despite the changes in the network which may\n",
            "simultaneously take place while the packet is being routed. \n",
            "URL: http://arxiv.org/pdf/1608.05931v1 \n",
            "\n",
            "\n",
            "240\n",
            "cs\n",
            "Title: Fractal AI: A fragile theory of intelligence \n",
            "Authors: Sergio Hernandez Cerezo, Guillem Duran Ballester \n",
            "Date: 2018-03-13 21:17:26+00:00 \n",
            "Id: 1803.05049 \n",
            "Summary: Fractal AI is a theory for general artificial intelligence. It allows\n",
            "deriving new mathematical tools that constitute the foundations for a new kind\n",
            "of stochastic calculus, by modelling information using cellular automaton-like\n",
            "structures instead of smooth functions. In the repository included we are\n",
            "presenting a new Agent, derived from the first principles of the theory, which\n",
            "is capable of solving Atari games several orders of magnitude more efficiently\n",
            "than other similar techniques, like Monte Carlo Tree Search. The code provided\n",
            "shows how it is now possible to beat some of the current State of The Art\n",
            "benchmarks on Atari games, without previous learning and using less than 1000\n",
            "samples to calculate each one of the actions when standard MCTS uses 3 Million\n",
            "samples. Among other things, Fractal AI makes it possible to generate a huge\n",
            "database of top performing examples with a very little amount of computation\n",
            "required, transforming Reinforcement Learning into a supervised problem. The\n",
            "algorithm presented is capable of solving the exploration vs exploitation\n",
            "dilemma on both the discrete and continuous cases, while maintaining control\n",
            "over any aspect of the behaviour of the Agent. From a general approach, new\n",
            "techniques presented here have direct applications to other areas such as\n",
            "Non-equilibrium thermodynamics, chemistry, quantum physics, economics,\n",
            "information theory, and non-linear control theory. \n",
            "URL: http://arxiv.org/pdf/1803.05049v5 \n",
            "\n",
            "\n",
            "241\n",
            "cs\n",
            "Title: OpenEI: An Open Framework for Edge Intelligence \n",
            "Authors: Xingzhou Zhang, Yifan Wang, Sidi Lu, Liangkai Liu, Lanyu Xu, Weisong Shi \n",
            "Date: 2019-06-05 07:41:39+00:00 \n",
            "Id: 1906.01864 \n",
            "Summary: In the last five years, edge computing has attracted tremendous attention\n",
            "from industry and academia due to its promise to reduce latency, save\n",
            "bandwidth, improve availability, and protect data privacy to keep data secure.\n",
            "At the same time, we have witnessed the proliferation of AI algorithms and\n",
            "models which accelerate the successful deployment of intelligence mainly in\n",
            "cloud services. These two trends, combined together, have created a new\n",
            "horizon: Edge Intelligence (EI). The development of EI requires much attention\n",
            "from both the computer systems research community and the AI community to meet\n",
            "these demands. However, existing computing techniques used in the cloud are not\n",
            "applicable to edge computing directly due to the diversity of computing sources\n",
            "and the distribution of data sources. We envision that there missing a\n",
            "framework that can be rapidly deployed on edge and enable edge AI capabilities.\n",
            "To address this challenge, in this paper we first present the definition and a\n",
            "systematic review of EI. Then, we introduce an Open Framework for Edge\n",
            "Intelligence (OpenEI), which is a lightweight software platform to equip edges\n",
            "with intelligent processing and data sharing capability. We analyze four\n",
            "fundamental EI techniques which are used to build OpenEI and identify several\n",
            "open problems based on potential research directions. Finally, four typical\n",
            "application scenarios enabled by OpenEI are presented. \n",
            "URL: http://arxiv.org/pdf/1906.01864v1 \n",
            "\n",
            "\n",
            "242\n",
            "cs\n",
            "Title: Neuro-symbolic Architectures for Context Understanding \n",
            "Authors: Alessandro Oltramari, Jonathan Francis, Cory Henson, Kaixin Ma, Ruwan Wickramarachchi \n",
            "Date: 2020-03-09 15:04:07+00:00 \n",
            "Id: 2003.04707 \n",
            "Summary: Computational context understanding refers to an agent's ability to fuse\n",
            "disparate sources of information for decision-making and is, therefore,\n",
            "generally regarded as a prerequisite for sophisticated machine reasoning\n",
            "capabilities, such as in artificial intelligence (AI). Data-driven and\n",
            "knowledge-driven methods are two classical techniques in the pursuit of such\n",
            "machine sense-making capability. However, while data-driven methods seek to\n",
            "model the statistical regularities of events by making observations in the\n",
            "real-world, they remain difficult to interpret and they lack mechanisms for\n",
            "naturally incorporating external knowledge. Conversely, knowledge-driven\n",
            "methods, combine structured knowledge bases, perform symbolic reasoning based\n",
            "on axiomatic principles, and are more interpretable in their inferential\n",
            "processing; however, they often lack the ability to estimate the statistical\n",
            "salience of an inference. To combat these issues, we propose the use of hybrid\n",
            "AI methodology as a general framework for combining the strengths of both\n",
            "approaches. Specifically, we inherit the concept of neuro-symbolism as a way of\n",
            "using knowledge-bases to guide the learning progress of deep neural networks.\n",
            "We further ground our discussion in two applications of neuro-symbolism and, in\n",
            "both cases, show that our systems maintain interpretability while achieving\n",
            "comparable performance, relative to the state-of-the-art. \n",
            "URL: http://arxiv.org/pdf/2003.04707v1 \n",
            "\n",
            "\n",
            "243\n",
            "cs\n",
            "Title: Explainable Goal-Driven Agents and Robots -- A Comprehensive Review \n",
            "Authors: Fatai Sado, Chu Kiong Loo, Wei Shiung Liew, Matthias Kerzel, Stefan Wermter \n",
            "Date: 2020-04-21 01:41:20+00:00 \n",
            "Id: 2004.09705 \n",
            "Summary: Recent applications of autonomous agents and robots, such as self-driving\n",
            "cars, scenario-based trainers, exploration robots, and service robots have\n",
            "brought attention to crucial trust-related challenges associated with the\n",
            "current generation of artificial intelligence (AI) systems. AI systems based on\n",
            "the connectionist deep learning neural network approach lack capabilities of\n",
            "explaining their decisions and actions to others, despite their great\n",
            "successes. Without symbolic interpretation capabilities, they are black boxes,\n",
            "which renders their decisions or actions opaque, making it difficult to trust\n",
            "them in safety-critical applications. The recent stance on the explainability\n",
            "of AI systems has witnessed several approaches on eXplainable Artificial\n",
            "Intelligence (XAI); however, most of the studies have focused on data-driven\n",
            "XAI systems applied in computational sciences. Studies addressing the\n",
            "increasingly pervasive goal-driven agents and robots are still missing. This\n",
            "paper reviews approaches on explainable goal-driven intelligent agents and\n",
            "robots, focusing on techniques for explaining and communicating agents\n",
            "perceptual functions (example, senses, and vision) and cognitive reasoning\n",
            "(example, beliefs, desires, intention, plans, and goals) with humans in the\n",
            "loop. The review highlights key strategies that emphasize transparency,\n",
            "understandability, and continual learning for explainability. Finally, the\n",
            "paper presents requirements for explainability and suggests a roadmap for the\n",
            "possible realization of effective goal-driven explainable agents and robots. \n",
            "URL: http://arxiv.org/pdf/2004.09705v7 \n",
            "\n",
            "\n",
            "245\n",
            "cs\n",
            "Title: Advancing Computing's Foundation of US Industry & Society \n",
            "Authors: Thomas M. Conte, Ian T. Foster, William Gropp, Mark D. Hill \n",
            "Date: 2021-01-04 23:40:45+00:00 \n",
            "Id: 2101.01284 \n",
            "Summary: While past information technology (IT) advances have transformed society,\n",
            "future advances hold even greater promise. For example, we have only just begun\n",
            "to reap the changes from artificial intelligence (AI), especially machine\n",
            "learning (ML). Underlying IT's impact are the dramatic improvements in computer\n",
            "hardware, which deliver performance that unlock new capabilities. For example,\n",
            "recent successes in AI/ML required the synergy of improved algorithms and\n",
            "hardware architectures (e.g., general-purpose graphics processing units).\n",
            "However, unlike in the 20th Century and early 2000s, tomorrow's performance\n",
            "aspirations must be achieved without continued semiconductor scaling formerly\n",
            "provided by Moore's Law and Dennard Scaling. How will one deliver the next 100x\n",
            "improvement in capability at similar or less cost to enable great value? Can we\n",
            "make the next AI leap without 100x better hardware?\n",
            "  This whitepaper argues for a multipronged effort to develop new computing\n",
            "approaches beyond Moore's Law to advance the foundation that computing provides\n",
            "to US industry, education, medicine, science, and government. This impact\n",
            "extends far beyond the IT industry itself, as IT is now central for providing\n",
            "value across society, for example in semi-autonomous vehicles, tele-education,\n",
            "health wearables, viral analysis, and efficient administration. Herein we draw\n",
            "upon considerable visioning work by CRA's Computing Community Consortium (CCC)\n",
            "and the IEEE Rebooting Computing Initiative (IEEE RCI), enabled by thought\n",
            "leader input from industry, academia, and the US government. \n",
            "URL: http://arxiv.org/pdf/2101.01284v1 \n",
            "\n",
            "\n",
            "246\n",
            "cs\n",
            "Title: Bridging Sim2Real Gap Using Image Gradients for the Task of End-to-End Autonomous Driving \n",
            "Authors: Unnikrishnan R Nair, Sarthak Sharma, Udit Singh Parihar, Midhun S Menon, Srikanth Vidapanakal \n",
            "Date: 2022-05-16 07:07:53+00:00 \n",
            "Id: 2205.07481 \n",
            "Summary: We present the first prize solution to NeurIPS 2021 - AWS Deepracer\n",
            "Challenge. In this competition, the task was to train a reinforcement learning\n",
            "agent (i.e. an autonomous car), that learns to drive by interacting with its\n",
            "environment, a simulated track, by taking an action in a given state to\n",
            "maximize the expected reward. This model was then tested on a real-world track\n",
            "with a miniature AWS Deepracer car. Our goal is to train a model that can\n",
            "complete a lap as fast as possible without going off the track. The Deepracer\n",
            "challenge is a part of a series of embodied intelligence competitions in the\n",
            "field of autonomous vehicles, called The AI Driving Olympics (AI-DO). The\n",
            "overall objective of the AI-DO is to provide accessible mechanisms for\n",
            "benchmarking progress in autonomy applied to the task of autonomous driving.\n",
            "The tricky section of this challenge was the sim2real transfer of the learned\n",
            "skills. To reduce the domain gap in the observation space we did a canny edge\n",
            "detection in addition to cropping out of the unnecessary background\n",
            "information. We modeled the problem as a behavioral cloning task and used\n",
            "MLP-MIXER to optimize for runtime. We made sure our model was capable of\n",
            "handling control noise by careful filtration of the training data and that gave\n",
            "us a robust model capable of completing the track even when 50% of the commands\n",
            "were randomly changed. The overall runtime of the model was only 2-3ms on a\n",
            "modern CPU. \n",
            "URL: http://arxiv.org/pdf/2205.07481v1 \n",
            "\n",
            "\n",
            "247\n",
            "cs\n",
            "Title: Cooperative Automated Vehicles: a Review of Opportunities and Challenges in Socially Intelligent Vehicles Beyond Networking \n",
            "Authors: Seng W. Loke \n",
            "Date: 2017-10-02 02:22:58+00:00 \n",
            "Id: 1710.00461 \n",
            "Summary: The connected automated vehicle has been often touted as a technology that\n",
            "will become pervasive in society in the near future. One can view an automated\n",
            "vehicle as having Artificial Intelligence (AI) capabilities, being able to\n",
            "self-drive, sense its surroundings, recognise objects in its vicinity, and\n",
            "perform reasoning and decision-making.\n",
            "  Rather than being stand alone, we examine the need for automated vehicles to\n",
            "cooperate and interact within their socio-cyber-physical environments,\n",
            "including the problems cooperation will solve, but also the issues and\n",
            "challenges. We review current work in cooperation for automated vehicles, based\n",
            "on selected examples from the literature. We conclude noting the need for the\n",
            "ability to behave cooperatively as a form of social-AI capability for automated\n",
            "vehicles, beyond sensing the immediate environment and beyond the underlying\n",
            "networking technology. \n",
            "URL: http://arxiv.org/pdf/1710.00461v2 \n",
            "\n",
            "\n",
            "248\n",
            "cs\n",
            "Title: Using Thought-Provoking Children's Questions to Drive Artificial Intelligence Research \n",
            "Authors: Erik T. Mueller, Henry Minsky \n",
            "Date: 2015-08-27 16:23:49+00:00 \n",
            "Id: 1508.06924 \n",
            "Summary: We propose to use thought-provoking children's questions (TPCQs), namely\n",
            "Highlights BrainPlay questions, as a new method to drive artificial\n",
            "intelligence research and to evaluate the capabilities of general-purpose AI\n",
            "systems. These questions are designed to stimulate thought and learning in\n",
            "children, and they can be used to do the same thing in AI systems, while\n",
            "demonstrating the system's reasoning capabilities to the evaluator. We\n",
            "introduce the TPCQ task, which which takes a TPCQ question as input and\n",
            "produces as output (1) answers to the question and (2) learned generalizations.\n",
            "We discuss how BrainPlay questions stimulate learning. We analyze 244 BrainPlay\n",
            "questions, and we report statistics on question type, question class, answer\n",
            "cardinality, answer class, types of knowledge needed, and types of reasoning\n",
            "needed. We find that BrainPlay questions span many aspects of intelligence.\n",
            "Because the answers to BrainPlay questions and the generalizations learned from\n",
            "them are often highly open-ended, we suggest using human judges for evaluation. \n",
            "URL: http://arxiv.org/pdf/1508.06924v3 \n",
            "\n",
            "\n",
            "249\n",
            "cs\n",
            "Title: Model-free, Model-based, and General Intelligence \n",
            "Authors: Hector Geffner \n",
            "Date: 2018-06-06 17:15:27+00:00 \n",
            "Id: 1806.02308 \n",
            "Summary: During the 60s and 70s, AI researchers explored intuitions about intelligence\n",
            "by writing programs that displayed intelligent behavior. Many good ideas came\n",
            "out from this work but programs written by hand were not robust or general.\n",
            "After the 80s, research increasingly shifted to the development of learners\n",
            "capable of inferring behavior and functions from experience and data, and\n",
            "solvers capable of tackling well-defined but intractable models like SAT,\n",
            "classical planning, Bayesian networks, and POMDPs. The learning approach has\n",
            "achieved considerable success but results in black boxes that do not have the\n",
            "flexibility, transparency, and generality of their model-based counterparts.\n",
            "Model-based approaches, on the other hand, require models and scalable\n",
            "algorithms. Model-free learners and model-based solvers have close parallels\n",
            "with Systems 1 and 2 in current theories of the human mind: the first, a fast,\n",
            "opaque, and inflexible intuitive mind; the second, a slow, transparent, and\n",
            "flexible analytical mind. In this paper, I review developments in AI and draw\n",
            "on these theories to discuss the gap between model-free learners and\n",
            "model-based solvers, a gap that needs to be bridged in order to have\n",
            "intelligent systems that are robust and general. \n",
            "URL: http://arxiv.org/pdf/1806.02308v1 \n",
            "\n",
            "\n",
            "251\n",
            "cs\n",
            "Title: A Brief Summary of Interactions Between Meta-Learning and Self-Supervised Learning \n",
            "Authors: Huimin Peng \n",
            "Date: 2021-03-01 08:31:28+00:00 \n",
            "Id: 2103.00845 \n",
            "Summary: This paper briefly reviews the connections between meta-learning and\n",
            "self-supervised learning. Meta-learning can be applied to improve model\n",
            "generalization capability and to construct general AI algorithms.\n",
            "Self-supervised learning utilizes self-supervision from original data and\n",
            "extracts higher-level generalizable features through unsupervised pre-training\n",
            "or optimization of contrastive loss objectives. In self-supervised learning,\n",
            "data augmentation techniques are widely applied and data labels are not\n",
            "required since pseudo labels can be estimated from trained models on similar\n",
            "tasks. Meta-learning aims to adapt trained deep models to solve diverse tasks\n",
            "and to develop general AI algorithms. We review the associations of\n",
            "meta-learning with both generative and contrastive self-supervised learning\n",
            "models. Unlabeled data from multiple sources can be jointly considered even\n",
            "when data sources are vastly different. We show that an integration of\n",
            "meta-learning and self-supervised learning models can best contribute to the\n",
            "improvement of model generalization capability. Self-supervised learning guided\n",
            "by meta-learner and general meta-learning algorithms under self-supervision are\n",
            "both examples of possible combinations. \n",
            "URL: http://arxiv.org/pdf/2103.00845v2 \n",
            "\n",
            "\n",
            "252\n",
            "cs\n",
            "Title: Project Debater APIs: Decomposing the AI Grand Challenge \n",
            "Authors: Roy Bar-Haim, Yoav Kantor, Elad Venezian, Yoav Katz, Noam Slonim \n",
            "Date: 2021-10-03 15:50:32+00:00 \n",
            "Id: 2110.01029 \n",
            "Summary: Project Debater was revealed in 2019 as the first AI system that can debate\n",
            "human experts on complex topics. Engaging in a live debate requires a diverse\n",
            "set of skills, and Project Debater has been developed accordingly as a\n",
            "collection of components, each designed to perform a specific subtask. Project\n",
            "Debater APIs provide access to many of these capabilities, as well as to more\n",
            "recently developed ones. This diverse set of web services, publicly available\n",
            "for academic use, includes core NLP services, argument mining and analysis\n",
            "capabilities, and higher-level services for content summarization. We describe\n",
            "these APIs and their performance, and demonstrate how they can be used for\n",
            "building practical solutions. In particular, we will focus on Key Point\n",
            "Analysis, a novel technology that identifies the main points and their\n",
            "prevalence in a collection of texts such as survey responses and user reviews. \n",
            "URL: http://arxiv.org/pdf/2110.01029v1 \n",
            "\n",
            "\n",
            "253\n",
            "cs\n",
            "Title: Task-Oriented Image Transmission for Scene Classification in Unmanned Aerial Systems \n",
            "Authors: Xu Kang, Bin Song, Jie Guo, Zhijin Qin, F. Richard Yu \n",
            "Date: 2021-12-21 02:44:49+00:00 \n",
            "Id: 2112.10948 \n",
            "Summary: The vigorous developments of Internet of Things make it possible to extend\n",
            "its computing and storage capabilities to computing tasks in the aerial system\n",
            "with collaboration of cloud and edge, especially for artificial intelligence\n",
            "(AI) tasks based on deep learning (DL). Collecting a large amount of\n",
            "image/video data, Unmanned aerial vehicles (UAVs) can only handover intelligent\n",
            "analysis tasks to the back-end mobile edge computing (MEC) server due to their\n",
            "limited storage and computing capabilities. How to efficiently transmit the\n",
            "most correlated information for the AI model is a challenging topic. Inspired\n",
            "by the task-oriented communication in recent years, we propose a new aerial\n",
            "image transmission paradigm for the scene classification task. A lightweight\n",
            "model is developed on the front-end UAV for semantic blocks transmission with\n",
            "perception of images and channel conditions. In order to achieve the tradeoff\n",
            "between transmission latency and classification accuracy, deep reinforcement\n",
            "learning (DRL) is used to explore the semantic blocks which have the best\n",
            "contribution to the back-end classifier under various channel conditions.\n",
            "Experimental results show that the proposed method can significantly improve\n",
            "classification accuracy compared to the fixed transmission strategy and\n",
            "traditional content perception methods. \n",
            "URL: http://arxiv.org/pdf/2112.10948v1 \n",
            "\n",
            "\n",
            "254\n",
            "cs\n",
            "Title: iPLAN: Interactive and Procedural Layout Planning \n",
            "Authors: Feixiang He, Yanlong Huang, He Wang \n",
            "Date: 2022-03-27 23:21:15+00:00 \n",
            "Id: 2203.14412 \n",
            "Summary: Layout design is ubiquitous in many applications, e.g. architecture/urban\n",
            "planning, etc, which involves a lengthy iterative design process. Recently,\n",
            "deep learning has been leveraged to automatically generate layouts via image\n",
            "generation, showing a huge potential to free designers from laborious routines.\n",
            "While automatic generation can greatly boost productivity, designer input is\n",
            "undoubtedly crucial. An ideal AI-aided design tool should automate repetitive\n",
            "routines, and meanwhile accept human guidance and provide smart/proactive\n",
            "suggestions. However, the capability of involving humans into the loop has been\n",
            "largely ignored in existing methods which are mostly end-to-end approaches. To\n",
            "this end, we propose a new human-in-the-loop generative model, iPLAN, which is\n",
            "capable of automatically generating layouts, but also interacting with\n",
            "designers throughout the whole procedure, enabling humans and AI to co-evolve a\n",
            "sketchy idea gradually into the final design. iPLAN is evaluated on diverse\n",
            "datasets and compared with existing methods. The results show that iPLAN has\n",
            "high fidelity in producing similar layouts to those from human designers, great\n",
            "flexibility in accepting designer inputs and providing design suggestions\n",
            "accordingly, and strong generalizability when facing unseen design tasks and\n",
            "limited training data. \n",
            "URL: http://arxiv.org/pdf/2203.14412v1 \n",
            "\n",
            "\n",
            "257\n",
            "cs\n",
            "Title: AI system for fetal ultrasound in low-resource settings \n",
            "Authors: Ryan G. Gomes, Bellington Vwalika, Chace Lee, Angelica Willis, Marcin Sieniek, Joan T. Price, Christina Chen, Margaret P. Kasaro, James A. Taylor, Elizabeth M. Stringer, Scott Mayer McKinney, Ntazana Sindano, George E. Dahl, William Goodnight III, Justin Gilmer, Benjamin H. Chi, Charles Lau, Terry Spitz, T Saensuksopa, Kris Liu, Jonny Wong, Rory Pilgrim, Akib Uddin, Greg Corrado, Lily Peng, Katherine Chou, Daniel Tse, Jeffrey S. A. Stringer, Shravya Shetty \n",
            "Date: 2022-03-18 19:39:34+00:00 \n",
            "Id: 2203.10139 \n",
            "Summary: Despite considerable progress in maternal healthcare, maternal and perinatal\n",
            "deaths remain high in low-to-middle income countries. Fetal ultrasound is an\n",
            "important component of antenatal care, but shortage of adequately trained\n",
            "healthcare workers has limited its adoption. We developed and validated an\n",
            "artificial intelligence (AI) system that uses novice-acquired \"blind sweep\"\n",
            "ultrasound videos to estimate gestational age (GA) and fetal malpresentation.\n",
            "We further addressed obstacles that may be encountered in low-resourced\n",
            "settings. Using a simplified sweep protocol with real-time AI feedback on sweep\n",
            "quality, we have demonstrated the generalization of model performance to\n",
            "minimally trained novice ultrasound operators using low cost ultrasound devices\n",
            "with on-device AI integration. The GA model was non-inferior to standard fetal\n",
            "biometry estimates with as few as two sweeps, and the fetal malpresentation\n",
            "model had high AUC-ROCs across operators and devices. Our AI models have the\n",
            "potential to assist in upleveling the capabilities of lightly trained\n",
            "ultrasound operators in low resource settings. \n",
            "URL: http://arxiv.org/pdf/2203.10139v1 \n",
            "\n",
            "\n",
            "259\n",
            "cs\n",
            "Title: LuNet: A Deep Neural Network for Network Intrusion Detection \n",
            "Authors: Peilun Wu, Hui Guo \n",
            "Date: 2019-09-22 15:34:27+00:00 \n",
            "Id: 1909.10031 \n",
            "Summary: Network attack is a significant security issue for modern society. From small\n",
            "mobile devices to large cloud platforms, almost all computing products, used in\n",
            "our daily life, are networked and potentially under the threat of network\n",
            "intrusion. With the fast-growing network users, network intrusions become more\n",
            "and more frequent, volatile and advanced. Being able to capture intrusions in\n",
            "time for such a large scale network is critical and very challenging. To this\n",
            "end, the machine learning (or AI) based network intrusion detection (NID), due\n",
            "to its intelligent capability, has drawn increasing attention in recent years.\n",
            "Compared to the traditional signature-based approaches, the AI-based solutions\n",
            "are more capable of detecting variants of advanced network attacks. However,\n",
            "the high detection rate achieved by the existing designs is usually accompanied\n",
            "by a high rate of false alarms, which may significantly discount the overall\n",
            "effectiveness of the intrusion detection system. In this paper, we consider the\n",
            "existence of spatial and temporal features in the network traffic data and\n",
            "propose a hierarchical CNN+RNN neural network, LuNet. In LuNet, the\n",
            "convolutional neural network (CNN) and the recurrent neural network (RNN) learn\n",
            "input traffic data in sync with a gradually increasing granularity such that\n",
            "both spatial and temporal features of the data can be effectively extracted.\n",
            "Our experiments on two network traffic datasets show that compared to the\n",
            "state-of-the-art network intrusion detection techniques, LuNet not only offers\n",
            "a high level of detection capability but also has a much low rate of false\n",
            "positive-alarm. \n",
            "URL: http://arxiv.org/pdf/1909.10031v2 \n",
            "\n",
            "\n",
            "260\n",
            "cs\n",
            "Title: Self-Evolving Integrated Vertical Heterogeneous Networks \n",
            "Authors: Amin Farajzadeh, Mohammad G. Khoshkholgh, Halim Yanikomeroglu, Ozgur Ercetin \n",
            "Date: 2021-06-26 05:57:06+00:00 \n",
            "Id: 2106.13950 \n",
            "Summary: 6G and beyond networks tend towards fully intelligent and adaptive design in\n",
            "order to provide better operational agility in maintaining universal wireless\n",
            "access and supporting a wide range of services and use cases while dealing with\n",
            "network complexity efficiently. Such enhanced network agility will require\n",
            "developing a self-evolving capability in designing both the network\n",
            "architecture and resource management to intelligently utilize resources, reduce\n",
            "operational costs, and achieve the coveted quality of service (QoS). To enable\n",
            "this capability, the necessity of considering an integrated vertical\n",
            "heterogeneous network (VHetNet) architecture appears to be inevitable due to\n",
            "its high inherent agility. Moreover, employing an intelligent framework is\n",
            "another crucial requirement for self-evolving networks to deal with real-time\n",
            "network optimization problems. Hence, in this work, to provide a better insight\n",
            "on network architecture design in support of self-evolving networks, we\n",
            "highlight the merits of integrated VHetNet architecture while proposing an\n",
            "intelligent framework for self-evolving integrated vertical heterogeneous\n",
            "networks (SEI-VHetNets). The impact of the challenges associated with\n",
            "SEI-VHetNet architecture, on network management is also studied considering a\n",
            "generalized network model. Furthermore, the current literature on network\n",
            "management of integrated VHetNets along with the recent advancements in\n",
            "artificial intelligence (AI)/machine learning (ML) solutions are discussed.\n",
            "Accordingly, the core challenges of integrating AI/ML in SEI-VHetNets are\n",
            "identified. Finally, the potential future research directions for advancing the\n",
            "autonomous and self-evolving capabilities of SEI-VHetNets are discussed. \n",
            "URL: http://arxiv.org/pdf/2106.13950v2 \n",
            "\n",
            "\n",
            "261\n",
            "cs\n",
            "Title: \"Weak AI\" is Likely to Never Become \"Strong AI\", So What is its Greatest Value for us? \n",
            "Authors: Bin Liu \n",
            "Date: 2021-03-29 02:57:48+00:00 \n",
            "Id: 2103.15294 \n",
            "Summary: AI has surpassed humans across a variety of tasks such as image\n",
            "classification, playing games (e.g., go, \"Starcraft\" and poker), and protein\n",
            "structure prediction. However, at the same time, AI is also bearing serious\n",
            "controversies. Many researchers argue that little substantial progress has been\n",
            "made for AI in recent decades. In this paper, the author (1) explains why\n",
            "controversies about AI exist; (2) discriminates two paradigms of AI research,\n",
            "termed \"weak AI\" and \"strong AI\" (a.k.a. artificial general intelligence); (3)\n",
            "clarifies how to judge which paradigm a research work should be classified\n",
            "into; (4) discusses what is the greatest value of \"weak AI\" if it has no chance\n",
            "to develop into \"strong AI\". \n",
            "URL: http://arxiv.org/pdf/2103.15294v1 \n",
            "\n",
            "\n",
            "262\n",
            "cs\n",
            "Title: A Model-Driven Approach to Machine Learning and Software Modeling for the IoT \n",
            "Authors: Armin Moin, Moharram Challenger, Atta Badii, Stephan Günnemann \n",
            "Date: 2021-07-06 15:50:50+00:00 \n",
            "Id: 2107.02689 \n",
            "Summary: Models are used in both Software Engineering (SE) and Artificial Intelligence\n",
            "(AI). SE models may specify the architecture at different levels of abstraction\n",
            "and for addressing different concerns at various stages of the software\n",
            "development life-cycle, from early conceptualization and design, to\n",
            "verification, implementation, testing and evolution. However, AI models may\n",
            "provide smart capabilities, such as prediction and decision-making support. For\n",
            "instance, in Machine Learning (ML), which is currently the most popular\n",
            "sub-discipline of AI, mathematical models may learn useful patterns in the\n",
            "observed data and can become capable of making predictions. The goal of this\n",
            "work is to create synergy by bringing models in the said communities together\n",
            "and proposing a holistic approach to model-driven software development for\n",
            "intelligent systems that require ML. We illustrate how software models can\n",
            "become capable of creating and dealing with ML models in a seamless manner. The\n",
            "main focus is on the domain of the Internet of Things (IoT), where both ML and\n",
            "model-driven SE play a key role. In the context of the need to take a\n",
            "Cyber-Physical System-of-Systems perspective of the targeted architecture, an\n",
            "integrated design environment for both SE and ML sub-systems would best support\n",
            "the optimization and overall efficiency of the implementation of the resulting\n",
            "system. In particular, we implement the proposed approach, called ML-Quadrat,\n",
            "based on ThingML, and validate it using a case study from the IoT domain, as\n",
            "well as through an empirical user evaluation. It transpires that the proposed\n",
            "approach is not only feasible, but may also contribute to the performance leap\n",
            "of software development for smart Cyber-Physical Systems (CPS) which are\n",
            "connected to the IoT, as well as an enhanced user experience of the\n",
            "practitioners who use the proposed modeling solution. \n",
            "URL: http://arxiv.org/pdf/2107.02689v3 \n",
            "\n",
            "\n",
            "263\n",
            "cs\n",
            "Title: The Off-Switch Game \n",
            "Authors: Dylan Hadfield-Menell, Anca Dragan, Pieter Abbeel, Stuart Russell \n",
            "Date: 2016-11-24 15:23:48+00:00 \n",
            "Id: 1611.08219 \n",
            "Summary: It is clear that one of the primary tools we can use to mitigate the\n",
            "potential risk from a misbehaving AI system is the ability to turn the system\n",
            "off. As the capabilities of AI systems improve, it is important to ensure that\n",
            "such systems do not adopt subgoals that prevent a human from switching them\n",
            "off. This is a challenge because many formulations of rational agents create\n",
            "strong incentives for self-preservation. This is not caused by a built-in\n",
            "instinct, but because a rational agent will maximize expected utility and\n",
            "cannot achieve whatever objective it has been given if it is dead. Our goal is\n",
            "to study the incentives an agent has to allow itself to be switched off. We\n",
            "analyze a simple game between a human H and a robot R, where H can press R's\n",
            "off switch but R can disable the off switch. A traditional agent takes its\n",
            "reward function for granted: we show that such agents have an incentive to\n",
            "disable the off switch, except in the special case where H is perfectly\n",
            "rational. Our key insight is that for R to want to preserve its off switch, it\n",
            "needs to be uncertain about the utility associated with the outcome, and to\n",
            "treat H's actions as important observations about that utility. (R also has no\n",
            "incentive to switch itself off in this setting.) We conclude that giving\n",
            "machines an appropriate level of uncertainty about their objectives leads to\n",
            "safer designs, and we argue that this setting is a useful generalization of the\n",
            "classical AI paradigm of rational agents. \n",
            "URL: http://arxiv.org/pdf/1611.08219v3 \n",
            "\n",
            "\n",
            "264\n",
            "cs\n",
            "Title: Combined Task and Motion Planning as Classical AI Planning \n",
            "Authors: Jonathan Ferrer-Mestres, Guillem Francès, Hector Geffner \n",
            "Date: 2017-06-21 14:24:54+00:00 \n",
            "Id: 1706.06927 \n",
            "Summary: Planning in robotics is often split into task and motion planning. The\n",
            "high-level, symbolic task planner decides what needs to be done, while the\n",
            "motion planner checks feasibility and fills up geometric detail. It is known\n",
            "however that such a decomposition is not effective in general as the symbolic\n",
            "and geometrical components are not independent. In this work, we show that it\n",
            "is possible to compile task and motion planning problems into classical AI\n",
            "planning problems; i.e., planning problems over finite and discrete state\n",
            "spaces with a known initial state, deterministic actions, and goal states to be\n",
            "reached. The compilation is sound, meaning that classical plans are valid robot\n",
            "plans, and probabilistically complete, meaning that valid robot plans are\n",
            "classical plans when a sufficient number of configurations is sampled. In this\n",
            "approach, motion planners and collision checkers are used for the compilation,\n",
            "but not at planning time. The key elements that make the approach effective are\n",
            "1) expressive classical AI planning languages for representing the compiled\n",
            "problems in compact form, that unlike PDDL make use of functions and state\n",
            "constraints, and 2) general width-based search algorithms capable of finding\n",
            "plans over huge combinatorial spaces using weak heuristics only. Empirical\n",
            "results are presented for a PR2 robot manipulating tens of objects, for which\n",
            "long plans are required. \n",
            "URL: http://arxiv.org/pdf/1706.06927v1 \n",
            "\n",
            "\n",
            "265\n",
            "cs\n",
            "Title: Intelligent Traffic Light Control Using Distributed Multi-agent Q Learning \n",
            "Authors: Ying Liu, Lei Liu, Wei-Peng Chen \n",
            "Date: 2017-11-29 16:23:38+00:00 \n",
            "Id: 1711.10941 \n",
            "Summary: The combination of Artificial Intelligence (AI) and Internet-of-Things (IoT),\n",
            "which is denoted as AI-powered Internet-of-Things (AIoT), is capable of\n",
            "processing huge amount of data generated from a large number of devices and\n",
            "handling complex problems in social infrastructures. As AI and IoT technologies\n",
            "are becoming mature, in this paper, we propose to apply AIoT technologies for\n",
            "traffic light control, which is an essential component for intelligent\n",
            "transportation system, to improve the efficiency of smart city's road system.\n",
            "Specifically, various sensors such as surveillance cameras provide real-time\n",
            "information for intelligent traffic light control system to observe the states\n",
            "of both motorized traffic and non-motorized traffic. In this paper, we propose\n",
            "an intelligent traffic light control solution by using distributed multi-agent\n",
            "Q learning, considering the traffic information at the neighboring\n",
            "intersections as well as local motorized and non-motorized traffic, to improve\n",
            "the overall performance of the entire control system. By using the proposed\n",
            "multi-agent Q learning algorithm, our solution is targeting to optimize both\n",
            "the motorized and non-motorized traffic. In addition, we considered many\n",
            "constraints/rules for traffic light control in the real world, and integrate\n",
            "these constraints in the learning algorithm, which can facilitate the proposed\n",
            "solution to be deployed in real operational scenarios. We conducted numerical\n",
            "simulations for a real-world map with real-world traffic data. The simulation\n",
            "results show that our proposed solution outperforms existing solutions in terms\n",
            "of vehicle and pedestrian queue lengths, waiting time at intersections, and\n",
            "many other key performance metrics. \n",
            "URL: http://arxiv.org/pdf/1711.10941v1 \n",
            "\n",
            "\n",
            "267\n",
            "cs\n",
            "Title: Synthetic-Neuroscore: Using A Neuro-AI Interface for Evaluating Generative Adversarial Networks \n",
            "Authors: Zhengwei Wang, Qi She, Alan F. Smeaton, Tomas E. Ward, Graham Healy \n",
            "Date: 2019-05-10 16:25:07+00:00 \n",
            "Id: 1905.04243 \n",
            "Summary: Generative adversarial networks (GANs) are increasingly attracting attention\n",
            "in the computer vision, natural language processing, speech synthesis and\n",
            "similar domains. Arguably the most striking results have been in the area of\n",
            "image synthesis. However, evaluating the performance of GANs is still an open\n",
            "and challenging problem. Existing evaluation metrics primarily measure the\n",
            "dissimilarity between real and generated images using automated statistical\n",
            "methods. They often require large sample sizes for evaluation and do not\n",
            "directly reflect human perception of image quality. In this work, we describe\n",
            "an evaluation metric we call Neuroscore, for evaluating the performance of\n",
            "GANs, that more directly reflects psychoperceptual image quality through the\n",
            "utilization of brain signals. Our results show that Neuroscore has superior\n",
            "performance to the current evaluation metrics in that: (1) It is more\n",
            "consistent with human judgment; (2) The evaluation process needs much smaller\n",
            "numbers of samples; and (3) It is able to rank the quality of images on a per\n",
            "GAN basis. A convolutional neural network (CNN) based neuro-AI interface is\n",
            "proposed to predict Neuroscore from GAN-generated images directly without the\n",
            "need for neural responses. Importantly, we show that including neural responses\n",
            "during the training phase of the network can significantly improve the\n",
            "prediction capability of the proposed model. Materials related to this work are\n",
            "provided at https://github.com/villawang/Neuro-AI-Interface. \n",
            "URL: http://arxiv.org/pdf/1905.04243v2 \n",
            "\n",
            "\n",
            "268\n",
            "cs\n",
            "Title: Learning of Art Style Using AI and Its Evaluation Based on Psychological Experiments \n",
            "Authors: Mai Cong Hung, Ryohei Nakatsu, Naoko Tosa, Takashi Kusumi, Koji Koyamada \n",
            "Date: 2020-05-04 07:19:37+00:00 \n",
            "Id: 2005.02220 \n",
            "Summary: GANs (Generative adversarial networks) is a new AI technology that can\n",
            "perform deep learning with less training data and has the capability of\n",
            "achieving transformation between two image sets. Using GAN we have carried out\n",
            "a comparison between several art sets with different art style. We have\n",
            "prepared several image sets; a flower photo set (A), an art image set (B1) of\n",
            "Impressionism drawings, an art image set of abstract paintings (B2), an art\n",
            "image set of Chinese figurative paintings, (B3), and an art image set of\n",
            "abstract images (B4) created by Naoko Tosa, one of the authors. Transformation\n",
            "between set A to each of B was carried out using GAN and four image sets (B1,\n",
            "B2, B3, B4) was obtained. Using these four image sets we have carried out\n",
            "psychological experiment by asking subjects consisting of 23 students to fill\n",
            "in questionnaires. By analyzing the obtained questionnaires, we have found the\n",
            "followings. Abstract drawings and figurative drawings are clearly judged to be\n",
            "different. Figurative drawings in West and East were judged to be similar.\n",
            "Abstract images by Naoko Tosa were judged as similar to Western abstract\n",
            "images. These results show that AI could be used as an analysis tool to reveal\n",
            "differences between art genres. \n",
            "URL: http://arxiv.org/pdf/2005.02220v1 \n",
            "\n",
            "\n",
            "269\n",
            "cs\n",
            "Title: Comparing Knowledge-based Reinforcement Learning to Neural Networks in a Strategy Game \n",
            "Authors: Liudmyla Nechepurenko, Viktor Voss, Vyacheslav Gritsenko \n",
            "Date: 2019-01-15 01:23:38+00:00 \n",
            "Id: 1901.04626 \n",
            "Summary: The paper reports on an experiment, in which a Knowledge-Based Reinforcement\n",
            "Learning (KB-RL) method was compared to a Neural Network (NN) approach in\n",
            "solving a classical Artificial Intelligence (AI) task. In contrast to NNs,\n",
            "which require a substantial amount of data to learn a good policy, the KB-RL\n",
            "method seeks to encode human knowledge into the solution, considerably reducing\n",
            "the amount of data needed for a good policy. By means of Reinforcement Learning\n",
            "(RL), KB-RL learns to optimize the model and improves the output of the system.\n",
            "Furthermore, KB-RL offers the advantage of a clear explanation of the taken\n",
            "decisions as well as transparent reasoning behind the solution.\n",
            "  The goal of the reported experiment was to examine the performance of the\n",
            "KB-RL method in contrast to the Neural Network and to explore the capabilities\n",
            "of KB-RL to deliver a strong solution for the AI tasks. The results show that,\n",
            "within the designed settings, KB-RL outperformed the NN, and was able to learn\n",
            "a better policy from the available amount of data. These results support the\n",
            "opinion that Artificial Intelligence can benefit from the discovery and study\n",
            "of alternative approaches, potentially extending the frontiers of AI. \n",
            "URL: http://arxiv.org/pdf/1901.04626v2 \n",
            "\n",
            "\n",
            "270\n",
            "cs\n",
            "Title: Dota 2 with Large Scale Deep Reinforcement Learning \n",
            "Authors: OpenAI, :, Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Dębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael Petrov, Henrique P. d. O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, Susan Zhang \n",
            "Date: 2019-12-13 19:56:40+00:00 \n",
            "Id: 1912.06680 \n",
            "Summary: On April 13th, 2019, OpenAI Five became the first AI system to defeat the\n",
            "world champions at an esports game. The game of Dota 2 presents novel\n",
            "challenges for AI systems such as long time horizons, imperfect information,\n",
            "and complex, continuous state-action spaces, all challenges which will become\n",
            "increasingly central to more capable AI systems. OpenAI Five leveraged existing\n",
            "reinforcement learning techniques, scaled to learn from batches of\n",
            "approximately 2 million frames every 2 seconds. We developed a distributed\n",
            "training system and tools for continual training which allowed us to train\n",
            "OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG),\n",
            "OpenAI Five demonstrates that self-play reinforcement learning can achieve\n",
            "superhuman performance on a difficult task. \n",
            "URL: http://arxiv.org/pdf/1912.06680v1 \n",
            "\n",
            "\n",
            "271\n",
            "cs\n",
            "Title: LIMEADE: From AI Explanations to Advice Taking \n",
            "Authors: Benjamin Charles Germain Lee, Doug Downey, Kyle Lo, Daniel S. Weld \n",
            "Date: 2020-03-09 18:00:00+00:00 \n",
            "Id: 2003.04315 \n",
            "Summary: Research in human-centered AI has shown the benefits of systems that can\n",
            "explain their predictions. Methods that allow an AI to take advice from humans\n",
            "in response to explanations are similarly useful. While both capabilities are\n",
            "well-developed for transparent learning models (e.g., linear models and\n",
            "GA$^2$Ms), and recent techniques (e.g., LIME and SHAP) can generate\n",
            "explanations for opaque models, little attention has been given to advice\n",
            "methods for opaque models. This paper introduces LIMEADE, the first general\n",
            "framework that translates both positive and negative advice (expressed using\n",
            "high-level vocabulary such as that employed by post-hoc explanations) into an\n",
            "update to an arbitrary, underlying opaque model. We demonstrate the generality\n",
            "of our approach with case studies on seventy real-world models across two broad\n",
            "domains: image classification and text recommendation. We show our method\n",
            "improves accuracy compared to a rigorous baseline on the image classification\n",
            "domains. For the text modality, we apply our framework to a neural recommender\n",
            "system for scientific papers on a public website; our user study shows that our\n",
            "framework leads to significantly higher perceived user control, trust, and\n",
            "satisfaction. \n",
            "URL: http://arxiv.org/pdf/2003.04315v3 \n",
            "\n",
            "\n",
            "272\n",
            "cs\n",
            "Title: PathVQA: 30000+ Questions for Medical Visual Question Answering \n",
            "Authors: Xuehai He, Yichen Zhang, Luntian Mou, Eric Xing, Pengtao Xie \n",
            "Date: 2020-03-07 17:55:41+00:00 \n",
            "Id: 2003.10286 \n",
            "Summary: Is it possible to develop an \"AI Pathologist\" to pass the board-certified\n",
            "examination of the American Board of Pathology? To achieve this goal, the first\n",
            "step is to create a visual question answering (VQA) dataset where the AI agent\n",
            "is presented with a pathology image together with a question and is asked to\n",
            "give the correct answer. Our work makes the first attempt to build such a\n",
            "dataset. Different from creating general-domain VQA datasets where the images\n",
            "are widely accessible and there are many crowdsourcing workers available and\n",
            "capable of generating question-answer pairs, developing a medical VQA dataset\n",
            "is much more challenging. First, due to privacy concerns, pathology images are\n",
            "usually not publicly available. Second, only well-trained pathologists can\n",
            "understand pathology images, but they barely have time to help create datasets\n",
            "for AI research. To address these challenges, we resort to pathology textbooks\n",
            "and online digital libraries. We develop a semi-automated pipeline to extract\n",
            "pathology images and captions from textbooks and generate question-answer pairs\n",
            "from captions using natural language processing. We collect 32,799 open-ended\n",
            "questions from 4,998 pathology images where each question is manually checked\n",
            "to ensure correctness. To our best knowledge, this is the first dataset for\n",
            "pathology VQA. Our dataset will be released publicly to promote research in\n",
            "medical VQA. \n",
            "URL: http://arxiv.org/pdf/2003.10286v1 \n",
            "\n",
            "\n",
            "273\n",
            "cs\n",
            "Title: When Autonomous Systems Meet Accuracy and Transferability through AI: A Survey \n",
            "Authors: Chongzhen Zhang, Jianrui Wang, Gary G. Yen, Chaoqiang Zhao, Qiyu Sun, Yang Tang, Feng Qian, Jürgen Kurths \n",
            "Date: 2020-03-29 04:50:22+00:00 \n",
            "Id: 2003.12948 \n",
            "Summary: With widespread applications of artificial intelligence (AI), the\n",
            "capabilities of the perception, understanding, decision-making and control for\n",
            "autonomous systems have improved significantly in the past years. When\n",
            "autonomous systems consider the performance of accuracy and transferability,\n",
            "several AI methods, like adversarial learning, reinforcement learning (RL) and\n",
            "meta-learning, show their powerful performance. Here, we review the\n",
            "learning-based approaches in autonomous systems from the perspectives of\n",
            "accuracy and transferability. Accuracy means that a well-trained model shows\n",
            "good results during the testing phase, in which the testing set shares a same\n",
            "task or a data distribution with the training set. Transferability means that\n",
            "when a well-trained model is transferred to other testing domains, the accuracy\n",
            "is still good. Firstly, we introduce some basic concepts of transfer learning\n",
            "and then present some preliminaries of adversarial learning, RL and\n",
            "meta-learning. Secondly, we focus on reviewing the accuracy or transferability\n",
            "or both of them to show the advantages of adversarial learning, like generative\n",
            "adversarial networks (GANs), in typical computer vision tasks in autonomous\n",
            "systems, including image style transfer, image superresolution, image\n",
            "deblurring/dehazing/rain removal, semantic segmentation, depth estimation,\n",
            "pedestrian detection and person re-identification (re-ID). Then, we further\n",
            "review the performance of RL and meta-learning from the aspects of accuracy or\n",
            "transferability or both of them in autonomous systems, involving pedestrian\n",
            "tracking, robot navigation and robotic manipulation. Finally, we discuss\n",
            "several challenges and future topics for using adversarial learning, RL and\n",
            "meta-learning in autonomous systems. \n",
            "URL: http://arxiv.org/pdf/2003.12948v3 \n",
            "\n",
            "\n",
            "274\n",
            "cs\n",
            "Title: Artificial Intelligence (AI)-Centric Management of Resources in Modern Distributed Computing Systems \n",
            "Authors: Shashikant Ilager, Rajeev Muralidhar, Rajkumar Buyya \n",
            "Date: 2020-06-09 06:54:07+00:00 \n",
            "Id: 2006.05075 \n",
            "Summary: Contemporary Distributed Computing Systems (DCS) such as Cloud Data Centres\n",
            "are large scale, complex, heterogeneous, and distributed across multiple\n",
            "networks and geographical boundaries. On the other hand, the Internet of Things\n",
            "(IoT)-driven applications are producing a huge amount of data that requires\n",
            "real-time processing and fast response. Managing these resources efficiently to\n",
            "provide reliable services to end-users or applications is a challenging task.\n",
            "The existing Resource Management Systems (RMS) rely on either static or\n",
            "heuristic solutions inadequate for such composite and dynamic systems. The\n",
            "advent of Artificial Intelligence (AI) due to data availability and processing\n",
            "capabilities manifested into possibilities of exploring data-driven solutions\n",
            "in RMS tasks that are adaptive, accurate, and efficient. In this regard, this\n",
            "paper aims to draw the motivations and necessities for data-driven solutions in\n",
            "resource management. It identifies the challenges associated with it and\n",
            "outlines the potential future research directions detailing where and how to\n",
            "apply the data-driven techniques in the different RMS tasks. Finally, it\n",
            "provides a conceptual data-driven RMS model for DCS and presents the two\n",
            "real-time use cases (GPU frequency scaling and data centre resource management\n",
            "from Google Cloud and Microsoft Azure) demonstrating AI-centric approaches'\n",
            "feasibility. \n",
            "URL: http://arxiv.org/pdf/2006.05075v2 \n",
            "\n",
            "\n",
            "275\n",
            "cs\n",
            "Title: Mediating Artificial Intelligence Developments through Negative and Positive Incentives \n",
            "Authors: The Anh Han, Luis Moniz Pereira, Tom Lenaerts, Francisco C. Santos \n",
            "Date: 2020-10-01 13:43:32+00:00 \n",
            "Id: 2010.00403 \n",
            "Summary: The field of Artificial Intelligence (AI) is going through a period of great\n",
            "expectations, introducing a certain level of anxiety in research, business and\n",
            "also policy. This anxiety is further energised by an AI race narrative that\n",
            "makes people believe they might be missing out. Whether real or not, a belief\n",
            "in this narrative may be detrimental as some stake-holders will feel obliged to\n",
            "cut corners on safety precautions, or ignore societal consequences just to\n",
            "\"win\". Starting from a baseline model that describes a broad class of\n",
            "technology races where winners draw a significant benefit compared to others\n",
            "(such as AI advances, patent race, pharmaceutical technologies), we investigate\n",
            "here how positive (rewards) and negative (punishments) incentives may\n",
            "beneficially influence the outcomes. We uncover conditions in which punishment\n",
            "is either capable of reducing the development speed of unsafe participants or\n",
            "has the capacity to reduce innovation through over-regulation. Alternatively,\n",
            "we show that, in several scenarios, rewarding those that follow safety measures\n",
            "may increase the development speed while ensuring safe choices. Moreover, in\n",
            "{the latter} regimes, rewards do not suffer from the issue of over-regulation\n",
            "as is the case for punishment. Overall, our findings provide valuable insights\n",
            "into the nature and kinds of regulatory actions most suitable to improve safety\n",
            "compliance in the contexts of both smooth and sudden technological shifts. \n",
            "URL: http://arxiv.org/pdf/2010.00403v1 \n",
            "\n",
            "\n",
            "276\n",
            "cs\n",
            "Title: Reinforcement Learning with Dual-Observation for General Video Game Playing \n",
            "Authors: Chengpeng Hu, Ziqi Wang, Tianye Shu, Hao Tong, Julian Togelius, Xin Yao, Jialin Liu \n",
            "Date: 2020-11-11 08:28:20+00:00 \n",
            "Id: 2011.05622 \n",
            "Summary: Reinforcement learning algorithms have performed well in playing challenging\n",
            "board and video games. More and more studies focus on improving the\n",
            "generalisation ability of reinforcement learning algorithms. The General Video\n",
            "Game AI Learning Competition aims to develop agents capable of learning to play\n",
            "different game levels that were unseen during training. This paper summarises\n",
            "the five years' General Video Game AI Learning Competition editions. At each\n",
            "edition, three new games were designed. The training and test levels were\n",
            "designed separately in the first three editions. Since 2020, three test levels\n",
            "of each game were generated by perturbing or combining two training levels.\n",
            "Then, we present a novel reinforcement learning technique with dual-observation\n",
            "for general video game playing, assuming that it is more likely to observe\n",
            "similar local information in different levels rather than global information.\n",
            "Instead of directly inputting a single, raw pixel-based screenshot of the\n",
            "current game screen, our proposed general technique takes the encoded,\n",
            "transformed global and local observations of the game screen as two\n",
            "simultaneous inputs, aiming at learning local information for playing new\n",
            "levels. Our proposed technique is implemented with three state-of-the-art\n",
            "reinforcement learning algorithms and tested on the game set of the 2020\n",
            "General Video Game AI Learning Competition. Ablation studies show the\n",
            "outstanding performance of using encoded, transformed global and local\n",
            "observations as input. \n",
            "URL: http://arxiv.org/pdf/2011.05622v4 \n",
            "\n",
            "\n",
            "277\n",
            "cs\n",
            "Title: Integrating Deep Learning in Domain Sciences at Exascale \n",
            "Authors: Rick Archibald, Edmond Chow, Eduardo D'Azevedo, Jack Dongarra, Markus Eisenbach, Rocco Febbo, Florent Lopez, Daniel Nichols, Stanimire Tomov, Kwai Wong, Junqi Yin \n",
            "Date: 2020-11-23 03:09:58+00:00 \n",
            "Id: 2011.11188 \n",
            "Summary: This paper presents some of the current challenges in designing deep learning\n",
            "artificial intelligence (AI) and integrating it with traditional\n",
            "high-performance computing (HPC) simulations. We evaluate existing packages for\n",
            "their ability to run deep learning models and applications on large-scale HPC\n",
            "systems efficiently, identify challenges, and propose new asynchronous\n",
            "parallelization and optimization techniques for current large-scale\n",
            "heterogeneous systems and upcoming exascale systems. These developments, along\n",
            "with existing HPC AI software capabilities, have been integrated into MagmaDNN,\n",
            "an open-source HPC deep learning framework. Many deep learning frameworks are\n",
            "targeted at data scientists and fall short in providing quality integration\n",
            "into existing HPC workflows. This paper discusses the necessities of an HPC\n",
            "deep learning framework and how those needs can be provided (e.g., as in\n",
            "MagmaDNN) through a deep integration with existing HPC libraries, such as MAGMA\n",
            "and its modular memory management, MPI, CuBLAS, CuDNN, MKL, and HIP.\n",
            "Advancements are also illustrated through the use of algorithmic enhancements\n",
            "in reduced- and mixed-precision, as well as asynchronous optimization methods.\n",
            "Finally, we present illustrations and potential solutions for enhancing\n",
            "traditional compute- and data-intensive applications at ORNL and UTK with AI.\n",
            "The approaches and future challenges are illustrated in materials science,\n",
            "imaging, and climate applications. \n",
            "URL: http://arxiv.org/pdf/2011.11188v1 \n",
            "\n",
            "\n",
            "278\n",
            "cs\n",
            "Title: Digital me ontology and ethics \n",
            "Authors: Ljupco Kocarev, Jasna Koteska \n",
            "Date: 2020-12-22 09:54:04+00:00 \n",
            "Id: 2012.14325 \n",
            "Summary: This paper addresses ontology and ethics of an AI agent called digital me. We\n",
            "define digital me as autonomous, decision-making, and learning agent,\n",
            "representing an individual and having practically immortal own life. It is\n",
            "assumed that digital me is equipped with the big-five personality model,\n",
            "ensuring that it provides a model of some aspects of a strong AI:\n",
            "consciousness, free will, and intentionality. As computer-based personality\n",
            "judgments are more accurate than those made by humans, digital me can judge the\n",
            "personality of the individual represented by the digital me, other individuals'\n",
            "personalities, and other digital me-s. We describe seven ontological qualities\n",
            "of digital me: a) double-layer status of Digital Being versus digital me, b)\n",
            "digital me versus real me, c) mind-digital me and body-digital me, d) digital\n",
            "me versus doppelganger (shadow digital me), e) non-human time concept, f)\n",
            "social quality, g) practical immortality. We argue that with the advancement of\n",
            "AI's sciences and technologies, there exist two digital me thresholds. The\n",
            "first threshold defines digital me having some (rudimentarily) form of\n",
            "consciousness, free will, and intentionality. The second threshold assumes that\n",
            "digital me is equipped with moral learning capabilities, implying that, in\n",
            "principle, digital me could develop their own ethics which significantly\n",
            "differs from human's understanding of ethics. Finally we discuss the\n",
            "implications of digital me metaethics, normative and applied ethics, the\n",
            "implementation of the Golden Rule in digital me-s, and we suggest two sets of\n",
            "normative principles for digital me: consequentialist and duty based digital me\n",
            "principles. \n",
            "URL: http://arxiv.org/pdf/2012.14325v1 \n",
            "\n",
            "\n",
            "280\n",
            "cs\n",
            "Title: A Case for 3D Integrated System Design for Neuromorphic Computing & AI Applications \n",
            "Authors: Eren Kurshan, Hai Li, Mingoo Seok, Yuan Xie \n",
            "Date: 2021-03-02 21:50:12+00:00 \n",
            "Id: 2103.04852 \n",
            "Summary: Over the last decade, artificial intelligence has found many applications\n",
            "areas in the society. As AI solutions have become more sophistication and the\n",
            "use cases grew, they highlighted the need to address performance and energy\n",
            "efficiency challenges faced during the implementation process. To address these\n",
            "challenges, there has been growing interest in neuromorphic chips. Neuromorphic\n",
            "computing relies on non von Neumann architectures as well as novel devices,\n",
            "circuits and manufacturing technologies to mimic the human brain. Among such\n",
            "technologies, 3D integration is an important enabler for AI hardware and the\n",
            "continuation of the scaling laws. In this paper, we overview the unique\n",
            "opportunities 3D integration provides in neuromorphic chip design, discuss the\n",
            "emerging opportunities in next generation neuromorphic architectures and review\n",
            "the obstacles. Neuromorphic architectures, which relied on the brain for\n",
            "inspiration and emulation purposes, face grand challenges due to the limited\n",
            "understanding of the functionality and the architecture of the human brain.\n",
            "Yet, high-levels of investments are dedicated to develop neuromorphic chips. We\n",
            "argue that 3D integration not only provides strategic advantages to the\n",
            "cost-effective and flexible design of neuromorphic chips, it may provide design\n",
            "flexibility in incorporating advanced capabilities to further benefits the\n",
            "designs in the future. \n",
            "URL: http://arxiv.org/pdf/2103.04852v1 \n",
            "\n",
            "\n",
            "281\n",
            "cs\n",
            "Title: Towards Solving Multimodal Comprehension \n",
            "Authors: Pritish Sahu, Karan Sikka, Ajay Divakaran \n",
            "Date: 2021-04-20 17:30:27+00:00 \n",
            "Id: 2104.10139 \n",
            "Summary: This paper targets the problem of procedural multimodal machine comprehension\n",
            "(M3C). This task requires an AI to comprehend given steps of multimodal\n",
            "instructions and then answer questions. Compared to vanilla machine\n",
            "comprehension tasks where an AI is required only to understand a textual input,\n",
            "procedural M3C is more challenging as the AI needs to comprehend both the\n",
            "temporal and causal factors along with multimodal inputs. Recently Yagcioglu et\n",
            "al. [35] introduced RecipeQA dataset to evaluate M3C. Our first contribution is\n",
            "the introduction of two new M3C datasets- WoodworkQA and DecorationQA with 16K\n",
            "and 10K instructional procedures, respectively. We then evaluate M3C using a\n",
            "textual cloze style question-answering task and highlight an inherent bias in\n",
            "the question answer generation method from [35] that enables a naive baseline\n",
            "to cheat by learning from only answer choices. This naive baseline performs\n",
            "similar to a popular method used in question answering- Impatient Reader [6]\n",
            "that uses attention over both the context and the query. We hypothesized that\n",
            "this naturally occurring bias present in the dataset affects even the best\n",
            "performing model. We verify our proposed hypothesis and propose an algorithm\n",
            "capable of modifying the given dataset to remove the bias elements. Finally, we\n",
            "report our performance on the debiased dataset with several strong baselines.\n",
            "We observe that the performance of all methods falls by a margin of 8% - 16%\n",
            "after correcting for the bias. We hope these datasets and the analysis will\n",
            "provide valuable benchmarks and encourage further research in this area. \n",
            "URL: http://arxiv.org/pdf/2104.10139v1 \n",
            "\n",
            "\n",
            "282\n",
            "cs\n",
            "Title: SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents \n",
            "Authors: Grgur Kovač, Rémy Portelas, Katja Hofmann, Pierre-Yves Oudeyer \n",
            "Date: 2021-07-02 10:39:18+00:00 \n",
            "Id: 2107.00956 \n",
            "Summary: Building embodied autonomous agents capable of participating in social\n",
            "interactions with humans is one of the main challenges in AI. Within the Deep\n",
            "Reinforcement Learning (DRL) field, this objective motivated multiple works on\n",
            "embodied language use. However, current approaches focus on language as a\n",
            "communication tool in very simplified and non-diverse social situations: the\n",
            "\"naturalness\" of language is reduced to the concept of high vocabulary size and\n",
            "variability. In this paper, we argue that aiming towards human-level AI\n",
            "requires a broader set of key social skills: 1) language use in complex and\n",
            "variable social contexts; 2) beyond language, complex embodied communication in\n",
            "multimodal settings within constantly evolving social worlds. We explain how\n",
            "concepts from cognitive sciences could help AI to draw a roadmap towards\n",
            "human-like intelligence, with a focus on its social dimensions. As a first\n",
            "step, we propose to expand current research to a broader set of core social\n",
            "skills. To do this, we present SocialAI, a benchmark to assess the acquisition\n",
            "of social skills of DRL agents using multiple grid-world environments featuring\n",
            "other (scripted) social agents. We then study the limits of a recent SOTA DRL\n",
            "approach when tested on SocialAI and discuss important next steps towards\n",
            "proficient social agents. Videos and code are available at\n",
            "https://sites.google.com/view/socialai. \n",
            "URL: http://arxiv.org/pdf/2107.00956v3 \n",
            "\n",
            "\n",
            "284\n",
            "cs\n",
            "Title: Eden: A Unified Environment Framework for Booming Reinforcement Learning Algorithms \n",
            "Authors: Ruizhi Chen, Xiaoyu Wu, Yansong Pan, Kaizhao Yuan, Ling Li, TianYun Ma, JiYuan Liang, Rui Zhang, Kai Wang, Chen Zhang, Shaohui Peng, Xishan Zhang, Zidong Du, Qi Guo, Yunji Chen \n",
            "Date: 2021-09-04 02:38:08+00:00 \n",
            "Id: 2109.01768 \n",
            "Summary: With AlphaGo defeats top human players, reinforcement learning(RL) algorithms\n",
            "have gradually become the code-base of building stronger artificial\n",
            "intelligence(AI). The RL algorithm design firstly needs to adapt to the\n",
            "specific environment, so the designed environment guides the rapid and profound\n",
            "development of RL algorithms. However, the existing environments, which can be\n",
            "divided into real world games and customized toy environments, have obvious\n",
            "shortcomings. For real world games, it is designed for human entertainment, and\n",
            "too much difficult for most of RL researchers. For customized toy environments,\n",
            "there is no widely accepted unified evaluation standard for all RL algorithms.\n",
            "Therefore, we introduce the first virtual user-friendly environment framework\n",
            "for RL. In this framework, the environment can be easily configured to realize\n",
            "all kinds of RL tasks in the mainstream research. Then all the mainstream\n",
            "state-of-the-art(SOTA) RL algorithms can be conveniently evaluated and\n",
            "compared. Therefore, our contributions mainly includes the following aspects:\n",
            "1.single configured environment for all classification of SOTA RL algorithms;\n",
            "2.combined environment of more than one classification RL algorithms; 3.the\n",
            "evaluation standard for all kinds of RL algorithms. With all these efforts, a\n",
            "possibility for breeding an AI with capability of general competency in a\n",
            "variety of tasks is provided, and maybe it will open up a new chapter for AI. \n",
            "URL: http://arxiv.org/pdf/2109.01768v1 \n",
            "\n",
            "\n",
            "285\n",
            "cs\n",
            "Title: The pitfalls of using open data to develop deep learning solutions for COVID-19 detection in chest X-rays \n",
            "Authors: Rachael Harkness, Geoff Hall, Alejandro F Frangi, Nishant Ravikumar, Kieran Zucker \n",
            "Date: 2021-09-14 10:59:11+00:00 \n",
            "Id: 2109.08020 \n",
            "Summary: Since the emergence of COVID-19, deep learning models have been developed to\n",
            "identify COVID-19 from chest X-rays. With little to no direct access to\n",
            "hospital data, the AI community relies heavily on public data comprising\n",
            "numerous data sources. Model performance results have been exceptional when\n",
            "training and testing on open-source data, surpassing the reported capabilities\n",
            "of AI in pneumonia-detection prior to the COVID-19 outbreak. In this study\n",
            "impactful models are trained on a widely used open-source data and tested on an\n",
            "external test set and a hospital dataset, for the task of classifying chest\n",
            "X-rays into one of three classes: COVID-19, non-COVID pneumonia and\n",
            "no-pneumonia. Classification performance of the models investigated is\n",
            "evaluated through ROC curves, confusion matrices and standard classification\n",
            "metrics. Explainability modules are implemented to explore the image features\n",
            "most important to classification. Data analysis and model evaluations show that\n",
            "the popular open-source dataset COVIDx is not representative of the real\n",
            "clinical problem and that results from testing on this are inflated. Dependence\n",
            "on open-source data can leave models vulnerable to bias and confounding\n",
            "variables, requiring careful analysis to develop clinically useful/viable AI\n",
            "tools for COVID-19 detection in chest X-rays. \n",
            "URL: http://arxiv.org/pdf/2109.08020v1 \n",
            "\n",
            "\n",
            "286\n",
            "cs\n",
            "Title: Self-Initiated Open World Learning for Autonomous AI Agents \n",
            "Authors: Bing Liu, Eric Robertson, Scott Grigsby, Sahisnu Mazumder \n",
            "Date: 2021-10-21 18:11:02+00:00 \n",
            "Id: 2110.11385 \n",
            "Summary: As more and more AI agents are used in practice, it is time to think about\n",
            "how to make these agents fully autonomous so that they can learn by themselves\n",
            "in a self-motivated and self-supervised manner rather than being retrained\n",
            "periodically on the initiation of human engineers using expanded training data.\n",
            "As the real-world is an open environment with unknowns or novelties, detecting\n",
            "novelties or unknowns, characterizing them, accommodating or adapting to them,\n",
            "gathering ground-truth training data, and incrementally learning the\n",
            "unknowns/novelties are critical to making the agent more and more knowledgeable\n",
            "and powerful over time. The key challenge is how to automate the process so\n",
            "that it is carried out on the agent's own initiative and through its own\n",
            "interactions with humans and the environment. Since an AI agent usually has a\n",
            "performance task, characterizing each novelty becomes critical and necessary so\n",
            "that the agent can formulate an appropriate response to adapt its behavior to\n",
            "accommodate the novelty and to learn from it to improve the agent's adaptation\n",
            "capability and task performance. The process goes continually without\n",
            "termination. This paper proposes a theoretic framework for this learning\n",
            "paradigm to promote the research of building Self-initiated Open world Learning\n",
            "(SOL) agents. An example SOL agent is also described. \n",
            "URL: http://arxiv.org/pdf/2110.11385v2 \n",
            "\n",
            "\n",
            "287\n",
            "cs\n",
            "Title: From Convolutions towards Spikes: The Environmental Metric that the Community currently Misses \n",
            "Authors: Aviral Chharia, Shivu Chauhan, Rahul Upadhyay, Vinay Kumar \n",
            "Date: 2021-11-16 11:04:42+00:00 \n",
            "Id: 2111.08361 \n",
            "Summary: Today, the AI community is obsessed with 'state-of-the-art' scores (80%\n",
            "papers in NeurIPS) as the major performance metrics, due to which an important\n",
            "parameter, i.e., the environmental metric, remains unreported. Computational\n",
            "capabilities were a limiting factor a decade ago; however, in foreseeable\n",
            "future circumstances, the challenge will be to develop environment-friendly and\n",
            "power-efficient algorithms. The human brain, which has been optimizing itself\n",
            "for almost a million years, consumes the same amount of power as a typical\n",
            "laptop. Therefore, developing nature-inspired algorithms is one solution to it.\n",
            "In this study, we show that currently used ANNs are not what we find in nature,\n",
            "and why, although having lower performance, spiking neural networks, which\n",
            "mirror the mammalian visual cortex, have attracted much interest. We further\n",
            "highlight the hardware gaps restricting the researchers from using spike-based\n",
            "computation for developing neuromorphic energy-efficient microchips on a large\n",
            "scale. Using neuromorphic processors instead of traditional GPUs might be more\n",
            "environment friendly and efficient. These processors will turn SNNs into an\n",
            "ideal solution for the problem. This paper presents in-depth attention\n",
            "highlighting the current gaps, the lack of comparative research, while\n",
            "proposing new research directions at the intersection of two fields --\n",
            "neuroscience and deep learning. Further, we define a new evaluation metric\n",
            "'NATURE' for reporting the carbon footprint of AI models. \n",
            "URL: http://arxiv.org/pdf/2111.08361v1 \n",
            "\n",
            "\n",
            "288\n",
            "cs\n",
            "Title: Generating Synthetic Mixed-type Longitudinal Electronic Health Records for Artificial Intelligent Applications \n",
            "Authors: Jin Li, Benjamin J. Cairns, Jingsong Li, Tingting Zhu \n",
            "Date: 2021-12-22 17:17:34+00:00 \n",
            "Id: 2112.12047 \n",
            "Summary: The recent availability of electronic health records (EHRs) have provided\n",
            "enormous opportunities to develop artificial intelligence (AI) algorithms.\n",
            "However, patient privacy has become a major concern that limits data sharing\n",
            "across hospital settings and subsequently hinders the advances in AI.\n",
            "\\textit{Synthetic data}, which benefits from the development and proliferation\n",
            "of generative models, has served as a promising substitute for real patient EHR\n",
            "data. However, the current generative models are limited as they only generate\n",
            "\\textit{single type} of clinical data, i.e., either continuous-valued or\n",
            "discrete-valued. In this paper, we propose a generative adversarial network\n",
            "(GAN) entitled EHR-M-GAN which synthesizes \\textit{mixed-type} timeseries EHR\n",
            "data. EHR-M-GAN is capable of capturing the multidimensional, heterogeneous,\n",
            "and correlated temporal dynamics in patient trajectories. We have validated\n",
            "EHR-M-GAN on three publicly-available intensive care unit databases with\n",
            "records from a total of 141,488 unique patients, and performed privacy risk\n",
            "evaluation of the proposed model. EHR-M-GAN has demonstrated its superiority in\n",
            "performance over state-of-the-art benchmarks for synthesizing clinical\n",
            "timeseries with high fidelity. Notably, prediction models for outcomes of\n",
            "intensive care performed significantly better when training data was augmented\n",
            "with the addition of EHR-M-GAN-generated timeseries. EHR-M-GAN may have use in\n",
            "developing AI algorithms in resource-limited settings, lowering the barrier for\n",
            "data acquisition while preserving patient privacy. \n",
            "URL: http://arxiv.org/pdf/2112.12047v1 \n",
            "\n",
            "\n",
            "290\n",
            "cs\n",
            "Title: Enabling Reproducibility and Meta-learning Through a Lifelong Database of Experiments (LDE) \n",
            "Authors: Jason Tsay, Andrea Bartezzaghi, Aleke Nolte, Cristiano Malossi \n",
            "Date: 2022-02-22 15:35:16+00:00 \n",
            "Id: 2202.10979 \n",
            "Summary: Artificial Intelligence (AI) development is inherently iterative and\n",
            "experimental. Over the course of normal development, especially with the advent\n",
            "of automated AI, hundreds or thousands of experiments are generated and are\n",
            "often lost or never examined again. There is a lost opportunity to document\n",
            "these experiments and learn from them at scale, but the complexity of tracking\n",
            "and reproducing these experiments is often prohibitive to data scientists. We\n",
            "present the Lifelong Database of Experiments (LDE) that automatically extracts\n",
            "and stores linked metadata from experiment artifacts and provides features to\n",
            "reproduce these artifacts and perform meta-learning across them. We store\n",
            "context from multiple stages of the AI development lifecycle including\n",
            "datasets, pipelines, how each is configured, and training runs with information\n",
            "about their runtime environment. The standardized nature of the stored metadata\n",
            "allows for querying and aggregation, especially in terms of ranking artifacts\n",
            "by performance metrics. We exhibit the capabilities of the LDE by reproducing\n",
            "an existing meta-learning study and storing the reproduced metadata in our\n",
            "system. Then, we perform two experiments on this metadata: 1) examining the\n",
            "reproducibility and variability of the performance metrics and 2) implementing\n",
            "a number of meta-learning algorithms on top of the data and examining how\n",
            "variability in experimental results impacts recommendation performance. The\n",
            "experimental results suggest significant variation in performance, especially\n",
            "depending on dataset configurations; this variation carries over when\n",
            "meta-learning is built on top of the results, with performance improving when\n",
            "using aggregated results. This suggests that a system that automatically\n",
            "collects and aggregates results such as the LDE not only assists in\n",
            "implementing meta-learning but may also improve its performance. \n",
            "URL: http://arxiv.org/pdf/2202.10979v2 \n",
            "\n",
            "\n",
            "291\n",
            "cs\n",
            "Title: Query Processing on Tensor Computation Runtimes \n",
            "Authors: Dong He, Supun Nakandala, Dalitso Banda, Rathijit Sen, Karla Saur, Kwanghyun Park, Carlo Curino, Jesús Camacho-Rodríguez, Konstantinos Karanasos, Matteo Interlandi \n",
            "Date: 2022-03-03 17:41:39+00:00 \n",
            "Id: 2203.01877 \n",
            "Summary: The huge demand for computation in artificial intelligence (AI) is driving\n",
            "unparalleled investments in new hardware and software systems for AI. This\n",
            "leads to an explosion in the number of specialized hardware devices, which are\n",
            "now part of the offerings of major cloud providers. Meanwhile, by hiding the\n",
            "low-level complexity through a tensor-based interface, tensor computation\n",
            "runtimes (TCRs) such as PyTorch allow data scientists to efficiently exploit\n",
            "the exciting capabilities offered by the new hardware. In this paper, we\n",
            "explore how databases can ride the wave of innovation happening in the AI\n",
            "space. Specifically, we present Tensor Query Processor (TQP): a SQL query\n",
            "processor leveraging the tensor interface of TCRs. TQP is able to efficiently\n",
            "run the full TPC-H benchmark by implementing novel algorithms for executing\n",
            "relational operators on the specialized tensor routines provided by TCRs.\n",
            "Meanwhile, TQP can target various hardware while only requiring a fraction of\n",
            "the usual development effort. Experiments show that TQP can improve query\n",
            "execution time by up to 20x over CPU-only systems, and up to 5x over\n",
            "specialized GPU solutions. Finally, TQP can accelerate queries mixing ML\n",
            "predictions and SQL end-to-end, and deliver up to 5x speedup over CPU\n",
            "baselines. \n",
            "URL: http://arxiv.org/pdf/2203.01877v1 \n",
            "\n",
            "\n",
            "292\n",
            "cs\n",
            "Title: Toward a Research Agenda in Adversarial Reasoning: Computational Approaches to Anticipating the Opponent's Intent and Actions \n",
            "Authors: Alexander Kott, Michael Ownby \n",
            "Date: 2015-12-25 01:27:55+00:00 \n",
            "Id: 1512.07943 \n",
            "Summary: This paper defines adversarial reasoning as computational approaches to\n",
            "inferring and anticipating an enemy's perceptions, intents and actions. It\n",
            "argues that adversarial reasoning transcends the boundaries of game theory and\n",
            "must also leverage such disciplines as cognitive modeling, control theory, AI\n",
            "planning and others. To illustrate the challenges of applying adversarial\n",
            "reasoning to real-world problems, the paper explores the lessons learned in the\n",
            "CADET - a battle planning system that focuses on brigade-level ground\n",
            "operations and involves adversarial reasoning. From this example of current\n",
            "capabilities, the paper proceeds to describe RAID - a DARPA program that aims\n",
            "to build capabilities in adversarial reasoning, and how such capabilities would\n",
            "address practical requirements in Defense and other application areas. \n",
            "URL: http://arxiv.org/pdf/1512.07943v1 \n",
            "\n",
            "\n",
            "294\n",
            "cs\n",
            "Title: Towards Enterprise-Ready AI Deployments Minimizing the Risk of Consuming AI Models in Business Applications \n",
            "Authors: Aleksander Slominski, Vinod Muthusamy, Vatche Ishakian \n",
            "Date: 2019-06-25 09:46:02+00:00 \n",
            "Id: 1906.10418 \n",
            "Summary: The stochastic nature of artificial intelligence (AI) models introduces risk\n",
            "to business applications that use AI models without careful consideration. This\n",
            "paper offers an approach to use AI techniques to gain insights on the usage of\n",
            "the AI models and control how they are deployed to a production application.\n",
            "  Keywords: artificial intelligence (AI), machine learning, microservices,\n",
            "business process \n",
            "URL: http://arxiv.org/pdf/1906.10418v1 \n",
            "\n",
            "\n",
            "295\n",
            "cs\n",
            "Title: Understanding Mental Models of AI through Player-AI Interaction \n",
            "Authors: Jennifer Villareale, Jichen Zhu \n",
            "Date: 2021-03-30 08:49:45+00:00 \n",
            "Id: 2103.16168 \n",
            "Summary: Designing human-centered AI-driven applications require deep understandings\n",
            "of how people develop mental models of AI. Currently, we have little knowledge\n",
            "of this process and limited tools to study it. This paper presents the position\n",
            "that AI-based games, particularly the player-AI interaction component, offer an\n",
            "ideal domain to study the process in which mental models evolve. We present a\n",
            "case study to illustrate the benefits of our approach for explainable AI. \n",
            "URL: http://arxiv.org/pdf/2103.16168v1 \n",
            "\n",
            "\n",
            "296\n",
            "cs\n",
            "Title: Artificial Intelligence Techniques for Steam Generator Modelling \n",
            "Authors: Sarah Wright, Tshilidzi Marwala \n",
            "Date: 2008-11-11 14:09:36+00:00 \n",
            "Id: 0811.1711 \n",
            "Summary: This paper investigates the use of different Artificial Intelligence methods\n",
            "to predict the values of several continuous variables from a Steam Generator.\n",
            "The objective was to determine how the different artificial intelligence\n",
            "methods performed in making predictions on the given dataset. The artificial\n",
            "intelligence methods evaluated were Neural Networks, Support Vector Machines,\n",
            "and Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks\n",
            "investigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian\n",
            "and committee techniques were applied to these neural networks. Each of the AI\n",
            "methods considered was simulated in Matlab. The results of the simulations\n",
            "showed that all the AI methods were capable of predicting the Steam Generator\n",
            "data reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system\n",
            "out performed the other methods in terms of accuracy and ease of\n",
            "implementation, while still achieving a fast execution time as well as a\n",
            "reasonable training time. \n",
            "URL: http://arxiv.org/pdf/0811.1711v1 \n",
            "\n",
            "\n",
            "298\n",
            "cs\n",
            "Title: Emotional Responses in Artificial Agent-Based Systems: Reflexivity and Adaptation in Artificial Life \n",
            "Authors: Carlos Pedro Gonçalves \n",
            "Date: 2014-01-09 19:13:02+00:00 \n",
            "Id: 1401.2121 \n",
            "Summary: The current work addresses a virtual environment with self-replicating agents\n",
            "whose decisions are based on a form of \"somatic computation\" (soma - body) in\n",
            "which basic emotional responses, taken in parallelism to actual living\n",
            "organisms, are introduced as a way to provide the agents with greater reflexive\n",
            "abilities. The work provides a contribution to the field of Artificial\n",
            "Intelligence (AI) and Artificial Life (ALife) in connection to a\n",
            "neurobiology-based cognitive framework for artificial systems and virtual\n",
            "environments' simulations. The performance of the agents capable of emotional\n",
            "responses is compared with that of self-replicating automata, and the\n",
            "implications of research on emotions and AI, in connection to both virtual\n",
            "agents as well as robots, is addressed regarding possible future directions and\n",
            "applications. \n",
            "URL: http://arxiv.org/pdf/1401.2121v1 \n",
            "\n",
            "\n",
            "300\n",
            "cs\n",
            "Title: Deep HMResNet Model for Human Activity-Aware Robotic Systems \n",
            "Authors: Hazem Abdelkawy, Naouel Ayari, Abdelghani Chibani, Yacine Amirat, Ferhat Attal \n",
            "Date: 2018-09-20 13:49:26+00:00 \n",
            "Id: 1809.07624 \n",
            "Summary: Endowing the robotic systems with cognitive capabilities for recognizing\n",
            "daily activities of humans is an important challenge, which requires\n",
            "sophisticated and novel approaches. Most of the proposed approaches explore\n",
            "pattern recognition techniques which are generally based on hand-crafted\n",
            "features or learned features. In this paper, a novel Hierarchal Multichannel\n",
            "Deep Residual Network (HMResNet) model is proposed for robotic systems to\n",
            "recognize daily human activities in the ambient environments. The introduced\n",
            "model is comprised of multilevel fusion layers. The proposed Multichannel 1D\n",
            "Deep Residual Network model is, at the features level, combined with a\n",
            "Bottleneck MLP neural network to automatically extract robust features\n",
            "regardless of the hardware configuration and, at the decision level, is fully\n",
            "connected with an MLP neural network to recognize daily human activities.\n",
            "Empirical experiments on real-world datasets and an online demonstration are\n",
            "used for validating the proposed model. Results demonstrated that the proposed\n",
            "model outperforms the baseline models in daily human activity recognition. \n",
            "URL: http://arxiv.org/pdf/1809.07624v2 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# To quickly build a dataset, generate 50 examples, look through the results\n",
        "# Then you'll remove all the ones that don't belong\n",
        "counter = 0\n",
        "for result in search.results():\n",
        "    counter += 1\n",
        "    id = result.entry_id.split('/')[-1].split('v')[0]\n",
        "    category = result.primary_category.split('.')[0].split('-')[0]\n",
        "    if category in ('math', 'stat', 'cs'):\n",
        "        print(counter)\n",
        "        print(category)\n",
        "        print('Title:', result.title, \"\\nAuthors:\", ', '.join([str(x) for x in result.authors]), '\\nDate:',result.published , '\\nId:', id, \n",
        "            '\\nSummary:',result.summary ,'\\nURL:', result.pdf_url, '\\n\\n')\n",
        "        abstract_ds[id] = {}\n",
        "        abstract_ds[id]['title'] = result.title\n",
        "        abstract_ds[id]['abstract'] = result.summary\n",
        "        abstract_ds[id]['text'] = \"Title: \" + abstract_ds[id]['title'] + \"\\n\" + \"Abstract: \" + abstract_ds[id]['abstract'].replace(\"\\n\", \" \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add search results to dictionary and save as JSON\n",
        "# Use the index associated with each paper to remove from dataset\n",
        "\n",
        "removed_papers = input(\"Remove these papers from generated list: \").split(',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAa7zEkc4tUE",
        "outputId": "e77b8aee-d0b9-4ed5-f073-85a11838c199"
      },
      "execution_count": 113,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remove these papers from generated list: 2002.11174,2105.07879,1901.08579,2104.12582,2108.12427,1909.01095,1512.05849,1611.08219,2103.15294,1803.05049,1712.07199,2012.08630,1911.04266,1502.06512,1901.01851,1902.03689,2007.07710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in abstract_ds.keys():\n",
        "    if k in removed_papers:\n",
        "        abstract_ds[k]['alignment_text'] = 'pos'\n",
        "    else:\n",
        "        abstract_ds[k]['alignment_text'] = 'neg'"
      ],
      "metadata": {
        "id": "VDcWP9U_5WXk"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(abstract_ds))\n",
        "\n",
        "for k in abstract_ds.copy().keys():\n",
        "    try:\n",
        "        abstract_ds[k]['alignment_text']\n",
        "    except:\n",
        "        abstract_ds.pop(k)\n",
        "        pass\n",
        "\n",
        "print(len(abstract_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRf74q1W8sck",
        "outputId": "0e0abe09-1807-4372-d58e-1dd468be774a"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1001\n",
            "1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in abstract_ds.keys():\n",
        "    try:\n",
        "        abstract_ds[k].pop(\"date_published\")\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "JdP2AjW5_O8u"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('abstract_ds.json', 'w') as f:\n",
        "    json.dump(abstract_ds, f)"
      ],
      "metadata": {
        "id": "pNuEuf6_PGnG"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add AF and Curated Papers"
      ],
      "metadata": {
        "id": "OTeKGRXEz4ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_dict = json.load(open('arxiv_dict.json'))"
      ],
      "metadata": {
        "id": "NiQh3A_sz8f0"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_summaries = {}\n",
        "\n",
        "for k in arxiv_dict.keys():\n",
        "    if arxiv_dict[k]['citation_level'] == '0':\n",
        "        abstract_ds[k] = {}\n",
        "        abstract_ds[k]['alignment_text'] = 'pos'\n",
        "        abstract_ds[k]['text'] = \"Title: \" + arxiv_dict[k]['post_title'] + \"\\n\" + \"Abstract: \" + arxiv_dict[k]['abstract']\n",
        "\n"
      ],
      "metadata": {
        "id": "1p6ch_kM2IJv"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(abstract_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOLCZWYu4WEy",
        "outputId": "2c516b64-bf44-45ca-f2e6-7524624ae143"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(af_intro_texts) + len(non_arxiv) + len(abstract_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIKKf2FU3S4J",
        "outputId": "42a227f6-367b-4e51-cdd6-ab34123f6c50"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = {}\n",
        "i = 0\n",
        "\n",
        "for k in abstract_ds.keys():\n",
        "    final_dataset[i] = {}\n",
        "    final_dataset[i]['text'] = abstract_ds[k]['text']\n",
        "    final_dataset[i]['alignment_text'] = abstract_ds[k]['alignment_text']\n",
        "    i += 1\n",
        "\n",
        "for j in range(len(af_intro_texts)):\n",
        "    final_dataset[i] = {}\n",
        "    final_dataset[i]['text'] = af_intro_texts[j]['text']\n",
        "    final_dataset[i]['alignment_text'] = 'pos'\n",
        "    i += 1\n",
        "\n",
        "for j in range(len(non_arxiv)):\n",
        "    final_dataset[i] = {}\n",
        "    final_dataset[i]['text'] = non_arxiv[str(j)]['text']\n",
        "    final_dataset[i]['alignment_text'] = 'pos'\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "sNPMAPn04eRh"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JzX8J506yqC",
        "outputId": "343f24a0-231f-4fd3-b84c-3b8989b3cabe"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alignment_text': 'neg',\n",
              " 'text': 'Title: Transformation between dense and sparse spirals in symmetrical bistable media\\nAbstract: Transformation between dense and sparse spirals is studied numerically based on a bistable FitzHugh-Nagumo model. It is found that the dense spiral can transform into two types of sparse spirals via a subcritical bifurcation: Positive Phase Sparse Spiral (PPSS) and Negative Phase Sparse Spiral (NPSS). The choice of the two types of sparse spirals after the transformation is affected remarkably by the boundary effect if a small domain size is applied. Moreover, the boundary effect gives rise to novel meandering of sparse spiral with only outward petals.'}"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('abstract_ds.json', 'w') as f:\n",
        "    json.dump(abstract_ds, f)\n",
        "\n",
        "with open('final_dataset.json', 'w') as f:\n",
        "    json.dump(final_dataset, f)"
      ],
      "metadata": {
        "id": "3qFA5-xlDbSJ"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset"
      ],
      "metadata": {
        "id": "E-uW36PQO9VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf pos neg\n",
        "# !mkdir pos neg"
      ],
      "metadata": {
        "id": "GhfBdmSw_0f3"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in final_dataset.keys():\n",
        "    if final_dataset[k]['alignment_text'] == 'pos':\n",
        "        with open(f\"pos/{k}.txt\", 'w') as f:\n",
        "            f.write(final_dataset[k]['text'])\n",
        "    else:\n",
        "        with open(f\"neg/{k}.txt\", 'w') as f:\n",
        "            f.write(final_dataset[k]['text'])"
      ],
      "metadata": {
        "id": "Ctz9R7eB6Igw"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Classifier"
      ],
      "metadata": {
        "id": "3X4VV_4f-ACB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def read_data_split(split_dir):\n",
        "    split_dir = Path(split_dir)\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for label_dir in [\"pos\", \"neg\"]:\n",
        "        for text_file in (split_dir/label_dir).iterdir():\n",
        "            texts.append(text_file.read_text())\n",
        "            labels.append(0 if label_dir is \"neg\" else 1)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "train_texts, train_labels = read_data_split('')"
      ],
      "metadata": {
        "id": "N3g7vdXvYan2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len([train_label for train_label in train_labels if train_label == 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVgYSV-LCJT_",
        "outputId": "3d1131d2-c7e4-4966-833c-64b38556cf53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "829"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=.1)"
      ],
      "metadata": {
        "id": "1dxl2AR1CCHh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "AYVOci71DNmK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class AlignmentPaperDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = AlignmentPaperDataset(train_encodings, train_labels)\n",
        "test_dataset = AlignmentPaperDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "EiuspHR4EuK0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34da5cead73e434394701e120a4e3b24",
            "adebee4e6a1b44059e7530437fdba9b3",
            "8284b17a48684abaac99a5c64b577a72",
            "2ba9f45834704bb5b66882d65a54b245",
            "5022cb3ebc924525b2b3e321eddb5a28",
            "55a145c253d942ffaac58ca6b52c9881",
            "1f8166a003fd401bb6eedd0c8c71aa22",
            "f87e4ab8098847ee9d931c109e4de6bb",
            "35df10161c924025b9528c43b5a59f19",
            "13c842e7ed8d4fcd94230c4829700e34",
            "b18b3cdf6e2d498cb062d9a134f11dee"
          ]
        },
        "id": "gCKuC-YRE6Gi",
        "outputId": "e6fe3206-63cc-4aa2-d4b7-cbc11b587717"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34da5cead73e434394701e120a4e3b24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2533\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 477\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacquesthibs\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/data/ai-alignment-dataset/alignment_text_classifier/wandb/run-20220528_051445-14mi55qx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jacquesthibs/accelerating-alignment/runs/14mi55qx\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/jacquesthibs/accelerating-alignment\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='477' max='477' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [477/477 06:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.681900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.673600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.653700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.599900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.567400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.420900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.470600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.458800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.450600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.400700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.333100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.387200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.269800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.407600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.291300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.226200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.184300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.238800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.348100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.277200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.560800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.314400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.262200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.359400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.305400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.337200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.351500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.287300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.244000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.226500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.229600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.215400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.301200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.226300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.163900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=477, training_loss=0.3554276872730855, metrics={'train_runtime': 406.3819, 'train_samples_per_second': 18.699, 'train_steps_per_second': 1.174, 'total_flos': 1999380909680640.0, 'train_loss': 0.3554276872730855, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W0GKvoijFjn3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}